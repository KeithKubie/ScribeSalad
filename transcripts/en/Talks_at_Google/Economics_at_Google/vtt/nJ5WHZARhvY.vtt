WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.500
[MUSIC PLAYING]

00:00:07.000 --> 00:00:10.500
[APPLAUSE]

00:00:10.500 --> 00:00:13.280
MICHAEL BHASKAR: Thank you
very much for coming and taking

00:00:13.280 --> 00:00:17.180
the time out of your day to
come and listen to me talk.

00:00:17.180 --> 00:00:20.120
Hopefully it'll be
worth your while.

00:00:20.120 --> 00:00:22.400
Why curation?

00:00:22.400 --> 00:00:26.390
Actually it's a word that used
to really, really annoy me,

00:00:26.390 --> 00:00:29.390
and I used to think that people
who used the word curation

00:00:29.390 --> 00:00:31.273
were just trying to
be really clever.

00:00:31.273 --> 00:00:32.689
They were being a
bit pretentious.

00:00:32.689 --> 00:00:34.772
They were just trying to
take a little bit of cool

00:00:34.772 --> 00:00:38.100
and just apply it to
something, and at the time--

00:00:38.100 --> 00:00:40.990
so my background is primarily
as a book publisher.

00:00:40.990 --> 00:00:44.960
And I guess about seven
years ago, maybe even more,

00:00:44.960 --> 00:00:47.000
there was this great
wave of digitization

00:00:47.000 --> 00:00:50.190
and the e-book revolution that
hit the book publishing world.

00:00:50.190 --> 00:00:52.704
And I would go to a
lot of the conferences,

00:00:52.704 --> 00:00:55.370
mainly just because I thought it
would be an interesting day out

00:00:55.370 --> 00:00:57.370
and more interesting than
staying in the office,

00:00:57.370 --> 00:00:59.360
unlike here at Google,
where it's always

00:00:59.360 --> 00:01:01.830
interesting to see our talks.

00:01:01.830 --> 00:01:03.590
Anyway, so I'd go to
these conferences,

00:01:03.590 --> 00:01:07.490
and constantly people would
be talking about curation.

00:01:07.490 --> 00:01:11.480
And I thought, no, this
has got to be ridiculous.

00:01:11.480 --> 00:01:13.790
And then the more
I started to go,

00:01:13.790 --> 00:01:16.610
the more I started
to think, hang on,

00:01:16.610 --> 00:01:18.770
maybe there is
something in this idea.

00:01:18.770 --> 00:01:21.570
Maybe when people are
using the word curation,

00:01:21.570 --> 00:01:24.470
there is actually something much
more interesting and powerful

00:01:24.470 --> 00:01:25.900
going on.

00:01:25.900 --> 00:01:28.550
And I got so interested in it,
I then wrote a book about it.

00:01:28.550 --> 00:01:31.070
And I'm now forever going to
be associated with this word

00:01:31.070 --> 00:01:33.980
that I once thought was
hopelessly pretentious.

00:01:33.980 --> 00:01:36.860
But I'll just have
to live with that.

00:01:36.860 --> 00:01:39.710
So anyway, before
getting to exactly why I

00:01:39.710 --> 00:01:42.360
think it's so interesting
and important,

00:01:42.360 --> 00:01:46.960
a bit of background
about this word itself.

00:01:46.960 --> 00:01:50.220
So it all comes from
the Latin word curare,

00:01:50.220 --> 00:01:52.731
which means to take care of.

00:01:52.731 --> 00:01:54.480
That's sort of always,
I think, an element

00:01:54.480 --> 00:01:57.720
that has remained in
curation, taking care of.

00:01:57.720 --> 00:02:01.890
And actually, if you look at the
Roman Empire, you had curators,

00:02:01.890 --> 00:02:03.900
and it was-- the curators
were the people who

00:02:03.900 --> 00:02:05.350
built the infrastructure.

00:02:05.350 --> 00:02:07.560
So the Colosseum,
the roads, they

00:02:07.560 --> 00:02:09.150
were built by the
Roman curators.

00:02:09.150 --> 00:02:10.590
They planned it all.

00:02:10.590 --> 00:02:13.080
And then years
later in the church,

00:02:13.080 --> 00:02:16.050
you had curates, who
were priests, vicars.

00:02:16.050 --> 00:02:18.150
So in this idea of
a curator, you've

00:02:18.150 --> 00:02:20.160
got the bureaucrat
and the priest

00:02:20.160 --> 00:02:23.740
and this kind of idea of hidden
knowledge and hidden power.

00:02:23.740 --> 00:02:26.670
But that's where it might
have just been left.

00:02:26.670 --> 00:02:29.910
But then in the 18th
century we started

00:02:29.910 --> 00:02:32.340
to get the first big museums.

00:02:32.340 --> 00:02:33.990
This is the British Museum.

00:02:33.990 --> 00:02:35.580
That building came later.

00:02:35.580 --> 00:02:39.120
But the British Museum combined
these three great collections,

00:02:39.120 --> 00:02:43.650
and for the first time you
had a national collection.

00:02:43.650 --> 00:02:45.120
And then in Paris--

00:02:45.120 --> 00:02:46.260
this is the Louvre--

00:02:46.260 --> 00:02:47.940
you had pretty much
the same thing.

00:02:47.940 --> 00:02:51.160
What happened in Paris was
there was the French Revolution,

00:02:51.160 --> 00:02:54.450
that the old king had
probably Europe's biggest art

00:02:54.450 --> 00:02:55.050
collection.

00:02:55.050 --> 00:02:57.480
And after the revolution,
they said, hold on,

00:02:57.480 --> 00:03:00.460
we're going to show his
collection to the public

00:03:00.460 --> 00:03:02.370
and we're going to do
it in his old palace,

00:03:02.370 --> 00:03:04.770
and that today is
the Louvre Museum.

00:03:04.770 --> 00:03:07.530
And in both the British
Museum and the Louvre,

00:03:07.530 --> 00:03:09.420
you had a new problem.

00:03:09.420 --> 00:03:12.930
You had loads and
loads of stuff to show,

00:03:12.930 --> 00:03:15.150
and that meant you
needed a new role.

00:03:15.150 --> 00:03:18.990
You needed a curator to
come and put on exhibitions,

00:03:18.990 --> 00:03:21.780
to kind of say to
people, this is actually

00:03:21.780 --> 00:03:22.740
what you should see.

00:03:22.740 --> 00:03:25.510
This is how the
exhibition works.

00:03:25.510 --> 00:03:28.950
And over the 19th century you
got more and more museums.

00:03:28.950 --> 00:03:30.210
They got bigger and bigger.

00:03:30.210 --> 00:03:33.780
And this role of a curator
as the key person in museums

00:03:33.780 --> 00:03:37.560
became something
really important.

00:03:37.560 --> 00:03:40.380
And that takes us up
to the 20th century.

00:03:40.380 --> 00:03:42.330
And then something
sort of interesting

00:03:42.330 --> 00:03:46.880
happened in that curation
jumped over to the art world,

00:03:46.880 --> 00:03:49.770
and specifically the
contemporary art world.

00:03:49.770 --> 00:03:53.730
This figure here is Marcel
Duchamp, who you may or may not

00:03:53.730 --> 00:03:57.510
know is famous for just putting
a urinal in an art gallery,

00:03:57.510 --> 00:04:00.090
signing it with a fake
name, and then calling it

00:04:00.090 --> 00:04:03.330
art, which at the time was
obviously pretty controversial,

00:04:03.330 --> 00:04:05.160
and people are like,
what are you doing?

00:04:05.160 --> 00:04:07.680
And anyway, by doing
that Duchamp kind of

00:04:07.680 --> 00:04:10.770
started this revolution
of conceptual art.

00:04:10.770 --> 00:04:14.100
And art over the course
of the 20th century

00:04:14.100 --> 00:04:16.440
became something where
you needed somebody

00:04:16.440 --> 00:04:19.079
to say it was art
for it to be art.

00:04:19.079 --> 00:04:20.160
Who does that?

00:04:20.160 --> 00:04:22.050
Well, a curator does that.

00:04:22.050 --> 00:04:24.210
So suddenly you
have-- the curator

00:04:24.210 --> 00:04:29.510
in the art world
becomes the key person.

00:04:29.510 --> 00:04:30.980
And now what you get--

00:04:30.980 --> 00:04:35.630
so this is Miami, where there's
the big Miami Art Basel,

00:04:35.630 --> 00:04:39.080
and you get these big biennales
like this where the curators

00:04:39.080 --> 00:04:41.690
jetton for a few days.

00:04:41.690 --> 00:04:45.050
One art critic calls them
now the popes of art.

00:04:45.050 --> 00:04:48.260
That's because it's the curators
who are the real power brokers.

00:04:48.260 --> 00:04:49.430
It's not the artists.

00:04:49.430 --> 00:04:50.430
It's not the gallerists.

00:04:50.430 --> 00:04:52.430
It's not the collectors.

00:04:52.430 --> 00:04:54.500
It's not the public viewer.

00:04:54.500 --> 00:04:56.360
It's the curator who
ties it all together.

00:04:56.360 --> 00:04:58.970
They're the one who
says, this is art.

00:04:58.970 --> 00:05:00.770
They put together
these big exhibitions,

00:05:00.770 --> 00:05:02.960
these blockbusters.

00:05:02.960 --> 00:05:05.990
And anyway, that's a kind of
potted history of the word

00:05:05.990 --> 00:05:10.814
curation and curator, and it
kind of-- at that level sort of

00:05:10.814 --> 00:05:12.230
would have stayed
as little niche.

00:05:12.230 --> 00:05:13.605
It's something
for the art world.

00:05:13.605 --> 00:05:15.350
It's something for museums.

00:05:15.350 --> 00:05:19.920
But of course, something
bumped it out of its niche,

00:05:19.920 --> 00:05:21.780
and that was the internet.

00:05:21.780 --> 00:05:25.830
And actually you can look at the
very early days of the internet

00:05:25.830 --> 00:05:28.200
and you see-- actually if
you look at the Google Ngram

00:05:28.200 --> 00:05:30.810
Viewer, the uses of
the word curation

00:05:30.810 --> 00:05:34.260
really starts spiking
from the mid to late '90s,

00:05:34.260 --> 00:05:36.710
and that's because actually
on a sort of GeoCities

00:05:36.710 --> 00:05:38.290
style site-- do
you guys remember

00:05:38.290 --> 00:05:40.350
GeoCities, the early
website, you know,

00:05:40.350 --> 00:05:44.340
where you'd have sort of
nice design like this?

00:05:44.340 --> 00:05:46.320
People were starting
to do things that

00:05:46.320 --> 00:05:49.260
looked very much like curation.

00:05:49.260 --> 00:05:53.790
And so what happened was that
this old kind of fusty concept

00:05:53.790 --> 00:05:56.520
from the art world suddenly
became really mainstream,

00:05:56.520 --> 00:05:58.980
and that was all down to
what was going on on the web.

00:05:58.980 --> 00:06:02.970
Suddenly everyone was
becoming a curator,

00:06:02.970 --> 00:06:05.670
and it became a really
kind of hot, hot topic

00:06:05.670 --> 00:06:09.640
and then has just sort
of mushroomed from there.

00:06:09.640 --> 00:06:14.750
But that doesn't really explain
what's important about it.

00:06:14.750 --> 00:06:17.510
Here's what I think,
actually why did we

00:06:17.510 --> 00:06:19.100
need curators on the internet?

00:06:19.100 --> 00:06:22.220
Because a context of
abundance changes everything.

00:06:22.220 --> 00:06:24.080
When you've got too
much, when you've

00:06:24.080 --> 00:06:27.410
got problems of
having too much stuff,

00:06:27.410 --> 00:06:29.330
that's when you need curation.

00:06:29.330 --> 00:06:32.540
And on the internet, we
suddenly had too much

00:06:32.540 --> 00:06:34.400
of basically everything.

00:06:34.400 --> 00:06:37.580
But it's not just the internet.

00:06:37.580 --> 00:06:41.670
This is a chart of economic
growth throughout history.

00:06:41.670 --> 00:06:46.250
If you look at Western Europe
from the years 1000 to 1500,

00:06:46.250 --> 00:06:52.280
there was less growth than in
years 2012 to 2016 in China.

00:06:52.280 --> 00:06:55.410
Basically for most of history
we didn't have economic growth.

00:06:55.410 --> 00:06:57.490
The world just stayed the same.

00:06:57.490 --> 00:07:01.040
Then look at what's happened on
a global scale in the past 50

00:07:01.040 --> 00:07:02.070
years.

00:07:02.070 --> 00:07:05.840
Productivity improvements,
manufacturing improvements,

00:07:05.840 --> 00:07:07.760
the whole gamut of
digital technology

00:07:07.760 --> 00:07:10.550
and what it's enabled
people to unleash.

00:07:10.550 --> 00:07:13.640
We actually have
problems of too much.

00:07:13.640 --> 00:07:17.286
And I say that, and
people think, well, do we?

00:07:17.286 --> 00:07:19.160
Of course, it's a kind
of privileged position

00:07:19.160 --> 00:07:21.380
to be in, to have
problems of too much,

00:07:21.380 --> 00:07:24.740
but it's still a reality
in those privileged parts

00:07:24.740 --> 00:07:27.890
that we have too many
things coming at us.

00:07:27.890 --> 00:07:31.620
For example, books.

00:07:31.620 --> 00:07:35.290
I'm a publisher, and I
work in the book world.

00:07:35.290 --> 00:07:37.480
In the English
language every year

00:07:37.480 --> 00:07:40.750
we have a million
new books published.

00:07:40.750 --> 00:07:43.330
And if you think about it,
there's already a lot of books

00:07:43.330 --> 00:07:44.080
out there.

00:07:44.080 --> 00:07:46.010
There's already a
lot of classics.

00:07:46.010 --> 00:07:48.790
There's already a lot
of books building up

00:07:48.790 --> 00:07:51.730
on your bedside table that
you really should read.

00:07:51.730 --> 00:07:54.340
There's already a lot of
publishers and writers

00:07:54.340 --> 00:07:56.530
like me just churning
out another book,

00:07:56.530 --> 00:07:59.230
and yet a million new
ones come in every year.

00:07:59.230 --> 00:08:02.500
That's not including all
the self-published material.

00:08:02.500 --> 00:08:06.380
That's not including all the
other languages in the world.

00:08:06.380 --> 00:08:09.310
And of course,
that's not including

00:08:09.310 --> 00:08:11.290
the massive information
overload that we

00:08:11.290 --> 00:08:13.270
experience everywhere else.

00:08:13.270 --> 00:08:16.960
This is a statistic from the
American neuroscientist Daniel

00:08:16.960 --> 00:08:21.490
Levitin, and he thinks
that if you kind of add up

00:08:21.490 --> 00:08:24.460
all of the tweets we look at,
the adverts we see on our way

00:08:24.460 --> 00:08:27.490
to work, the TV
that we watch, it's

00:08:27.490 --> 00:08:30.670
basically equivalent to
175 newspapers just being

00:08:30.670 --> 00:08:33.549
downloaded into our
brain every day.

00:08:33.549 --> 00:08:36.490
I'm sure this is a problem
people think about here quite

00:08:36.490 --> 00:08:38.620
a lot as well.

00:08:38.620 --> 00:08:41.380
So as a kind of humble
book publisher, when people

00:08:41.380 --> 00:08:44.410
have x number of
TV series to watch,

00:08:44.410 --> 00:08:47.830
they've got social media,
how do you compete with that?

00:08:47.830 --> 00:08:52.120
We don't have a problem
of a scarcity of new books

00:08:52.120 --> 00:08:53.950
at the minute in the UK.

00:08:53.950 --> 00:08:56.200
We have a problem that
there are far, far too

00:08:56.200 --> 00:08:59.620
many books competing for
an ever-shrinking number

00:08:59.620 --> 00:09:01.180
of readers.

00:09:01.180 --> 00:09:02.830
And so to me that
kind of changes

00:09:02.830 --> 00:09:07.030
the whole equation of just
producing more doesn't work.

00:09:07.030 --> 00:09:09.790
Actually what's the
value in me publishing

00:09:09.790 --> 00:09:13.210
the millionth and first
book against finding

00:09:13.210 --> 00:09:16.900
you the exact perfect book
that you want to read next?

00:09:16.900 --> 00:09:21.780
And that I think is why
curation is important.

00:09:21.780 --> 00:09:24.460
And it also ties into choice.

00:09:24.460 --> 00:09:28.830
So what all of this means,
what all of this expanding

00:09:28.830 --> 00:09:32.580
production means is that
we all have more choices.

00:09:32.580 --> 00:09:34.870
And actually if you look
at government policy,

00:09:34.870 --> 00:09:36.210
it's all about expanding choice.

00:09:36.210 --> 00:09:39.390
If you look at most businesses,
all about expanding choice.

00:09:39.390 --> 00:09:42.780
As individuals, we like to
think the more choices we have,

00:09:42.780 --> 00:09:44.280
the better.

00:09:44.280 --> 00:09:47.220
And actually this is
wrong to some extent.

00:09:47.220 --> 00:09:50.860
So there's a famous experiment
from Sheena Iyengar, who's

00:09:50.860 --> 00:09:54.270
a Columbia University
psychologist in the States,

00:09:54.270 --> 00:09:56.430
and what she did was
she wanted to see

00:09:56.430 --> 00:09:58.920
whether this idea that
more choice is better

00:09:58.920 --> 00:10:00.520
is actually true.

00:10:00.520 --> 00:10:02.790
And the initial
experiment was with jam,

00:10:02.790 --> 00:10:05.010
and she did this
around the Bay Area.

00:10:05.010 --> 00:10:08.250
She went to supermarkets,
and on some days did

00:10:08.250 --> 00:10:12.150
a presentation of 24
jams, and a lot of people

00:10:12.150 --> 00:10:15.090
would come and look at the jam
and try it and think, oh, yes,

00:10:15.090 --> 00:10:16.330
very nice.

00:10:16.330 --> 00:10:19.950
But then almost no one
actually went on to buy jam.

00:10:19.950 --> 00:10:22.770
On other days she put four
or five different jams

00:10:22.770 --> 00:10:24.300
on the same table.

00:10:24.300 --> 00:10:27.990
Slightly fewer people
went to look at the jam,

00:10:27.990 --> 00:10:32.120
but a huge proportion of
them then went on to buy jam.

00:10:32.120 --> 00:10:34.320
And this sort of
principle has now

00:10:34.320 --> 00:10:36.860
been repeated many,
many, many times.

00:10:36.860 --> 00:10:39.090
I tend to be quite
skeptical often

00:10:39.090 --> 00:10:42.030
of these psychological
experiments that you do once.

00:10:42.030 --> 00:10:45.510
You kind of come up with a grand
conclusion, and then move on.

00:10:45.510 --> 00:10:47.250
This is actually pretty solid.

00:10:47.250 --> 00:10:49.410
And what it comes down
to is that there's

00:10:49.410 --> 00:10:51.860
a limit to the amount
of choice we want.

00:10:51.860 --> 00:10:55.300
After about four or five
choices, we switch off.

00:10:55.300 --> 00:10:56.610
We don't want to do anything.

00:10:56.610 --> 00:10:57.360
Why?

00:10:57.360 --> 00:11:00.750
Well, it all comes down to the
by now well-known principle

00:11:00.750 --> 00:11:02.680
of loss aversion.

00:11:02.680 --> 00:11:07.140
So the idea is that if you've
got, let's say, 15 choices,

00:11:07.140 --> 00:11:09.270
you're quite likely
to potentially make

00:11:09.270 --> 00:11:09.990
the wrong choice.

00:11:09.990 --> 00:11:11.790
You're quite likely
to think, oh, I

00:11:11.790 --> 00:11:13.890
could have chosen
something better even

00:11:13.890 --> 00:11:16.830
on something as trivial as
jam, and because of that,

00:11:16.830 --> 00:11:18.000
you don't want to choose.

00:11:18.000 --> 00:11:19.729
So you just move on.

00:11:19.729 --> 00:11:22.020
And this is a psychological
principle that we see again

00:11:22.020 --> 00:11:23.310
and again and again.

00:11:23.310 --> 00:11:28.090
We anticipate our own regret
at making the wrong choice,

00:11:28.090 --> 00:11:30.120
and so don't choose.

00:11:30.120 --> 00:11:33.720
We still like the agency of
feeling like we've chosen,

00:11:33.720 --> 00:11:36.054
but we don't want too
many different choices.

00:11:36.054 --> 00:11:37.470
And so I think
this is a principle

00:11:37.470 --> 00:11:39.960
that in too many
areas in the world

00:11:39.960 --> 00:11:41.460
we've totally lost sight of.

00:11:41.460 --> 00:11:44.280
We'll just go into shops
and it's just filled

00:11:44.280 --> 00:11:45.750
with tons of different choice.

00:11:45.750 --> 00:11:47.020
That's not what we want.

00:11:47.020 --> 00:11:50.082
We want to have things that
are very finely chosen.

00:11:50.082 --> 00:11:52.290
We want to know that somebody
has put a lot of effort

00:11:52.290 --> 00:11:54.830
in beforehand.

00:11:54.830 --> 00:11:57.110
So then all of this,
I think, takes us

00:11:57.110 --> 00:12:00.560
to what I see as
the core definition.

00:12:00.560 --> 00:12:03.320
This is what curation
is really about.

00:12:03.320 --> 00:12:06.380
When you hear people at
fancy conferences talking

00:12:06.380 --> 00:12:08.710
about curating this, that,
and the other, what I think

00:12:08.710 --> 00:12:11.010
they really are
trying to say is,

00:12:11.010 --> 00:12:14.690
when you're selecting and
arranging to add value,

00:12:14.690 --> 00:12:16.010
that's the meaning of curation.

00:12:16.010 --> 00:12:17.810
I think it's
something that Google

00:12:17.810 --> 00:12:19.950
does in numerous
different ways every day,

00:12:19.950 --> 00:12:21.560
and that a huge
part of the business

00:12:21.560 --> 00:12:24.800
is probably premised on is
this idea of adding value

00:12:24.800 --> 00:12:27.690
through selecting and
arranging things for people.

00:12:27.690 --> 00:12:32.420
And that is often all it
really amounts to, yet

00:12:32.420 --> 00:12:37.000
that is where a huge part of
the economy today is going.

00:12:37.000 --> 00:12:40.010
We're not in the stage of
just producing more and more.

00:12:40.010 --> 00:12:44.460
Actually the value has shifted
to this kind of activity.

00:12:44.460 --> 00:12:46.550
Anyway, so next time
you hear somebody talk

00:12:46.550 --> 00:12:48.869
about curating something,
make sure this is really

00:12:48.869 --> 00:12:50.660
what they mean, because
if they don't, then

00:12:50.660 --> 00:12:52.951
I'm afraid to say they may
just be waffling and looking

00:12:52.951 --> 00:12:56.170
pretentious.

00:12:56.170 --> 00:13:00.520
So, yeah, I think we are
now building and seeing

00:13:00.520 --> 00:13:04.960
the evolution of what I
would call broadly a curation

00:13:04.960 --> 00:13:07.630
economy, an economy
that is built

00:13:07.630 --> 00:13:12.370
to manage the various kind of
excesses that we've produced.

00:13:12.370 --> 00:13:16.850
Let me give you a few examples.

00:13:16.850 --> 00:13:19.020
This is an island
called Saadiyat Island

00:13:19.020 --> 00:13:21.940
that they're building off
the coast of Abu Dhabi.

00:13:21.940 --> 00:13:24.370
Now, Abu Dhabi has an
interesting situation

00:13:24.370 --> 00:13:28.690
because right now it's a very
wealthy, oil-led economy,

00:13:28.690 --> 00:13:31.030
but they're desperate,
like Dubai up the road,

00:13:31.030 --> 00:13:32.620
to diversify.

00:13:32.620 --> 00:13:34.060
And how are they
going to do that?

00:13:34.060 --> 00:13:36.430
They're going to do it by
building a whole island that

00:13:36.430 --> 00:13:41.020
is full of museums, and
they're buying art collections

00:13:41.020 --> 00:13:44.212
in a very careful way
for these museums.

00:13:44.212 --> 00:13:45.670
And it's almost
like they're trying

00:13:45.670 --> 00:13:49.570
to shift their economy up
scale through this kind of very

00:13:49.570 --> 00:13:52.360
careful curation of museums.

00:13:52.360 --> 00:13:55.840
It's sort of like the old Bill
Bauer tactic of build a museum

00:13:55.840 --> 00:14:00.370
but supercharged with
curation at its core.

00:14:00.370 --> 00:14:02.950
A very different
example would be roughly

00:14:02.950 --> 00:14:05.200
what you might think this is.

00:14:05.200 --> 00:14:07.540
I don't know about
you, but in my family

00:14:07.540 --> 00:14:10.870
when I was growing up, on a
Saturday night we'd always go

00:14:10.870 --> 00:14:11.860
and we'd rent a video.

00:14:11.860 --> 00:14:14.260
We'd go for some fish and
chips, and then we'd go home.

00:14:14.260 --> 00:14:17.950
We would have rented a
video, and we'd all watch it.

00:14:17.950 --> 00:14:20.270
And I'm sure you remember
going into Blockbuster

00:14:20.270 --> 00:14:24.974
and it had big racks
of, yes, blockbusters.

00:14:24.974 --> 00:14:26.140
And that was it pretty much.

00:14:26.140 --> 00:14:29.650
It wasn't a huge selection.

00:14:29.650 --> 00:14:32.830
In 1999, it had the
opportunity to buy a then

00:14:32.830 --> 00:14:34.540
fledgling start-up
for $50 million.

00:14:34.540 --> 00:14:38.530
It turned that down because it
thought that was outrageous.

00:14:38.530 --> 00:14:40.760
That start-up, of
course, was Netflix.

00:14:40.760 --> 00:14:44.560
And today Blockbuster
is no longer with us.

00:14:44.560 --> 00:14:48.340
I think there are many
reasons why Netflix took over

00:14:48.340 --> 00:14:51.600
or the Netflix model took over.

00:14:51.600 --> 00:14:53.820
And there's a lot in
there about convenience,

00:14:53.820 --> 00:14:56.020
but there was a different
model of selection

00:14:56.020 --> 00:14:57.420
at work in Netflix.

00:14:57.420 --> 00:15:01.060
In Blockbuster, you
just have a few things

00:15:01.060 --> 00:15:03.970
that are just put everywhere,
but there's not really

00:15:03.970 --> 00:15:06.150
any deep selection.

00:15:06.150 --> 00:15:09.970
In Netflix you have all
these tailored choices.

00:15:09.970 --> 00:15:13.060
So you never see everything,
but the overall catalog

00:15:13.060 --> 00:15:14.870
is much larger.

00:15:14.870 --> 00:15:18.930
So let's say you
like art house films.

00:15:18.930 --> 00:15:21.130
You won't ever find
those in Blockbuster.

00:15:21.130 --> 00:15:22.930
You will find them
in Netflix, and they

00:15:22.930 --> 00:15:25.300
will have been taken
from a large catalog

00:15:25.300 --> 00:15:27.112
and chosen for you.

00:15:27.112 --> 00:15:28.570
So what I call that
is an evolution

00:15:28.570 --> 00:15:31.330
from an industrial
model of selection

00:15:31.330 --> 00:15:34.990
to a curated model of selection,
and in the curated model

00:15:34.990 --> 00:15:37.940
you have much more
possible choices

00:15:37.940 --> 00:15:40.180
but always whittled
down for you.

00:15:40.180 --> 00:15:41.325
And I don't think Netflix--

00:15:41.325 --> 00:15:42.700
I don't think any
of us would say

00:15:42.700 --> 00:15:46.150
they've got it perfectly
right, but it's

00:15:46.150 --> 00:15:49.060
an example of how that
business model has changed.

00:15:49.060 --> 00:15:53.840
We don't just want the
same things for everyone.

00:15:53.840 --> 00:15:56.150
And of course, in music--

00:15:56.150 --> 00:16:00.192
we were just listening to some
music from a streaming service.

00:16:00.192 --> 00:16:01.900
There are millions
and millions of songs.

00:16:01.900 --> 00:16:03.760
All of us can go on
the internet right

00:16:03.760 --> 00:16:06.370
now, sign up to
something, and have access

00:16:06.370 --> 00:16:08.940
to basically all the
music in the world.

00:16:08.940 --> 00:16:13.150
And I'm sure you, like me,
will have been there facing

00:16:13.150 --> 00:16:16.570
all the music in the world
and really not having a clue

00:16:16.570 --> 00:16:18.210
what to listen to.

00:16:18.210 --> 00:16:21.700
And so now what we're
seeing is a real arms race

00:16:21.700 --> 00:16:23.770
in the kind of
curation of this music,

00:16:23.770 --> 00:16:27.700
and I'm sure Google Play
and others like Spotify--

00:16:27.700 --> 00:16:29.260
huge amounts of
investment is being

00:16:29.260 --> 00:16:33.430
made on building playlists
for people, creating

00:16:33.430 --> 00:16:35.560
the kind of algorithmic
infrastructure

00:16:35.560 --> 00:16:38.350
for recommending things
in very good ways,

00:16:38.350 --> 00:16:41.080
but also hiring experts.

00:16:41.080 --> 00:16:45.220
Spotify and Apple Music are
hiring deejays, as well as

00:16:45.220 --> 00:16:48.180
putting a lot of technological
resource behind it.

00:16:48.180 --> 00:16:51.250
Again, it's this idea of a
curated model of selection.

00:16:51.250 --> 00:16:52.750
You have everything,
but then you

00:16:52.750 --> 00:16:55.750
have to find ways of really
making it work for individuals.

00:16:58.810 --> 00:17:03.060
This is the IFC Tower and
Shopping Mall in Hong Kong,

00:17:03.060 --> 00:17:07.079
and this has pretty much the
highest rents of any shopping

00:17:07.079 --> 00:17:10.890
mall on Earth because you have
wealthy Hong Kong people going,

00:17:10.890 --> 00:17:13.050
mainland wealthy
Chinese, people from all

00:17:13.050 --> 00:17:14.800
over Asia and Southeast Asia.

00:17:14.800 --> 00:17:16.980
They're all going to this mall.

00:17:16.980 --> 00:17:20.040
The upshot of that is
that every single luxury

00:17:20.040 --> 00:17:22.589
brand in the world is just
desperate to get in there.

00:17:22.589 --> 00:17:26.550
It's just a must-go-to
kind of place.

00:17:26.550 --> 00:17:29.880
But the manager-- he
just says no to people,

00:17:29.880 --> 00:17:32.100
and he says no, no,
you're not right.

00:17:32.100 --> 00:17:34.500
Instead he's constantly
searching out

00:17:34.500 --> 00:17:36.750
the new cutting-edge
brands, the people who don't

00:17:36.750 --> 00:17:38.680
have any other stores in Asia.

00:17:38.680 --> 00:17:43.560
He wants to find a unique
mix of different shops.

00:17:43.560 --> 00:17:47.730
Now, if you go to a traditional
art curator and you say,

00:17:47.730 --> 00:17:51.150
well, your job is similar
to a shopping mall manager,

00:17:51.150 --> 00:17:54.840
I guarantee you'll get a really
bad response because I have

00:17:54.840 --> 00:17:57.630
done this, and
there's nothing more

00:17:57.630 --> 00:17:59.370
anathema to a
traditional curator

00:17:59.370 --> 00:18:02.250
than being compared to
a shopping mall manager.

00:18:02.250 --> 00:18:05.160
But what I say is there is a
familial resemblance there.

00:18:05.160 --> 00:18:07.650
They're both about
carefully selecting things

00:18:07.650 --> 00:18:09.420
and pulling them
together in a way that

00:18:09.420 --> 00:18:12.150
is unique and valuable
and interesting.

00:18:12.150 --> 00:18:14.550
There are plenty of
shopping malls in Hong

00:18:14.550 --> 00:18:16.230
Kong with the same shops.

00:18:16.230 --> 00:18:19.660
He wants to make sure this is
an absolutely unique experience,

00:18:19.660 --> 00:18:21.370
and that's the value in it.

00:18:21.370 --> 00:18:24.290
That's why this is such a
destination because it's

00:18:24.290 --> 00:18:25.650
exhaustively selected.

00:18:29.530 --> 00:18:31.752
And then talking
about retail, this--

00:18:31.752 --> 00:18:34.210
I don't know if any of you
would have been to one of these.

00:18:34.210 --> 00:18:35.890
This is in Italy.

00:18:35.890 --> 00:18:38.800
Alas, we don't have
one here in the UK.

00:18:38.800 --> 00:18:43.420
But people talk about this as
the supermarket of the future.

00:18:43.420 --> 00:18:45.410
Think about Italian
cooking for a minute,

00:18:45.410 --> 00:18:50.110
and it's incredibly complex in
that each area, each village

00:18:50.110 --> 00:18:53.860
has its own recipes, its own
style of cooking, its own very

00:18:53.860 --> 00:18:55.920
unique ingredients.

00:18:55.920 --> 00:18:59.440
And what Italy does is it
really literally goes down

00:18:59.440 --> 00:19:03.280
to the fields to choose the
very, very best possible

00:19:03.280 --> 00:19:06.730
products and food from Italy.

00:19:06.730 --> 00:19:10.910
It's a kind of super curated
version of a supermarket,

00:19:10.910 --> 00:19:12.370
and you really go
in there and you

00:19:12.370 --> 00:19:15.010
see the effort and the
care with which everything

00:19:15.010 --> 00:19:16.480
is put together.

00:19:16.480 --> 00:19:18.820
And really I think this is
kind of emblematic of what's

00:19:18.820 --> 00:19:21.730
happening in the retail
world more widely,

00:19:21.730 --> 00:19:24.370
and what we're seeing
just time and time again

00:19:24.370 --> 00:19:28.180
is that the middle of retail
is just falling apart.

00:19:28.180 --> 00:19:30.610
At the bottom end
you've got discounters

00:19:30.610 --> 00:19:32.950
who are doing very
well, and they're not

00:19:32.950 --> 00:19:34.170
really about selection.

00:19:34.170 --> 00:19:37.570
They are about price,
and they're doing OK.

00:19:37.570 --> 00:19:40.600
And then at the top end, you've
got really curated environments

00:19:40.600 --> 00:19:44.500
like Italy that are finding
a good kind of grounding

00:19:44.500 --> 00:19:47.140
for themselves by offering
something really special.

00:19:47.140 --> 00:19:50.980
Every single thing in that shop
has been pored over and thought

00:19:50.980 --> 00:19:53.380
about before it goes in there.

00:19:53.380 --> 00:19:56.290
But the middle of retail,
that's where you're in trouble.

00:19:56.290 --> 00:19:58.330
If you're not doing
either of those,

00:19:58.330 --> 00:20:01.107
that's going to create a
really big problem for you.

00:20:01.107 --> 00:20:03.190
And I think that-- that,
again, just sort of shows

00:20:03.190 --> 00:20:08.236
this kind of curation economy
that we are moving towards.

00:20:08.236 --> 00:20:09.360
I'm just checking the time.

00:20:12.340 --> 00:20:17.620
So I guess it all for me comes
down to this general shift.

00:20:17.620 --> 00:20:20.890
The curated model of selection
trumps the industrial model

00:20:20.890 --> 00:20:22.180
of selection.

00:20:22.180 --> 00:20:25.889
People don't just want these
kind of big categories that

00:20:25.889 --> 00:20:28.180
really aren't chosen, that
really aren't thought about,

00:20:28.180 --> 00:20:30.220
that aren't personalized.

00:20:30.220 --> 00:20:32.800
And then in media terms,
it also comes down

00:20:32.800 --> 00:20:35.890
to the kind of collapse of the
broadcast model in the sense

00:20:35.890 --> 00:20:39.910
that I mentioned music
services, streaming services.

00:20:39.910 --> 00:20:42.170
We have playlists, not albums.

00:20:42.170 --> 00:20:45.700
And those playlists are
constructed very specifically

00:20:45.700 --> 00:20:49.720
for us or for things
that we might like.

00:20:49.720 --> 00:20:52.660
In media, again I think
there's a shift in the sense

00:20:52.660 --> 00:20:56.330
that what we used to see
was journalists were just

00:20:56.330 --> 00:20:58.534
going out and taking all
of the footage, but then--

00:20:58.534 --> 00:21:00.950
and this is something I talk
about quite a lot in the book

00:21:00.950 --> 00:21:04.430
is if you look at the
revolution in Egypt, in Cairo,

00:21:04.430 --> 00:21:06.680
or you look at what
happened in Kiev and Ukraine

00:21:06.680 --> 00:21:08.630
when they had their
revolution, suddenly you

00:21:08.630 --> 00:21:11.710
had these kind of complex,
fast-moving environments,

00:21:11.710 --> 00:21:14.204
and news crews couldn't
keep up with it.

00:21:14.204 --> 00:21:15.620
And the role of
being a journalist

00:21:15.620 --> 00:21:18.170
slightly shifted from
being the one who goes out

00:21:18.170 --> 00:21:20.420
and gets the news
to being the one who

00:21:20.420 --> 00:21:23.550
pieces together the news from
sources that are out there.

00:21:23.550 --> 00:21:26.120
Everyone is there with their
phones just taking video.

00:21:26.120 --> 00:21:28.070
What you actually
need is an expert

00:21:28.070 --> 00:21:30.170
who can verify
what's happening, who

00:21:30.170 --> 00:21:32.950
can piece together a narrative.

00:21:32.950 --> 00:21:35.107
So again, it's just a
kind of subtle shift.

00:21:35.107 --> 00:21:37.190
And actually if you think
about what an editor has

00:21:37.190 --> 00:21:39.170
done at a newspaper,
they've always

00:21:39.170 --> 00:21:42.360
been about putting
together different things.

00:21:42.360 --> 00:21:45.110
And now that the curation
of our news environment

00:21:45.110 --> 00:21:47.450
has become a really
kind of hot topic,

00:21:47.450 --> 00:21:50.480
and this is something I wish I'd
talked more about in the book

00:21:50.480 --> 00:21:51.920
actually.

00:21:51.920 --> 00:21:54.440
Who decides what's
fake news, and how

00:21:54.440 --> 00:21:57.290
is that going to be something
that we can do algorithmically

00:21:57.290 --> 00:21:59.060
or machine learning,
or is it always

00:21:59.060 --> 00:22:03.610
going to need a kind of
human component as well?

00:22:03.610 --> 00:22:06.370
Whatever way you
cut it, the kind

00:22:06.370 --> 00:22:09.710
of-- the controversies,
the value of news today

00:22:09.710 --> 00:22:12.670
is as much about the
curation of what news just

00:22:12.670 --> 00:22:16.820
exists in the world as in being
the one going and getting it.

00:22:20.910 --> 00:22:23.490
The big distinction that
I make with all of this

00:22:23.490 --> 00:22:27.060
is between explicit
and implicit curation.

00:22:27.060 --> 00:22:31.830
So explicit curation, that is
people in East London with kind

00:22:31.830 --> 00:22:37.380
of cool glasses and galleries,
kind of getting-- doing--

00:22:37.380 --> 00:22:39.030
deejaying and so on.

00:22:39.030 --> 00:22:41.550
That's explicit curation, and
that's the kind of curation

00:22:41.550 --> 00:22:46.030
that I used to think was
just a bit everywhere.

00:22:46.030 --> 00:22:51.180
But actually so many industries
are implicitly curated.

00:22:51.180 --> 00:22:54.010
What is-- I think a lot
of what Google does.

00:22:54.010 --> 00:22:57.900
No one sort of sits there
and says, oh, we're curators,

00:22:57.900 --> 00:22:59.880
although I have to
say Eric Schmidt does

00:22:59.880 --> 00:23:03.840
say that Google is a curator
of the internet in his book.

00:23:03.840 --> 00:23:06.660
Actually what it is about is
about selecting and arranging

00:23:06.660 --> 00:23:08.410
information for people.

00:23:08.410 --> 00:23:10.140
And so even if it's
not called curation,

00:23:10.140 --> 00:23:13.050
I think it very much
is part of that.

00:23:13.050 --> 00:23:15.940
My wife is a buyer,
a retail buyer.

00:23:15.940 --> 00:23:18.064
She'd never say,
oh, I'm a curator,

00:23:18.064 --> 00:23:19.980
but actually what she
spends her days doing is

00:23:19.980 --> 00:23:22.470
choosing things that are
going to go on the shelves.

00:23:22.470 --> 00:23:25.530
It's very much
similar to curation.

00:23:25.530 --> 00:23:28.050
And it's this implicit
curation that I

00:23:28.050 --> 00:23:32.280
think is reordering so many
different industries, from TV

00:23:32.280 --> 00:23:36.240
to books to retail to
internet businesses.

00:23:36.240 --> 00:23:38.155
And that's what's
really exciting.

00:23:38.155 --> 00:23:41.850
And when we talk about
curation, more often than not,

00:23:41.850 --> 00:23:43.410
explicit is fine.

00:23:43.410 --> 00:23:45.030
It's sort of art galleries.

00:23:45.030 --> 00:23:46.964
It's when it's things
that implicitly curated,

00:23:46.964 --> 00:23:48.255
that's when it's very powerful.

00:23:51.290 --> 00:23:53.137
And around this
idea of selection,

00:23:53.137 --> 00:23:55.470
I think it's worth saying
that there are a lot of things

00:23:55.470 --> 00:23:59.100
that I call curation
effects, other things that

00:23:59.100 --> 00:24:02.850
are part of curation, because
it's not just about selecting.

00:24:02.850 --> 00:24:07.475
First and foremost, I think it's
about arranging things as well.

00:24:07.475 --> 00:24:08.850
And I've got a
couple of examples

00:24:08.850 --> 00:24:10.590
of the power of
arranging things,

00:24:10.590 --> 00:24:15.000
like, we don't actually have
to necessarily do new things.

00:24:15.000 --> 00:24:16.500
Sometimes just
simply rearranging

00:24:16.500 --> 00:24:20.310
what we have can have
enormously generative effects.

00:24:20.310 --> 00:24:24.540
So this building here
is building 20 at MIT.

00:24:24.540 --> 00:24:29.470
It's now been knocked down and
replaced by the Stata Center.

00:24:29.470 --> 00:24:32.370
It's probably the building
from the 20th century

00:24:32.370 --> 00:24:34.770
where more innovation
happened than

00:24:34.770 --> 00:24:38.490
in any other single building,
and this is its story.

00:24:38.490 --> 00:24:40.910
So it was thrown
up in World War II

00:24:40.910 --> 00:24:43.650
to basically pioneer
new kinds of radar.

00:24:43.650 --> 00:24:45.420
It was an urgent
effort for the war.

00:24:45.420 --> 00:24:47.220
They needed to do this.

00:24:47.220 --> 00:24:50.120
Because it was built just for
the radar in World War II,

00:24:50.120 --> 00:24:52.770
it was just always going
to be knocked down.

00:24:52.770 --> 00:24:56.510
So it was just jerry-rigged
and it was dodgy.

00:24:56.510 --> 00:25:00.510
After the war, a load of misfits
from across the MIT campus

00:25:00.510 --> 00:25:03.200
moved in there, and
all the people--

00:25:03.200 --> 00:25:05.190
it just didn't
really have a home.

00:25:05.190 --> 00:25:07.407
And actually what they
started to do was--

00:25:07.407 --> 00:25:08.490
there were no regulations.

00:25:08.490 --> 00:25:10.560
They just started knocking
through all the walls,

00:25:10.560 --> 00:25:12.480
knocking through the
ceilings, and that

00:25:12.480 --> 00:25:15.460
meant it just became
totally kind of open plan.

00:25:15.460 --> 00:25:17.370
And then all of these
strange collaborations

00:25:17.370 --> 00:25:20.490
started happening, and people
would just get together

00:25:20.490 --> 00:25:23.460
in totally different and
new ways in Building 20,

00:25:23.460 --> 00:25:25.470
and then all of
these innovations

00:25:25.470 --> 00:25:27.240
started spiraling out of it.

00:25:27.240 --> 00:25:32.040
And a huge part of that was just
that everywhere else on campus

00:25:32.040 --> 00:25:35.280
and at every other university
at the time departments

00:25:35.280 --> 00:25:38.970
were just these serried rows of
offices, whereas in Building 20

00:25:38.970 --> 00:25:40.801
they were all smashed together.

00:25:40.801 --> 00:25:42.300
And now, of course,
we're completely

00:25:42.300 --> 00:25:45.090
used to the idea of having big
atriums where everyone can meet

00:25:45.090 --> 00:25:46.970
and open plan offices,
but at the time

00:25:46.970 --> 00:25:49.530
it was totally revolutionary.

00:25:49.530 --> 00:25:52.200
Really what I think it's about
is saying that they had all

00:25:52.200 --> 00:25:56.160
of these amazing people
on campus anyway,

00:25:56.160 --> 00:25:59.270
but just simply by throwing
the arrangement around,

00:25:59.270 --> 00:26:02.880
you suddenly became
enormously generative.

00:26:02.880 --> 00:26:04.950
And that's all it
took to spark all

00:26:04.950 --> 00:26:06.870
of these different sort
of micro revolutions

00:26:06.870 --> 00:26:10.480
in various disciplines.

00:26:10.480 --> 00:26:13.530
And it's also how we
arrange and present things.

00:26:13.530 --> 00:26:17.520
So this is a map that was
done in the mid-19th century

00:26:17.520 --> 00:26:20.820
and it's been called by some
graphic designers the best

00:26:20.820 --> 00:26:22.290
visualization in history.

00:26:22.290 --> 00:26:25.710
It's really kind of the
first data visualization.

00:26:25.710 --> 00:26:29.250
And what it shows is
Napoleon's Grand Army marching

00:26:29.250 --> 00:26:31.560
to Moscow and then back.

00:26:31.560 --> 00:26:35.940
So the marching to Moscow
is the kind of beige line,

00:26:35.940 --> 00:26:39.990
and back is the black line,
and the thickness of the line

00:26:39.990 --> 00:26:42.960
tells you the size of the Army.

00:26:42.960 --> 00:26:45.720
So you really see
just in a second

00:26:45.720 --> 00:26:48.970
how disastrous this
whole campaign was.

00:26:48.970 --> 00:26:51.660
But what he did was
clever in that all of this

00:26:51.660 --> 00:26:55.830
was based on tables of
data that people had found,

00:26:55.830 --> 00:26:58.550
and obviously in France it
was a major national sort

00:26:58.550 --> 00:26:59.880
of catastrophe.

00:26:59.880 --> 00:27:03.859
Looking at just tables of
data and time sequences,

00:27:03.859 --> 00:27:05.400
there were six
different metrics that

00:27:05.400 --> 00:27:07.440
are actually displayed here.

00:27:07.440 --> 00:27:09.207
No one really got it.

00:27:09.207 --> 00:27:11.040
Simply by changing the
arrangement of it all

00:27:11.040 --> 00:27:13.020
and putting it in
visual form, bam,

00:27:13.020 --> 00:27:16.900
you suddenly realized
this is a disaster.

00:27:16.900 --> 00:27:19.560
So again, that's about how
we arrange information.

00:27:19.560 --> 00:27:24.390
So selecting, hugely
important, expert selections.

00:27:24.390 --> 00:27:25.470
That's what curation is.

00:27:25.470 --> 00:27:29.119
It's not just choosing
things willy-nilly.

00:27:29.119 --> 00:27:30.660
It's about really
knowing what you're

00:27:30.660 --> 00:27:34.260
on about, and then arranging
it in powerful new ways

00:27:34.260 --> 00:27:36.150
to bring out the most.

00:27:36.150 --> 00:27:38.370
This is all where
the value lies.

00:27:41.500 --> 00:27:43.510
And then quite often
I'll spend a lot

00:27:43.510 --> 00:27:45.520
of time talking
about the internet,

00:27:45.520 --> 00:27:49.630
but I sort of feel like too much
of an idiot to come to Google

00:27:49.630 --> 00:27:51.880
and lecture you guys
about the internet.

00:27:51.880 --> 00:27:55.930
So I won't spend too
long talking about it.

00:27:55.930 --> 00:27:58.660
But the way I think
about curation on the web

00:27:58.660 --> 00:28:00.480
is that there's a
curation layer which

00:28:00.480 --> 00:28:03.510
would fit into the
overall scheme of layers.

00:28:03.510 --> 00:28:05.560
And at times it's
very thin, and that's

00:28:05.560 --> 00:28:07.420
where you might have some--

00:28:07.420 --> 00:28:09.640
a page has been
indexed and that's it.

00:28:09.640 --> 00:28:13.172
It is kind of curated in a
sense, but in a very thin way.

00:28:13.172 --> 00:28:15.130
And then you have portions
of the internet that

00:28:15.130 --> 00:28:17.350
are very exhaustively curated.

00:28:17.350 --> 00:28:18.100
If you've got a--

00:28:18.100 --> 00:28:20.860
let's say a blues
fan who runs a blog

00:28:20.860 --> 00:28:24.400
on a website about the blues
where he reviews one CD a week

00:28:24.400 --> 00:28:26.650
and writes a huge essay
about that, that's

00:28:26.650 --> 00:28:28.960
kind of thickly curated
portion of the web

00:28:28.960 --> 00:28:31.990
because it has all of
the automated parts

00:28:31.990 --> 00:28:34.990
and yet it also would have a
very kind of personal aspect

00:28:34.990 --> 00:28:36.710
as well.

00:28:36.710 --> 00:28:39.790
And I think a really big
theme of the past few years,

00:28:39.790 --> 00:28:42.850
of course, has been about
the rise of machine learning

00:28:42.850 --> 00:28:45.280
and how important that is
and algorithmic curation,

00:28:45.280 --> 00:28:47.200
and obviously Google is--

00:28:47.200 --> 00:28:50.410
of any organization in the
world is probably really

00:28:50.410 --> 00:28:53.290
at the forefront of that.

00:28:53.290 --> 00:28:56.200
And of course, I think that
is absolutely essential, given

00:28:56.200 --> 00:28:58.960
the datasets we have
in almost every area,

00:28:58.960 --> 00:29:00.520
you need algorithmic curation.

00:29:00.520 --> 00:29:03.820
You need things that
can be automated.

00:29:03.820 --> 00:29:07.330
But to me, that doesn't
imply that the human role

00:29:07.330 --> 00:29:08.410
is completely redundant.

00:29:08.410 --> 00:29:12.640
Actually for me they really
complement each other well.

00:29:12.640 --> 00:29:15.840
And we see that-- let's go
back to the music example.

00:29:15.840 --> 00:29:19.480
You go on Spotify, there'll be
huge numbers of algorithmically

00:29:19.480 --> 00:29:20.890
curated playlists.

00:29:20.890 --> 00:29:23.350
Then they'll also have
a deejay or an artist

00:29:23.350 --> 00:29:25.510
who'll put together a playlist.

00:29:25.510 --> 00:29:27.936
You're interested in both
actually because sometimes you

00:29:27.936 --> 00:29:29.560
just want to know
what somebody thinks,

00:29:29.560 --> 00:29:32.890
and there's a kind of
personal human story there.

00:29:32.890 --> 00:29:36.340
Actually if we want to
do things as individuals,

00:29:36.340 --> 00:29:39.820
we have to rely on the
machine learning element.

00:29:39.820 --> 00:29:41.650
We can't just do
everything blind,

00:29:41.650 --> 00:29:46.120
but sometimes our own input on
top of that is also important.

00:29:46.120 --> 00:29:48.240
So for me the future of
curation on the internet

00:29:48.240 --> 00:29:53.500
is these kind of intricate
blends of human and machine.

00:29:53.500 --> 00:29:55.090
And what I actually
think is amazing

00:29:55.090 --> 00:29:57.790
is how a lot of the
work that goes on here

00:29:57.790 --> 00:30:00.160
is about enabling that and
providing tools for people

00:30:00.160 --> 00:30:04.290
to do that and providing
the underpinning of it.

00:30:04.290 --> 00:30:08.770
I guess the last point that I
would make is about how to me

00:30:08.770 --> 00:30:13.360
it's the more thickly curated
areas of the internet that

00:30:13.360 --> 00:30:15.340
are getting more
attraction, and I

00:30:15.340 --> 00:30:19.240
think you look at something
like Twitter and for a long time

00:30:19.240 --> 00:30:21.280
it was very uncurated
in the sense

00:30:21.280 --> 00:30:22.920
that it was just a
fire hose of tweets.

00:30:22.920 --> 00:30:25.930
And a big part of their strategy
over the past few years,

00:30:25.930 --> 00:30:27.550
trying to become more curated.

00:30:27.550 --> 00:30:30.160
That's why it lodged
moments and has

00:30:30.160 --> 00:30:32.440
put in all kinds of
features to basically make

00:30:32.440 --> 00:30:35.620
itself a more curated
space, with varying

00:30:35.620 --> 00:30:38.380
degrees of success.

00:30:38.380 --> 00:30:40.600
And again, like
news, all of this

00:30:40.600 --> 00:30:43.130
is now such a hot button topic.

00:30:43.130 --> 00:30:44.650
It's just not going to go away.

00:30:44.650 --> 00:30:47.290
There are just too many
things at stake now in

00:30:47.290 --> 00:30:50.590
how we curate our news
and our information

00:30:50.590 --> 00:30:53.420
and who says what
about what and how.

00:30:53.420 --> 00:30:55.810
And I think last year
that's what we saw.

00:30:59.580 --> 00:31:06.380
Just sort of before wrapping up,
I think this whole sort of idea

00:31:06.380 --> 00:31:10.940
really goes very deep, and
it really changes how we live

00:31:10.940 --> 00:31:13.220
and how we experience the world.

00:31:13.220 --> 00:31:17.960
So go back 50 years or
60, 70 years and people

00:31:17.960 --> 00:31:21.170
had fairly set identities.

00:31:21.170 --> 00:31:23.480
If you were an
accountant, you probably

00:31:23.480 --> 00:31:26.105
wouldn't look like and do
the same things as a punk.

00:31:28.220 --> 00:31:33.440
People had kind of a clear
life world that they lived in.

00:31:33.440 --> 00:31:37.910
Now it's much more confused, and
a very concrete example of that

00:31:37.910 --> 00:31:39.320
is holidays.

00:31:39.320 --> 00:31:43.310
So in the '60s, '70s,
'80s, the package holiday

00:31:43.310 --> 00:31:46.100
grew up as a huge
thing in tourism,

00:31:46.100 --> 00:31:47.990
and tourism is a
massive industry.

00:31:47.990 --> 00:31:50.210
One in 11 jobs
around the world is

00:31:50.210 --> 00:31:53.810
based on the tourism industry.

00:31:53.810 --> 00:31:57.050
And most of that was
in package holidays.

00:31:57.050 --> 00:32:01.100
Today package holiday providers
are basically out of business.

00:32:01.100 --> 00:32:05.010
Almost no one really wants to
go on package holidays anymore.

00:32:05.010 --> 00:32:08.570
Instead people want very
bespoke experiences.

00:32:08.570 --> 00:32:11.060
People want to go
to an ashram one day

00:32:11.060 --> 00:32:13.730
and then go to a
festival the next day

00:32:13.730 --> 00:32:18.030
and then maybe go to some
kind of unique extreme sports

00:32:18.030 --> 00:32:19.970
event another day.

00:32:19.970 --> 00:32:22.970
So what's really taken
over from the old travel

00:32:22.970 --> 00:32:24.950
agents are these
holiday designers,

00:32:24.950 --> 00:32:28.670
who essentially will kind
of curate your experiences.

00:32:28.670 --> 00:32:30.950
And that's really how we
approach our own identities

00:32:30.950 --> 00:32:32.660
in our own lives as well.

00:32:32.660 --> 00:32:36.650
It's not the case that we
just do one set of things.

00:32:36.650 --> 00:32:39.740
Actually we might go to
the football one day,

00:32:39.740 --> 00:32:43.750
Glastonbury the next day, and
then the opera the next day.

00:32:43.750 --> 00:32:46.730
We're able to mix and match
experiences, cuisines,

00:32:46.730 --> 00:32:47.900
and so on.

00:32:47.900 --> 00:32:51.910
We sort of have become curators
of our own lives in some sense,

00:32:51.910 --> 00:32:55.370
and it always sounds a
bit ridiculous to say it,

00:32:55.370 --> 00:32:57.530
and yet I think there is
a kind of element of truth

00:32:57.530 --> 00:33:00.800
and that's how people tend
to approach what they do

00:33:00.800 --> 00:33:01.550
and how they live.

00:33:04.240 --> 00:33:07.850
Anyway, the real message,
I guess, of the book

00:33:07.850 --> 00:33:13.580
is very simply this, that
in our world of excess,

00:33:13.580 --> 00:33:15.500
where we have too much--

00:33:15.500 --> 00:33:17.090
obviously on the
internet we just

00:33:17.090 --> 00:33:21.410
have too much of literally
every single thing--

00:33:21.410 --> 00:33:25.610
value shifts to where
things are more curated.

00:33:25.610 --> 00:33:28.580
The more that is produced,
the more that is true.

00:33:28.580 --> 00:33:31.790
And every single year more
and more is just produced.

00:33:31.790 --> 00:33:34.430
So to me it's the
individuals and businesses

00:33:34.430 --> 00:33:38.420
and business models that
can capture that that really

00:33:38.420 --> 00:33:40.190
have a good future.

00:33:40.190 --> 00:33:43.760
And it's worth saying on that
point about business models,

00:33:43.760 --> 00:33:46.880
rarely is curation
itself a business model.

00:33:46.880 --> 00:33:50.420
You don't go into, let's say,
a very high-end fashion store--

00:33:50.420 --> 00:33:52.340
they don't make their
money through curation.

00:33:52.340 --> 00:33:55.370
They make their money
through selling clothes.

00:33:55.370 --> 00:33:58.430
But in order for them to
sell clothes effectively

00:33:58.430 --> 00:34:02.510
in our contemporary environment,
curation is essential.

00:34:02.510 --> 00:34:04.580
So it's kind of folded
into businesses,

00:34:04.580 --> 00:34:09.960
it's folded into our world,
for better or for worse.

00:34:09.960 --> 00:34:13.770
I think probably for the better,
but you can make up your mind.

00:34:13.770 --> 00:34:15.109
Thank you.

00:34:15.109 --> 00:34:20.224
[APPLAUSE]

00:34:20.224 --> 00:34:22.230
SPEAKER: If anyone has
questions, we have time.

00:34:22.230 --> 00:34:23.440
I will open with one.

00:34:23.440 --> 00:34:27.120
What areas-- what businesses do
you think are more ripe for--

00:34:27.120 --> 00:34:28.580
I hate the word disruption.

00:34:28.580 --> 00:34:31.530
It's overused, but curation?

00:34:31.530 --> 00:34:34.560
MICHAEL BHASKAR: Well,
so I think we're already

00:34:34.560 --> 00:34:36.960
seeing that the
whole world of retail

00:34:36.960 --> 00:34:42.570
is being, as I said, totally
divergent into those who

00:34:42.570 --> 00:34:45.090
are curated and those
who aren't, and those

00:34:45.090 --> 00:34:49.080
who aren't are basically
disappearing slowly.

00:34:49.080 --> 00:34:52.170
Anything that is
about producing stuff.

00:34:52.170 --> 00:34:55.710
So if you are a company that
is making programs or a company

00:34:55.710 --> 00:34:58.080
like mine that is
making books, if you

00:34:58.080 --> 00:35:01.850
don't have curation at the
heart of what you're doing,

00:35:01.850 --> 00:35:04.260
you're, I think, going
to be in trouble.

00:35:04.260 --> 00:35:07.470
For me, it's producers
that are people

00:35:07.470 --> 00:35:12.270
who really have the problem
these days, producers

00:35:12.270 --> 00:35:13.110
and sellers.

00:35:13.110 --> 00:35:16.980
Service companies
that can manage excess

00:35:16.980 --> 00:35:18.960
are much better placed.

00:35:18.960 --> 00:35:22.920
And so it's really just like a
huge, huge range of companies,

00:35:22.920 --> 00:35:25.680
and it all comes down
to the idea of if you

00:35:25.680 --> 00:35:28.480
look at almost any market
in the world today--

00:35:28.480 --> 00:35:31.880
if you look at the
market for bottled water

00:35:31.880 --> 00:35:34.680
or the market for books
or the market for pens,

00:35:34.680 --> 00:35:36.870
it's not like there's
a shortage of them.

00:35:36.870 --> 00:35:37.710
You can go and buy--

00:35:37.710 --> 00:35:39.210
if you want to get
any-- if you want

00:35:39.210 --> 00:35:42.630
to start a new business
producing pens,

00:35:42.630 --> 00:35:44.040
you really won't
have any success

00:35:44.040 --> 00:35:45.780
because it is a
saturated market.

00:35:45.780 --> 00:35:48.000
There's really
not a lot of room.

00:35:48.000 --> 00:35:50.490
So anything that's
about producing

00:35:50.490 --> 00:35:54.030
is working in the context
of a saturated market,

00:35:54.030 --> 00:35:56.490
and it's unlikely
that you can just

00:35:56.490 --> 00:36:00.330
continue to kind of grind out
more and more and more, whereas

00:36:00.330 --> 00:36:03.390
to me anything that can
make things easier--

00:36:03.390 --> 00:36:05.760
if you were to do
something with pens,

00:36:05.760 --> 00:36:08.460
you'd say, right,
actually what's

00:36:08.460 --> 00:36:12.240
the best possible pen you
can buy for this price?

00:36:12.240 --> 00:36:13.524
That's probably what you do.

00:36:13.524 --> 00:36:14.940
SPEAKER: Do you
think that puts us

00:36:14.940 --> 00:36:17.070
in a place where the
best curators will

00:36:17.070 --> 00:36:19.731
become monopolies?

00:36:19.731 --> 00:36:23.620
MICHAEL BHASKAR: I'm
often asked that.

00:36:23.620 --> 00:36:28.690
Yes, and yes in the
sense that it's possible,

00:36:28.690 --> 00:36:32.200
and there's certainly a lot
of tendency towards that.

00:36:32.200 --> 00:36:35.860
No, in the sense that
there's no such thing

00:36:35.860 --> 00:36:37.505
as an absolute best curation.

00:36:39.861 --> 00:36:42.110
And this is where I think
you get into this question--

00:36:42.110 --> 00:36:48.040
obviously in terms of automated,
it would tend towards being one

00:36:48.040 --> 00:36:49.815
platform dominance, but that's--

00:36:49.815 --> 00:36:51.440
actually we always
want something more.

00:36:51.440 --> 00:36:53.530
We want something
idiosyncratic at the same time,

00:36:53.530 --> 00:36:54.960
and that that's counter to that.

00:37:02.280 --> 00:37:07.590
AUDIENCE: Is there a space
or a certain business model

00:37:07.590 --> 00:37:10.260
or something that you think
should never be curated,

00:37:10.260 --> 00:37:12.720
that's kind of left
sacred and separate

00:37:12.720 --> 00:37:17.172
and shouldn't be-- for ethical
reasons or anything else?

00:37:17.172 --> 00:37:19.922
MICHAEL BHASKAR: Actually
no, I can't think of one

00:37:19.922 --> 00:37:20.880
off the top of my head.

00:37:20.880 --> 00:37:24.030
Maybe you have an idea of
what you'd be thinking,

00:37:24.030 --> 00:37:29.160
but to me good curation-- having
a kind of ethical component,

00:37:29.160 --> 00:37:32.730
is part of what good
curation should be about.

00:37:32.730 --> 00:37:36.210
So expertise is one thing I
think good curation needs.

00:37:36.210 --> 00:37:40.656
It has to come from a deep level
of knowledge and understanding

00:37:40.656 --> 00:37:42.030
and an ethical
component as well.

00:37:42.030 --> 00:37:44.700
And I think-- actually
there's far more

00:37:44.700 --> 00:37:49.200
risk of kind of ethical
problems without curation.

00:37:49.200 --> 00:37:51.600
I think it's important--
it can be a really

00:37:51.600 --> 00:37:54.420
important ethical filter.

00:37:54.420 --> 00:37:57.480
And you just think
of, say, the internet

00:37:57.480 --> 00:38:01.320
and let's say on Facebook
there were no kind of curation

00:38:01.320 --> 00:38:04.710
mechanisms, it would just
be full of terrible things

00:38:04.710 --> 00:38:05.530
all the time.

00:38:05.530 --> 00:38:08.610
And actually a huge
amount of effort

00:38:08.610 --> 00:38:11.430
goes into making sure
that spaces like that

00:38:11.430 --> 00:38:13.890
aren't just full
of awful material.

00:38:13.890 --> 00:38:17.970
So to me almost every
area of the world

00:38:17.970 --> 00:38:23.520
can be made better and not
just in a superficial sense

00:38:23.520 --> 00:38:28.436
but ethically if it has
careful good curation of it.

00:38:28.436 --> 00:38:30.310
I'd love to know if
there is an area that you

00:38:30.310 --> 00:38:32.361
think wouldn't benefit.

00:38:32.361 --> 00:38:34.205
AUDIENCE: Dating.

00:38:34.205 --> 00:38:38.740
MICHAEL BHASKAR: Well, you
know, but even that, of course--

00:38:38.740 --> 00:38:42.580
the curation of dating has
become a huge industry,

00:38:42.580 --> 00:38:45.040
and yeah, maybe, maybe not.

00:38:45.040 --> 00:38:48.880
But I guess that's
something that yeah,

00:38:48.880 --> 00:38:52.180
it's interesting to think about
that because to some extent

00:38:52.180 --> 00:38:55.030
dating has always been
curated either by--

00:38:55.030 --> 00:38:57.550
in some societies by
your parents and others

00:38:57.550 --> 00:39:02.530
by your friends, now by Tinder.

00:39:02.530 --> 00:39:05.710
And so it's probably
always been the case

00:39:05.710 --> 00:39:08.710
that dating has been
curated to some extent.

00:39:08.710 --> 00:39:10.790
But maybe it would be
better if it wasn't.

00:39:10.790 --> 00:39:11.948
Potluck.

00:39:11.948 --> 00:39:13.900
SPEAKER: There's a
question behind you.

00:39:17.316 --> 00:39:20.300
AUDIENCE: My question is mostly
between balancing curation

00:39:20.300 --> 00:39:22.130
with scalability.

00:39:22.130 --> 00:39:25.910
So you kind of touched
that through the talk.

00:39:25.910 --> 00:39:28.310
I do-- I am passionate about
what they call curation

00:39:28.310 --> 00:39:29.684
and personalization
conversation,

00:39:29.684 --> 00:39:31.850
but at the same time, I
know that for some business

00:39:31.850 --> 00:39:35.510
it's not just feasible not to go
with the scalability approach.

00:39:35.510 --> 00:39:36.680
So what do you think is--

00:39:36.680 --> 00:39:38.820
what's the best way
to balance those two?

00:39:38.820 --> 00:39:43.070
Is it artificial intelligence
or data analysis?

00:39:43.070 --> 00:39:45.470
What kind of tools
and mechanisms

00:39:45.470 --> 00:39:48.140
do you think that companies
can use to balance those two

00:39:48.140 --> 00:39:49.310
approaches?

00:39:49.310 --> 00:39:51.020
MICHAEL BHASKAR:
So, yeah, I mean,

00:39:51.020 --> 00:39:53.270
the question about
scalability really comes

00:39:53.270 --> 00:39:57.410
about building really good
automated systems, and yeah,

00:39:57.410 --> 00:40:02.030
of course, then that's now about
really sophisticated AI machine

00:40:02.030 --> 00:40:02.990
learning techniques.

00:40:02.990 --> 00:40:07.020
And so you think
about music, just

00:40:07.020 --> 00:40:09.350
to come back to
that, or books, I

00:40:09.350 --> 00:40:11.930
interviewed the guy who wrote
the first recommendation

00:40:11.930 --> 00:40:15.350
algorithm for Amazon,
and that actually

00:40:15.350 --> 00:40:19.180
made some important advances
in machine learning at the time

00:40:19.180 --> 00:40:20.960
and now is in many
ways the template

00:40:20.960 --> 00:40:25.810
for a lot of subsequent
recommendation systems.

00:40:25.810 --> 00:40:30.200
And that is about just having
a really deep understanding

00:40:30.200 --> 00:40:32.930
of how that kind
of dataset works.

00:40:32.930 --> 00:40:35.660
So Spotify bought a company
called the Echo Nest,

00:40:35.660 --> 00:40:39.000
which was a spin-out from
MIT, and they developed

00:40:39.000 --> 00:40:41.360
the technique of
audio fingerprinting,

00:40:41.360 --> 00:40:43.760
which can look at songs
in kind of really good--

00:40:43.760 --> 00:40:47.000
really incredible detail and
then abstract that information

00:40:47.000 --> 00:40:51.700
and then use it to find
other similar songs.

00:40:51.700 --> 00:40:55.570
And it's that kind of-- that
was a group of pure research

00:40:55.570 --> 00:40:57.940
scientists working
over the course

00:40:57.940 --> 00:40:59.800
of their PhDs and
their post-docs

00:40:59.800 --> 00:41:02.620
to develop that software.

00:41:02.620 --> 00:41:04.570
And then you use that
and then you give that

00:41:04.570 --> 00:41:06.520
to a bunch of deejays.

00:41:06.520 --> 00:41:09.580
So let's say you've got 30
million songs in the catalog.

00:41:09.580 --> 00:41:12.460
You can use Echo Nest
software to build

00:41:12.460 --> 00:41:15.320
you a list of 1,000
songs, and then you

00:41:15.320 --> 00:41:17.830
get some deejays who are
just sort of totally immersed

00:41:17.830 --> 00:41:19.870
in that world to
narrow that down

00:41:19.870 --> 00:41:22.030
into a playlist of 20 songs.

00:41:22.030 --> 00:41:24.820
That's a kind of scalable
solution and also

00:41:24.820 --> 00:41:27.730
a personal solution,
and both sides of it

00:41:27.730 --> 00:41:30.250
come out of having a very
deep understanding of what's

00:41:30.250 --> 00:41:30.830
going on.

00:41:30.830 --> 00:41:34.450
So for me on the
engineering side,

00:41:34.450 --> 00:41:38.620
it is about just the same level
of expertise, more expertise

00:41:38.620 --> 00:41:43.250
potentially, and using every
single tool in the armory.

00:41:43.250 --> 00:41:46.750
So all-- any kind
of, yeah, evolution

00:41:46.750 --> 00:41:52.780
of software or techniques
and so on should be deployed.

00:41:58.184 --> 00:41:59.600
AUDIENCE: I was
just going to say,

00:41:59.600 --> 00:42:01.237
is there a risk in
curation that you

00:42:01.237 --> 00:42:03.320
are narrowing the field
of what people get to see?

00:42:03.320 --> 00:42:05.840
I think the word echo chamber
was being thrown around

00:42:05.840 --> 00:42:08.417
last year on Facebook,
you see the same things.

00:42:08.417 --> 00:42:10.250
If you're curating to
the extent that you're

00:42:10.250 --> 00:42:11.666
narrowing something,
you don't get

00:42:11.666 --> 00:42:13.930
to see a multiple
number of views.

00:42:13.930 --> 00:42:14.930
Is there a risk in that?

00:42:14.930 --> 00:42:16.350
MICHAEL BHASKAR:
Yeah, definitely,

00:42:16.350 --> 00:42:20.220
and that comes back to the
whole idea of the echo chamber

00:42:20.220 --> 00:42:22.610
of the filter bubble.

00:42:22.610 --> 00:42:26.090
And right now I'm experiencing
the filter bubble every day

00:42:26.090 --> 00:42:30.470
when I go on my Twitter feed,
and if you look at my Twitter

00:42:30.470 --> 00:42:31.956
feed, then there's
only one party

00:42:31.956 --> 00:42:33.330
that's going to
win the election,

00:42:33.330 --> 00:42:36.050
and it's not the conservatives.

00:42:36.050 --> 00:42:38.660
And that may not be
an accurate reflection

00:42:38.660 --> 00:42:40.160
of what's really going on.

00:42:40.160 --> 00:42:42.740
And so that's a huge
risk, and this is to me

00:42:42.740 --> 00:42:47.180
where it comes down to making
a bit of a finer distinction

00:42:47.180 --> 00:42:48.950
between good and bad curation.

00:42:48.950 --> 00:42:54.020
And this I think is actually
the biggest challenge for big

00:42:54.020 --> 00:42:57.890
curators, major curators,
like Google, like Facebook,

00:42:57.890 --> 00:43:02.300
big tech platforms is-- good
curation I think should be able

00:43:02.300 --> 00:43:05.630
to break out of echo chambers
and filter bubbles and should

00:43:05.630 --> 00:43:07.670
be able to--

00:43:07.670 --> 00:43:09.890
at the same time as
reflecting our world

00:43:09.890 --> 00:43:12.770
in terms of our groups
and our beliefs,

00:43:12.770 --> 00:43:14.780
should also be able
to remind us sometimes

00:43:14.780 --> 00:43:16.820
of the context in
which they work.

00:43:16.820 --> 00:43:22.250
And good curation is the
antidote to filter bubbles,

00:43:22.250 --> 00:43:25.310
yet they are driven themselves
by curation mechanisms.

00:43:25.310 --> 00:43:27.460
But they are bad
ones, if you ask me.

00:43:27.460 --> 00:43:31.670
So I think the real challenge
for the next few years

00:43:31.670 --> 00:43:38.270
is to find ways to build good
curation into our systems

00:43:38.270 --> 00:43:39.750
more than it currently is.

00:43:39.750 --> 00:43:44.630
And I don't really know
how that's possible.

00:43:44.630 --> 00:43:47.540
I'm sure there are a lot of
really, really smart people

00:43:47.540 --> 00:43:50.680
thinking about it, but yeah.

00:43:50.680 --> 00:43:53.000
And actually, if I
wrote the book again,

00:43:53.000 --> 00:43:56.090
I'd almost just spend all of
it talking about that question

00:43:56.090 --> 00:44:00.680
because I think we saw last year
so many times everyone was just

00:44:00.680 --> 00:44:04.700
stuck sort of mercilessly in
their own well that was just

00:44:04.700 --> 00:44:06.620
being reflected back on them.

00:44:06.620 --> 00:44:09.890
You turn up on a news
home page and it's

00:44:09.890 --> 00:44:13.070
just stories like stories that
you've clicked on in the past.

00:44:13.070 --> 00:44:14.840
So it is curating.

00:44:14.840 --> 00:44:15.980
But is that good?

00:44:15.980 --> 00:44:17.930
Is it being done well?

00:44:17.930 --> 00:44:20.890
Probably not.

00:44:20.890 --> 00:44:23.260
SPEAKER: Any more questions?

00:44:23.260 --> 00:44:23.966
One in the back.

00:44:26.822 --> 00:44:29.220
AUDIENCE: It seems
like you see curation

00:44:29.220 --> 00:44:33.360
as a combination of
saying you will like this

00:44:33.360 --> 00:44:35.040
and you should like this.

00:44:35.040 --> 00:44:37.140
You talk about the example
of the museum curator,

00:44:37.140 --> 00:44:39.040
but then Netflix.

00:44:39.040 --> 00:44:41.490
Do you see them as kind of
part of the same process,

00:44:41.490 --> 00:44:43.290
or are there some
places where one is more

00:44:43.290 --> 00:44:44.465
appropriate than the other?

00:44:44.465 --> 00:44:48.660
MICHAEL BHASKAR: So I
definitely think that both are--

00:44:48.660 --> 00:44:52.920
both are part of it.

00:44:52.920 --> 00:44:59.570
I tend to think that, going back
to this idea of good curation,

00:44:59.570 --> 00:45:02.910
for me that's where you're
saying you should like this.

00:45:02.910 --> 00:45:06.410
And actually, if you think-- one
thing to think about in terms

00:45:06.410 --> 00:45:11.480
of what curation is search,
a basic search functionality

00:45:11.480 --> 00:45:16.340
is saying I want this, and
then search brings it for you.

00:45:16.340 --> 00:45:18.350
Curation is when
you don't even know

00:45:18.350 --> 00:45:22.850
what you want in the first place
and someone is like, ah, this.

00:45:22.850 --> 00:45:26.060
So it's kind of
that distinction.

00:45:26.060 --> 00:45:30.290
For me, it is both, and again,
you might say that on the--

00:45:30.290 --> 00:45:32.990
that you will like is perhaps
the more automated side.

00:45:32.990 --> 00:45:36.740
You should like is perhaps
the more subjective side.

00:45:36.740 --> 00:45:40.070
So I think it's totally
got elements of both.

00:45:40.070 --> 00:45:43.610
I think it's the should bit
that is more interesting, more

00:45:43.610 --> 00:45:47.330
tricky, more messy,
and probably ultimately

00:45:47.330 --> 00:45:48.817
will have more value add.

00:45:56.769 --> 00:45:59.140
AUDIENCE: And just come
back to the question of good

00:45:59.140 --> 00:46:02.890
versus bad curation, and is
the issue that there's nobody

00:46:02.890 --> 00:46:04.510
to pay for the good curation?

00:46:04.510 --> 00:46:07.060
So if we can take
the politics example,

00:46:07.060 --> 00:46:10.030
I'm not sure who's going to
pay to give you a balanced book

00:46:10.030 --> 00:46:13.570
curated view of what's
happening, whereas if I think

00:46:13.570 --> 00:46:16.030
I'm going to win the election
and it's profitable for me

00:46:16.030 --> 00:46:20.440
to pay the [INAUDIBLE] gets
the right people to vote,

00:46:20.440 --> 00:46:22.460
then I pay for the bad curation.

00:46:22.460 --> 00:46:27.220
MICHAEL BHASKAR: I think
that is probably exactly it.

00:46:27.220 --> 00:46:33.350
And if you're a shop and
you curate really well,

00:46:33.350 --> 00:46:35.980
you hope that means that gives
you a competitive advantage

00:46:35.980 --> 00:46:38.190
that more people will
come into your shop,

00:46:38.190 --> 00:46:40.090
and that is indeed
what we are seeing

00:46:40.090 --> 00:46:42.670
across the retail sector.

00:46:42.670 --> 00:46:47.620
As a publisher, we spend so
much time at my company thinking

00:46:47.620 --> 00:46:50.147
about what books to
publish, and actually we're

00:46:50.147 --> 00:46:50.980
a digital publisher.

00:46:50.980 --> 00:46:53.560
We can publish thousands
of books every year,

00:46:53.560 --> 00:46:56.230
but we really limit it to
very few because we want those

00:46:56.230 --> 00:46:57.820
to be really
meaningful and to have

00:46:57.820 --> 00:47:00.520
really good chances of success
and to catch an audience.

00:47:00.520 --> 00:47:01.960
So both those
cases I think there

00:47:01.960 --> 00:47:07.510
is a kind of clear confluence
of a business imperative

00:47:07.510 --> 00:47:09.880
and a kind of
curation imperative.

00:47:09.880 --> 00:47:14.390
But on the internet, I
don't see that at all.

00:47:14.390 --> 00:47:16.210
And actually, what
you want is just

00:47:16.210 --> 00:47:19.960
to kind of get and
retain traffic and keep

00:47:19.960 --> 00:47:21.520
users interested.

00:47:21.520 --> 00:47:24.610
And if that's just serving
people up their own opinions

00:47:24.610 --> 00:47:27.730
again and again and again until
they believe that is a total

00:47:27.730 --> 00:47:31.980
reflection of the world,
it's-- yeah, it's non-aligned.

00:47:31.980 --> 00:47:34.780
Actually, I've even
wondered whether maybe there

00:47:34.780 --> 00:47:36.940
needs to be some
kind of regulation

00:47:36.940 --> 00:47:38.830
about how news is displayed.

00:47:38.830 --> 00:47:41.740
On television news,
for example, you

00:47:41.740 --> 00:47:44.005
can't just report with
total bias in this country.

00:47:44.005 --> 00:47:46.270
There are very kind of
strict controls on what you

00:47:46.270 --> 00:47:47.770
can say on the television news.

00:47:47.770 --> 00:47:50.900
Maybe that's ridiculous,
but I certainly

00:47:50.900 --> 00:47:54.820
would agree that the
payment mechanism

00:47:54.820 --> 00:48:02.310
for good curation in some
contexts really isn't that.

00:48:02.310 --> 00:48:04.580
Although if you look at--

00:48:04.580 --> 00:48:09.230
Google has managed to find
some brilliant ways of actually

00:48:09.230 --> 00:48:12.020
aligning good curation with
the business model of ads

00:48:12.020 --> 00:48:15.760
that are themselves curated.

00:48:15.760 --> 00:48:20.000
So maybe there is a model,
but I don't know what it is.

00:48:20.000 --> 00:48:24.220
I'm sure somebody at Google
can and will figure it out,

00:48:24.220 --> 00:48:25.210
but it's a tricky one.

00:48:28.000 --> 00:48:28.930
SPEAKER: Great.

00:48:28.930 --> 00:48:31.022
With that, please join
me in a round of applause

00:48:31.022 --> 00:48:31.720
for Michael Bhaskar.

00:48:31.720 --> 00:48:32.550
MICHAEL BHASKAR:
Thank you very much.

00:48:32.550 --> 00:48:33.549
Thank you for having me.

00:48:33.549 --> 00:48:35.900
[APPLAUSE]

