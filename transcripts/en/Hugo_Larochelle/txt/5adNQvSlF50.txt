Speaker 1:          00:00          In this video, we'll start, uh, uh, investigating how we can train neural networks. And a four that we'll look at the main principle behind training neural networks, uh, which is known as empirical risk minimization. Now we've seen the mathematical, a derivation or mathematical expression for what we mean by a multilayer neural network. Uh, and in this description there are these parameters which are for instance, the connections between the unions and the input layer. The first one there, the connections between the first and then layer in second hidden layer. Then the connections with, uh, between the Lassen in layer and the output layer as well as the bias vectors for each of the layers or the hidden layers and the output layer of the neural network. And so far we haven't talked about how we can actually, uh, find good values for these parameters such that on your own network will have the correct behavior, will solve our problem that we're trying to solve.

Speaker 1:          01:02          So, um, uh, what we'll see in this video in the following videos is how we can train a neural network to develop the right behavior to solve a given problem. One of the problem will often talk about them, we'll focus on is a problem classification. And a good problem to keep in mind when we're discussing a training neural network is one where we would have an image where there is a particular character, say a three in this example and a, and we'll assume that we have some data where someone has told us that for instance, for this image, this actually curse bonds to the character, uh, three. So we'll assume that we have some data where we have a, an input x and the associated target. Why that we must predict based on the input x and for a character prediction than x would be the a row wise vectorization of all the pixels in the image. That would be an example of an input to use an input representation for an image. Okay. So that's a good problem to keep in mind while we're talking about training neural networks.

Speaker 2:          02:07          Yeah.

Speaker 1:          02:08          So, uh, the specific algorithm that we'll be looking at for training neural network is going to be based on a very general principle in machine learning, uh, known as empirical risk minimization. So in a nutshell, the ideas that will convert the problem of training a neural network into an optimization problem. Um, so I'm going to call [inaudible] the set of all my parameters in a given model in, in my, uh, the case were interesting. Uh, Tara is going to be the, all the parameters in the connection matrices, the WWE matrices as well as the bias vectors be, uh, for each, uh, for all the different layers. I also note x t as the teeth, a training example. In some set of training images we'll use for, uh, to train on neural network. So XD here is a vector and his DTF input vector in my training set.

Speaker 1:          03:08          And then why tea is the associated. So the TF label a or target, they have to predict based on x. So again, x t could be an image of a character and why it could be the categories associated with that character. So in empirical risk minimization, we'll frame the problem of learning or training a model as the problem of finding the parameters which minimized this objective. Here, this objective has two parts. The first part is the average of a loss function l that compares the output of my neural network with the expected or the correct answer. Yt Okay. Al is going to be what is known as a loss function and it compares the output with the label. And also I'm going to add a term or mega data which is known as irregular riser. And what it does is that it penalizes certain values of data, certain values of my parameter, which uh, for some reason we think are not good values that will not work well On.

Speaker 1:          04:20          Uh, uh, when we try to solve, uh, problems on new images, say on new examples. And then we have a parameter here, lambda, which is going to be hyper parameter, which is going to control the, uh, a balance between optimizing the average loss and uh, optimizing the regularization burglarized or function. So here, because we have this argument, really we're converting our problem into an optimization problem, we're trying to minimize a particular objective. Ideally we'd like to optimize classification error if we're doing classification. So we'd like to optimize the actual percentage of errors that our model is, uh, makes on the training set. Howard, this function is not as smooth function. Uh, so, uh, if we wanted to optimize the number of times that the, uh, outputs class by our model, which is the class which is associated with the biggest probability based on the output probability given by our neural network.

Speaker 1:          05:27          So the number of times at this, the most likely class according to our model is wrong. This is actually a function which is a not smooth. So it essentially looks something like this where this is when we have an error of zero, when we have, uh, uh, where the correct class as the most, the highest probability. And then we have an error one when the correct class as doesn't have the highest probability. So this function, which looks like this is not smooth. So it's a, it's a very hard function to, uh, to optimize. So instead what we do is we usually use a loss function, which is going to be a surrogate of what we truly want to optimize. So, for instance, we might try to actually upper bound the real thing that we aren't optimized with something smooth. Uh, and uh, so you know, if we could somehow take this, uh, functions, they are lost function and look like this and have a smooth version which may be looked like this, then we might try to optimize this as well and hope that, uh, you know, because this is fairly close to that, then we are sort of optimizing the real thing.

Speaker 1:          06:33          Okay. And, uh, so this is the general principle for empirical risk minimization that we'll try to follow when training neural networks.

Speaker 1:          06:43          And because we've cast it our problem as an optimization problem, what's great is that we can leverage optimization algorithms from the optimization literature. And the one algorithm that will, uh, focus on is these stochastic gradient descent algorithm. And this is not going, you've probably seen if you've taken a machine learning class. So I'll just briefly describe it here. Um, so what the algorithm does is at first it initializes the parameters of our neural networks. So all the connections and biases in our neural network in some way, often it's initialized randomly. And then for a son, a number of iterations with we have to specify, we have to specify end here. What we'll do is that will iterate over our training set and for each training example, each pair x, t, y, t we'll figure out a direction, uh, that we'll explore for a that will consider for updating our parameters and send then and natural direction to use for a given training example is the opposite direction of the gradient of the loss and, uh, plus the gradient of the irregular riser.

Speaker 1:          07:54          So we go in the opposite directions who have a minus here. So remember that the gradient is telling us in what directions do, uh, I do, I get the biggest increase if I change a certain number of variables. So if I take my loss plus my regular riser, if I think the great end of that, then this will give me in which direction they, I think the grain in retrospect to my parameter. This gives me the direction in which if I changed my, if I increase a, oh, sorry, if I follow this direction in changing my parameter, I'm getting, I'm going to get the biggest increase in the loss plus the way that regular riser. So if I go in the opposite direction, I should get the locally, the biggest decrease in the last plus my weighted regularized, sir. So I use that as my direction.

Speaker 1:          08:42          So that's going to be my direction, Delta. And then I'll just take my parameter and I updated by adding a step size or learning rate Alpha, which is another parameter. I have to specify a hyper parameter a times dis direction delta of four, updating my privater. So I'm taking one step into, in the direction that is locally most likely to decrease, that's going to decrease the most my, some of loss plus record riser for my training example. And so I repeat this operation here for each training example in my training set. And then I repeat this whole loop and times, which is the number of iterations, or sometimes we'll call that a number of training epoch, uh, uh, over all my, uh, training examples. Okay. So if we want to apply this general algorithm of stochastic gradient descent, I need the following items in this recipe.

Speaker 1:          09:43          I need to define my loss function. This function owl. I need the procedure for computing the gradients. Ideally, I want a procedure that's efficient because I'm going to, I'm going to do a lot of updates. I'm going to compute this term here. Often I need to choose a particular form for my regular riser. And given that form else, we'll need to compute the gradients with respect to, uh, have that regularize her with respect to my parameter ETA. And then also need to specify a way of initializing my parameters. So what we'll do in the next videos, and we'll go over all of these different items in this recipe so that we have all the items we need all the ingredients to applies to Casta great in the center and train the neural network.