WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.350
[MUSIC PLAYING]

00:00:05.957 --> 00:00:07.790
MATTHEW O. JACKSON: So,
why write this book?

00:00:07.790 --> 00:00:09.950
There is a lot of
regularity in the way

00:00:09.950 --> 00:00:11.900
that people are
organized and how

00:00:11.900 --> 00:00:14.030
that influences their outcomes.

00:00:14.030 --> 00:00:15.920
And in the book, I
sort of intertwine

00:00:15.920 --> 00:00:17.640
two different themes.

00:00:17.640 --> 00:00:20.880
One is that our networks
have special features.

00:00:20.880 --> 00:00:23.810
And those features are
simple and quantifiable.

00:00:23.810 --> 00:00:26.840
And the second is that they
have impacts on our lives.

00:00:26.840 --> 00:00:30.350
And the sort of topics
I include and discuss

00:00:30.350 --> 00:00:33.458
are things like influence--
how people are influenced.

00:00:33.458 --> 00:00:35.000
How do you define
influential people?

00:00:35.000 --> 00:00:37.910
And how does it
depend on the context?

00:00:37.910 --> 00:00:39.680
What kind of biases
do we have in forming

00:00:39.680 --> 00:00:43.260
opinions and beliefs?

00:00:43.260 --> 00:00:46.070
Things like contagion and
how financial contagions are

00:00:46.070 --> 00:00:48.770
different from a flu
contagion, things

00:00:48.770 --> 00:00:53.930
like how splits in our
networks feed polarization,

00:00:53.930 --> 00:00:56.270
feed inequality,
freedom mobility--

00:00:56.270 --> 00:00:59.630
and then how patterns
are changing over time.

00:00:59.630 --> 00:01:03.410
I'll just go through a
few illustrative examples.

00:01:03.410 --> 00:01:09.230
And what I want to start with
is just a simple picture.

00:01:09.230 --> 00:01:12.500
What I'm going to do is show
you a series of pictures.

00:01:12.500 --> 00:01:15.287
The first picture is one
of a fictional high school.

00:01:15.287 --> 00:01:17.370
And then I'm going to show
you a real high school.

00:01:17.370 --> 00:01:19.340
And what I want to do
is contrast the two.

00:01:19.340 --> 00:01:21.757
And then you'll be able to see
the patterns that typically

00:01:21.757 --> 00:01:22.257
emerge.

00:01:22.257 --> 00:01:23.924
So the high school
I'm going to show you

00:01:23.924 --> 00:01:26.140
is one from what's known
as the Add Health data set.

00:01:26.140 --> 00:01:30.980
And that data set
looks at high schools,

00:01:30.980 --> 00:01:33.350
and how people's
friendships form,

00:01:33.350 --> 00:01:34.820
and what patterns they take.

00:01:34.820 --> 00:01:36.320
And so what I've
done here is I've

00:01:36.320 --> 00:01:38.480
created a fictional
network, which

00:01:38.480 --> 00:01:40.730
is exactly the same as
the high school in terms

00:01:40.730 --> 00:01:43.710
of the number of students
and a number of friendships.

00:01:43.710 --> 00:01:45.260
But I randomly place
the friendships

00:01:45.260 --> 00:01:47.480
instead of putting
them in the structure

00:01:47.480 --> 00:01:49.210
that they appear
in the high school.

00:01:49.210 --> 00:01:50.960
And so I want to do
is just contrast that.

00:01:50.960 --> 00:01:53.210
So here, it just sort of
looks like a spaghetti bowl.

00:01:53.210 --> 00:01:54.450
There's a bunch of students.

00:01:54.450 --> 00:01:55.520
They're connected.

00:01:55.520 --> 00:01:57.198
And you don't see any patterns.

00:01:57.198 --> 00:01:59.240
And now I'm going to show
you a real high school.

00:01:59.240 --> 00:02:02.540
So this is a real high school
from the Add Health data set--

00:02:02.540 --> 00:02:04.340
255 students.

00:02:04.340 --> 00:02:06.860
And now you'll
notice that there's

00:02:06.860 --> 00:02:08.630
some patterns that emerge.

00:02:08.630 --> 00:02:13.260
And just in terms of contrast,
here everybody has friends.

00:02:13.260 --> 00:02:15.380
So there's no isolated nodes.

00:02:15.380 --> 00:02:18.360
When you get to this one,
there are some isolated nodes.

00:02:18.360 --> 00:02:21.500
So there's some students who
don't have close friendships.

00:02:21.500 --> 00:02:24.110
And these were
defined by people who

00:02:24.110 --> 00:02:26.450
did at least three different
activities in a given time

00:02:26.450 --> 00:02:28.350
period with each other.

00:02:28.350 --> 00:02:30.620
The other thing is that
I had an algorithm that

00:02:30.620 --> 00:02:31.790
drew this picture.

00:02:31.790 --> 00:02:33.230
So you'll notice
that there's sort

00:02:33.230 --> 00:02:34.938
of a split between
the top of the picture

00:02:34.938 --> 00:02:36.410
and the bottom of the picture.

00:02:36.410 --> 00:02:39.950
The top of the picture, you
have connections in a group.

00:02:39.950 --> 00:02:43.040
And the bottom of the picture
has connections in a group.

00:02:43.040 --> 00:02:46.200
And there's not many connections
across the two groups.

00:02:46.200 --> 00:02:48.530
So there's sort of a
split in this graph.

00:02:48.530 --> 00:02:50.750
And the algorithm that
drew this, what it does

00:02:50.750 --> 00:02:52.610
is it doesn't know
where to place things.

00:02:52.610 --> 00:02:54.920
It just looks, and
it picks two nodes.

00:02:54.920 --> 00:02:57.500
And if they're connected, it
pulls them closer together.

00:02:57.500 --> 00:02:59.792
If they're not connected, it
pushes them further apart.

00:02:59.792 --> 00:03:01.710
And it just does this
until you stop it.

00:03:01.710 --> 00:03:02.908
And so it goes.

00:03:02.908 --> 00:03:04.700
And it tries to find
the community patterns

00:03:04.700 --> 00:03:05.820
in the network.

00:03:05.820 --> 00:03:09.780
Now what I'm going to do
is take this and color it.

00:03:09.780 --> 00:03:12.600
And what I'm doing now
is coloring it by race.

00:03:12.600 --> 00:03:16.210
So the blue nodes
are black students.

00:03:16.210 --> 00:03:17.750
The yellow nodes
are white students.

00:03:17.750 --> 00:03:19.637
The red nodes are
Hispanic students.

00:03:19.637 --> 00:03:22.220
And now you'll begin to notice
that there's strong segregation

00:03:22.220 --> 00:03:23.570
patterns in this network.

00:03:23.570 --> 00:03:26.810
Basically, there's only, I
think, three strong friendships

00:03:26.810 --> 00:03:30.590
between blacks and whites
in the whole high school.

00:03:30.590 --> 00:03:33.440
And you'll see that it's
a strongly segregated

00:03:33.440 --> 00:03:35.060
across racial lines.

00:03:35.060 --> 00:03:37.310
And that's even despite the
fact that this high school

00:03:37.310 --> 00:03:40.598
looks well-integrated in
terms of the composition

00:03:40.598 --> 00:03:41.390
of the high school.

00:03:41.390 --> 00:03:42.380
So you've got a
high school where

00:03:42.380 --> 00:03:43.820
you think is well-integrated.

00:03:43.820 --> 00:03:47.090
But if you look internally,
it's completely segregated.

00:03:47.090 --> 00:03:49.073
Here's another picture.

00:03:49.073 --> 00:03:50.240
This is another high school.

00:03:50.240 --> 00:03:52.400
But now it's
color-coded by gender.

00:03:52.400 --> 00:03:56.240
And the links are actually
romantic or sexual

00:03:56.240 --> 00:04:00.440
relationships during an
18-month period of the study.

00:04:00.440 --> 00:04:03.480
And here you'll notice,
also, in the 63, and the 2,

00:04:03.480 --> 00:04:05.240
and the 12, 9--

00:04:05.240 --> 00:04:08.810
those are numbers of how many
times that subgraph appears.

00:04:08.810 --> 00:04:11.360
So there is a 63
pairs that didn't

00:04:11.360 --> 00:04:12.597
connect with anybody else.

00:04:12.597 --> 00:04:14.180
But you'll notice
on the left, there's

00:04:14.180 --> 00:04:16.100
a giant component--
what it's called.

00:04:16.100 --> 00:04:18.350
So this is a component
where, basically, you

00:04:18.350 --> 00:04:21.540
could draw a path from any
node in that to any other node.

00:04:21.540 --> 00:04:24.770
So even though each person
has few relationships,

00:04:24.770 --> 00:04:28.100
you're able to actually
trace from one to another.

00:04:28.100 --> 00:04:32.750
And that means when you're
looking at things like disease

00:04:32.750 --> 00:04:33.710
spread and things--

00:04:33.710 --> 00:04:35.912
or even rumors spread,
other kinds of things--

00:04:35.912 --> 00:04:38.120
understanding this component
structure of the network

00:04:38.120 --> 00:04:40.400
can be very important
in understanding

00:04:40.400 --> 00:04:42.000
how things spread.

00:04:42.000 --> 00:04:45.740
So in going back to
this idea that there's

00:04:45.740 --> 00:04:49.010
a difference between these
networks and random networks,

00:04:49.010 --> 00:04:51.020
one thing that's
true is you end up

00:04:51.020 --> 00:04:54.170
having some nodes that
have very many connections,

00:04:54.170 --> 00:04:56.210
and some that have
very few connections,

00:04:56.210 --> 00:04:58.813
and essentially what's known as
fat tails in the distribution.

00:04:58.813 --> 00:05:00.980
So when you look at the
distribution of friendships,

00:05:00.980 --> 00:05:03.517
you see more people who have
very few and more people who

00:05:03.517 --> 00:05:05.600
have very many connections
than you would normally

00:05:05.600 --> 00:05:07.220
see just at random.

00:05:07.220 --> 00:05:09.913
And this has some impact.

00:05:09.913 --> 00:05:11.330
And one thing I
want to start with

00:05:11.330 --> 00:05:13.497
is just talking about what's
known as the friendship

00:05:13.497 --> 00:05:14.450
paradox.

00:05:14.450 --> 00:05:19.070
And this is something
that we're all constantly

00:05:19.070 --> 00:05:20.870
bombarded by, essentially.

00:05:20.870 --> 00:05:22.730
And it's the fact
that our friends

00:05:22.730 --> 00:05:24.740
are more popular than we are.

00:05:24.740 --> 00:05:26.750
And that sounds like
a strange thing.

00:05:26.750 --> 00:05:28.375
How can it be that
your friends are all

00:05:28.375 --> 00:05:29.900
much more popular than you are?

00:05:29.900 --> 00:05:32.240
On average, people's
friends tend

00:05:32.240 --> 00:05:34.010
to be more popular
than they are.

00:05:34.010 --> 00:05:35.570
And why is that true?

00:05:35.570 --> 00:05:37.430
When you look at
somebody who has,

00:05:37.430 --> 00:05:40.250
say, 20 friends and somebody
who has two friends,

00:05:40.250 --> 00:05:42.080
the person who has
20 friends is going

00:05:42.080 --> 00:05:45.020
to appear in a lot of
people's friendship counts.

00:05:45.020 --> 00:05:47.570
So people who have
the most friendships

00:05:47.570 --> 00:05:50.640
appear as friends
to the most people.

00:05:50.640 --> 00:05:54.020
And so our samples of friends
are not random samples

00:05:54.020 --> 00:05:55.340
from the population.

00:05:55.340 --> 00:05:57.740
They tend to be heavily
biased towards the people who

00:05:57.740 --> 00:05:59.570
are the most popular.

00:05:59.570 --> 00:06:01.770
And that ends up
having consequences.

00:06:01.770 --> 00:06:03.200
So if these people
act differently

00:06:03.200 --> 00:06:05.180
than the rest of the
population, then you

00:06:05.180 --> 00:06:07.790
end up having a
distortion in terms

00:06:07.790 --> 00:06:09.710
of when you look at
your friends and what

00:06:09.710 --> 00:06:11.180
their behaviors look like.

00:06:11.180 --> 00:06:13.430
And if you project that to
the rest of the population,

00:06:13.430 --> 00:06:15.620
it's not a random sample.

00:06:15.620 --> 00:06:23.190
And social media accelerated
this, in fact, or amplified it.

00:06:23.190 --> 00:06:27.590
So if you look at, say,
Twitter, typically the follower

00:06:27.590 --> 00:06:30.110
has 10 times fewer
followers than the people

00:06:30.110 --> 00:06:31.790
that they're following.

00:06:31.790 --> 00:06:34.820
So there, it gets
even more extreme.

00:06:34.820 --> 00:06:38.580
But to understand the
illustration of this,

00:06:38.580 --> 00:06:43.310
if you look in middle school,
each additional friend

00:06:43.310 --> 00:06:48.800
that a kid has makes them
6% more likely to have tried

00:06:48.800 --> 00:06:50.960
alcohol by the time
they become a teenager

00:06:50.960 --> 00:06:53.150
and 5% more likely to
have smoked by the time

00:06:53.150 --> 00:06:54.440
they become a teenager.

00:06:54.440 --> 00:06:57.080
So basically, the kids
who are the most popular

00:06:57.080 --> 00:07:00.328
are ones who tend to be
trying things at earlier ages.

00:07:00.328 --> 00:07:02.120
And that also goes--
there's a whole series

00:07:02.120 --> 00:07:03.470
of studies on drugs.

00:07:03.470 --> 00:07:06.440
And they tend to be
experimenting in earlier ages.

00:07:06.440 --> 00:07:08.390
And then the students
who are friends

00:07:08.390 --> 00:07:11.480
with them are seeing
their behaviors

00:07:11.480 --> 00:07:14.550
and projecting that often to
the rest of the population.

00:07:14.550 --> 00:07:18.050
So people systematically
overestimate the amount

00:07:18.050 --> 00:07:20.960
of consumption of drugs,
alcohol, smoking that goes on

00:07:20.960 --> 00:07:24.500
in a population in
schools, because they're

00:07:24.500 --> 00:07:29.430
being overexposed to people who
are following those behaviors.

00:07:29.430 --> 00:07:34.280
So that ends up having an impact
in terms of what people see.

00:07:34.280 --> 00:07:37.018
There's also something
that's very true

00:07:37.018 --> 00:07:39.560
both in social networks that
are purely social-- where you're

00:07:39.560 --> 00:07:41.390
just talking about
friends that you're

00:07:41.390 --> 00:07:44.510
meeting physically or online.

00:07:44.510 --> 00:07:47.270
And that's a rich get
richer phenomenon.

00:07:47.270 --> 00:07:52.040
So when you begin to look
at how you find friends,

00:07:52.040 --> 00:07:55.858
often you meet people through
people you already know.

00:07:55.858 --> 00:07:57.650
If you're in a business,
you meet customers

00:07:57.650 --> 00:07:59.630
through your existing customers.

00:07:59.630 --> 00:08:02.930
And the fact that
this happens means

00:08:02.930 --> 00:08:06.217
that, the more opportunities
you have to meet people,

00:08:06.217 --> 00:08:07.550
the easier it is to meet people.

00:08:07.550 --> 00:08:08.900
And that snowballs.

00:08:08.900 --> 00:08:12.440
And so you see this
acceleration in terms of--

00:08:12.440 --> 00:08:14.480
some people end up with
very many connections.

00:08:14.480 --> 00:08:16.640
Other people end up with
very few connections.

00:08:16.640 --> 00:08:18.680
And that happens through
all sorts of media.

00:08:18.680 --> 00:08:22.070
You can look at videos,
whether they go viral or not,

00:08:22.070 --> 00:08:23.507
and look at the quality of them.

00:08:23.507 --> 00:08:25.340
And there can be very
high-quality ones that

00:08:25.340 --> 00:08:27.540
don't and other ones that do.

00:08:27.540 --> 00:08:29.745
And that has this kind
of feedback effect.

00:08:29.745 --> 00:08:31.370
And so in networks,
you get these kinds

00:08:31.370 --> 00:08:36.230
of exacerbated inequality in
terms of social connections.

00:08:36.230 --> 00:08:39.299
And those social connections
have consequences.

00:08:39.299 --> 00:08:42.559
Now going back to this
other segregation pattern

00:08:42.559 --> 00:08:46.130
that we see, let me take you
through a couple of examples

00:08:46.130 --> 00:08:47.040
of this.

00:08:47.040 --> 00:08:51.140
So this is another example
from a study we did in India.

00:08:51.140 --> 00:08:56.090
And now what I've done
is coded things by caste.

00:08:56.090 --> 00:08:58.280
So this is an Indian village.

00:08:58.280 --> 00:09:00.803
These are connections
between households.

00:09:00.803 --> 00:09:02.220
And a connection
between household

00:09:02.220 --> 00:09:04.400
is usually that they're
borrowing and lending

00:09:04.400 --> 00:09:07.090
money, kerosene, rice.

00:09:07.090 --> 00:09:08.730
They're giving each
other medical help.

00:09:08.730 --> 00:09:09.980
So this is a poor village.

00:09:09.980 --> 00:09:12.320
And they're basically
helping each other out.

00:09:12.320 --> 00:09:16.460
And the caste designation
here-- the red nodes

00:09:16.460 --> 00:09:18.620
are the relatively
disadvantaged caste.

00:09:18.620 --> 00:09:21.262
So these are scheduled
castes and scheduled tribes.

00:09:21.262 --> 00:09:22.970
So these are the ones
that are recognized

00:09:22.970 --> 00:09:26.000
by the Indian government
for affirmative action.

00:09:26.000 --> 00:09:32.270
And the blue squares are the
relatively advantaged castes.

00:09:32.270 --> 00:09:34.160
And these villages are
not very advantaged.

00:09:34.160 --> 00:09:39.330
But they're considered to be
better off by the government

00:09:39.330 --> 00:09:40.630
than then the other ones.

00:09:40.630 --> 00:09:42.380
So those are the
otherwise backward castes

00:09:42.380 --> 00:09:44.510
and general merit.

00:09:44.510 --> 00:09:47.690
And here you can begin to
see that, again, you're

00:09:47.690 --> 00:09:49.520
15 times more likely
to be connected

00:09:49.520 --> 00:09:51.950
with somebody in your own
caste than across castes.

00:09:51.950 --> 00:09:54.380
So these are strong boundaries.

00:09:54.380 --> 00:09:56.870
And you can also see,
even among the schedule

00:09:56.870 --> 00:09:59.750
castes and scheduled tribes,
there are strong cuts.

00:09:59.750 --> 00:10:01.550
And these cut both on religion.

00:10:01.550 --> 00:10:03.770
So Muslim and Hindu
don't interact much

00:10:03.770 --> 00:10:04.910
in these villages.

00:10:04.910 --> 00:10:11.090
And also, for instance, the
Dalit, the untouchable caste,

00:10:11.090 --> 00:10:13.400
are often their
own group and don't

00:10:13.400 --> 00:10:14.930
communicate with other groups.

00:10:14.930 --> 00:10:16.020
And so you can go
into a village.

00:10:16.020 --> 00:10:17.395
We were going into
these villages

00:10:17.395 --> 00:10:19.622
to try and spread
microfinance information.

00:10:19.622 --> 00:10:21.830
And it turns out that, if
you hit one of these groups

00:10:21.830 --> 00:10:23.510
and you don't hit
multiple groups,

00:10:23.510 --> 00:10:25.860
you basically don't get
the information out.

00:10:25.860 --> 00:10:27.890
So it's really important.

00:10:27.890 --> 00:10:28.790
They're very insular.

00:10:28.790 --> 00:10:30.710
So even if it's a village
of 200 households,

00:10:30.710 --> 00:10:32.418
you think everybody
must know each other.

00:10:32.418 --> 00:10:33.800
They've lived their whole lives.

00:10:33.800 --> 00:10:36.570
200 households-- how can
they not be communicating?

00:10:36.570 --> 00:10:38.810
They can really be quite
segregated and quite

00:10:38.810 --> 00:10:40.580
introspective,
even though they're

00:10:40.580 --> 00:10:45.200
in close proximity and
in this kind of setting

00:10:45.200 --> 00:10:48.530
with lots of other individuals
that have differences.

00:10:48.530 --> 00:10:50.630
But they just don't
really communicate.

00:10:50.630 --> 00:10:54.110
When you get back
to the high school,

00:10:54.110 --> 00:10:58.052
you end up having impact on
whether people go to college.

00:10:58.052 --> 00:10:59.510
We're doing a study
now where we're

00:10:59.510 --> 00:11:01.468
trying to understand
decisions to go to college

00:11:01.468 --> 00:11:03.380
and how those peer affected.

00:11:03.380 --> 00:11:05.420
And again, you're
mostly influenced

00:11:05.420 --> 00:11:06.920
by your close friends.

00:11:06.920 --> 00:11:10.190
And even getting
basic information

00:11:10.190 --> 00:11:13.460
about how to study for SATs,
or how to apply to colleges,

00:11:13.460 --> 00:11:15.410
or what kind of financial
aid is available,

00:11:15.410 --> 00:11:18.080
all kinds of things
that seem fairly simple

00:11:18.080 --> 00:11:20.690
can be something that's
very alien to certain groups

00:11:20.690 --> 00:11:21.980
internally.

00:11:21.980 --> 00:11:26.270
And as people grow up, it
gets even more pronounced,

00:11:26.270 --> 00:11:31.430
in a sense that, when you
look at access to jobs,

00:11:31.430 --> 00:11:36.230
roughly 50% to 70% of
jobs are originally

00:11:36.230 --> 00:11:39.290
obtained through referrals,
meaning you know somebody

00:11:39.290 --> 00:11:40.460
at the company.

00:11:40.460 --> 00:11:42.410
They help get you an interview.

00:11:42.410 --> 00:11:44.480
And if you don't
have that interview,

00:11:44.480 --> 00:11:46.700
it's very difficult
to get looked at.

00:11:46.700 --> 00:11:51.200
And what that does
is it exacerbates

00:11:51.200 --> 00:11:56.150
this persistent inequality, in
a sense that, if I'm in a group

00:11:56.150 --> 00:11:58.910
that where very few of
my friends are employed

00:11:58.910 --> 00:12:01.130
and they have low wages,
it's very difficult for me

00:12:01.130 --> 00:12:03.860
to get information about
jobs to get contacts

00:12:03.860 --> 00:12:05.593
and to actually get jobs.

00:12:05.593 --> 00:12:07.010
And so then I have
more incentives

00:12:07.010 --> 00:12:08.720
to drop out of the labor force.

00:12:08.720 --> 00:12:12.020
I have less incentives
to invest in education.

00:12:12.020 --> 00:12:16.730
And this goes along over time.

00:12:16.730 --> 00:12:20.000
There's a really interesting
study by Ron Laschever.

00:12:20.000 --> 00:12:23.030
And he was trying-- so this is
very difficult to tease out.

00:12:23.030 --> 00:12:24.800
When you're doing
research on this,

00:12:24.800 --> 00:12:26.862
it's very difficult
to tell why--

00:12:26.862 --> 00:12:28.820
if two people are connected
and neither of them

00:12:28.820 --> 00:12:30.770
are getting a job,
it's very difficult

00:12:30.770 --> 00:12:33.703
to tell whether there's an
effect from one to the other.

00:12:33.703 --> 00:12:35.120
Because it could
be that these are

00:12:35.120 --> 00:12:36.530
people who just are unemployed.

00:12:36.530 --> 00:12:38.905
And unemployed people tend to
be friends with each other.

00:12:38.905 --> 00:12:41.552
And employed people tend to
be friends with each other.

00:12:41.552 --> 00:12:43.010
So what he did is
he took advantage

00:12:43.010 --> 00:12:46.460
of a random assignment of
people to friend groups.

00:12:46.460 --> 00:12:49.840
And the way he did it was
he looked at the draft

00:12:49.840 --> 00:12:51.560
in the First World War.

00:12:51.560 --> 00:12:54.920
So in the First World War, the
US Army went from about 300,000

00:12:54.920 --> 00:13:00.170
or 400,000 people in 1917
to almost 4 million people

00:13:00.170 --> 00:13:01.700
enlisted by 1918.

00:13:01.700 --> 00:13:04.860
So it was an enormous growth
in a very short period of time.

00:13:04.860 --> 00:13:06.920
And the way they did
this was a random draft.

00:13:06.920 --> 00:13:08.060
You got drafted.

00:13:08.060 --> 00:13:12.840
And then people were put
into companies of 100 people.

00:13:12.840 --> 00:13:15.873
So you were just thrown into
these people with other people.

00:13:15.873 --> 00:13:17.540
And it was done
completely randomly just

00:13:17.540 --> 00:13:21.950
by the order of your number
that you were drafted in.

00:13:21.950 --> 00:13:24.370
And then these people
literally spent

00:13:24.370 --> 00:13:26.790
a couple of years in the
trenches with each other.

00:13:26.790 --> 00:13:28.640
So they became
very close friends.

00:13:28.640 --> 00:13:31.790
And then what he does is
he follows their employment

00:13:31.790 --> 00:13:36.210
trajectories after the
war through the 1930s.

00:13:36.210 --> 00:13:40.760
And when you look at
somebody in my company,

00:13:40.760 --> 00:13:44.210
if there's a 10% increase in the
employment rate in my company,

00:13:44.210 --> 00:13:49.190
that corresponded to a 4%
increase in my employment

00:13:49.190 --> 00:13:50.220
on average.

00:13:50.220 --> 00:13:52.700
So basically, you're getting
about a 40% spillover

00:13:52.700 --> 00:13:55.040
of your friends employment
to your own employment

00:13:55.040 --> 00:13:57.890
just by completely random
assignment of friends.

00:13:57.890 --> 00:13:59.370
So it gives you
an idea that this

00:13:59.370 --> 00:14:02.090
can be a powerful force in terms
of whether or not people have

00:14:02.090 --> 00:14:03.410
access to jobs.

00:14:03.410 --> 00:14:05.690
And it gives you
an idea that, when

00:14:05.690 --> 00:14:09.200
you're looking at groups that
are relatively disadvantaged,

00:14:09.200 --> 00:14:10.980
it's very difficult
to get out of that.

00:14:10.980 --> 00:14:12.605
Because they don't
have the opportunity

00:14:12.605 --> 00:14:17.390
to access that other people do.

00:14:17.390 --> 00:14:20.330
One of the most, I
think, impressive studies

00:14:20.330 --> 00:14:22.790
in quantifying these
effects was what's

00:14:22.790 --> 00:14:24.510
known as the Moving
to Opportunity study.

00:14:24.510 --> 00:14:26.040
I don't know if
people know that.

00:14:26.040 --> 00:14:28.760
So this was a study that was
done by the US government

00:14:28.760 --> 00:14:30.440
in the 1990s.

00:14:30.440 --> 00:14:34.670
And what they did was they gave
different families vouchers.

00:14:34.670 --> 00:14:35.850
They gave them vouchers.

00:14:35.850 --> 00:14:37.610
And what was a voucher good for?

00:14:37.610 --> 00:14:39.890
The voucher would pay your rent.

00:14:39.890 --> 00:14:41.570
So they were giving
low-income families

00:14:41.570 --> 00:14:43.180
vouchers to pay for rent.

00:14:43.180 --> 00:14:46.280
And they had about 4,500
households-- a little

00:14:46.280 --> 00:14:47.540
more than 4,500.

00:14:47.540 --> 00:14:49.350
And they broke them
into three groups.

00:14:49.350 --> 00:14:51.500
A third of them,
they gave vouchers.

00:14:51.500 --> 00:14:53.390
And they could just
paid for their rent.

00:14:53.390 --> 00:14:55.550
A third of them, they
gave nothing just

00:14:55.550 --> 00:14:56.900
as a control group.

00:14:56.900 --> 00:14:59.600
And a third of them, they
gave vouchers but only

00:14:59.600 --> 00:15:02.820
if they agreed to move to
a wealthier neighborhood.

00:15:02.820 --> 00:15:03.660
So they had to move.

00:15:03.660 --> 00:15:06.480
And they had to move to a
neighborhood that was higher

00:15:06.480 --> 00:15:08.710
up in the income distribution.

00:15:08.710 --> 00:15:11.190
And what they found
was, if your family--

00:15:11.190 --> 00:15:15.210
so now you can look back at this
and see what the outcome was.

00:15:15.210 --> 00:15:19.530
And a family that moved
with an eight-year-old

00:15:19.530 --> 00:15:25.240
child from a poor location
to a wealthier location, now

00:15:25.240 --> 00:15:30.760
the eight-year-old child,
in terms of lifetime income,

00:15:30.760 --> 00:15:33.900
looks like they're
about $300,000

00:15:33.900 --> 00:15:37.410
higher in terms of
lifetime income.

00:15:37.410 --> 00:15:40.020
They're 1/6 more likely
to have gone to college.

00:15:40.020 --> 00:15:41.730
They're less likely
to be single parents.

00:15:41.730 --> 00:15:43.355
They're less likely
to be incarcerated.

00:15:43.355 --> 00:15:45.720
They have better
health outcomes.

00:15:45.720 --> 00:15:48.450
So essentially, taking
them out of one community,

00:15:48.450 --> 00:15:51.030
putting them into another
community made a big difference

00:15:51.030 --> 00:15:55.320
in who their peers were,
what the parental peers were,

00:15:55.320 --> 00:15:59.130
and then what their life was
like as a result of this.

00:15:59.130 --> 00:16:01.080
Now obviously,
social engineering

00:16:01.080 --> 00:16:02.290
is not an easy thing to do.

00:16:02.290 --> 00:16:04.415
We don't want to start just
going around and trying

00:16:04.415 --> 00:16:05.920
to rewire everybody's networks.

00:16:05.920 --> 00:16:08.580
But what that does tell us
is that these things can

00:16:08.580 --> 00:16:11.070
have a very large impact.

00:16:11.070 --> 00:16:13.110
And interestingly,
the impact depended

00:16:13.110 --> 00:16:14.550
on how old the kids were.

00:16:14.550 --> 00:16:17.220
So an eight-year-old
kid got a huge impact.

00:16:17.220 --> 00:16:19.750
An 18-year-old kid
had almost no impact.

00:16:19.750 --> 00:16:22.050
So if you took an
18-year-old, they basically

00:16:22.050 --> 00:16:23.720
had already had
their social network

00:16:23.720 --> 00:16:26.582
and a lot of impact on them.

00:16:26.582 --> 00:16:28.290
And it really made
very little difference

00:16:28.290 --> 00:16:32.110
in terms of outcomes.

00:16:32.110 --> 00:16:36.090
I spend more time in the book
also talking about learning

00:16:36.090 --> 00:16:39.160
and how people learn
information through networks.

00:16:39.160 --> 00:16:42.990
And I think now, with all
the discussion of fake news,

00:16:42.990 --> 00:16:44.713
and polarization,
and echo chambers,

00:16:44.713 --> 00:16:47.130
there's a lot we can actually
learn from the basic network

00:16:47.130 --> 00:16:50.180
structures in terms of the
kinds of biases that operate.

00:16:50.180 --> 00:16:54.690
And there's a
fascinating study that

00:16:54.690 --> 00:16:58.260
goes way back, which
is known as Vox Populi.

00:16:58.260 --> 00:17:00.270
I don't know if
people know the term.

00:17:00.270 --> 00:17:02.040
It's the wisdom of the crowds.

00:17:02.040 --> 00:17:04.890
And this was a guy named
Sir Francis Galton.

00:17:04.890 --> 00:17:09.569
And he published a paper in the
"Journal of Nature" in 1907.

00:17:09.569 --> 00:17:13.805
And what it did was-- he
went to a fair in England.

00:17:13.805 --> 00:17:15.180
And it was a fair
where you could

00:17:15.180 --> 00:17:17.010
guess the weight of an ox.

00:17:17.010 --> 00:17:18.660
So there was an ox there.

00:17:18.660 --> 00:17:22.500
The ox weighed 1,198 pounds.

00:17:22.500 --> 00:17:25.800
And then for a fee, you could
guess the weight of the ox.

00:17:25.800 --> 00:17:31.320
And then whoever got closest to
the actual weight won a prize.

00:17:31.320 --> 00:17:34.770
And what he did is he
collected all the guesses.

00:17:34.770 --> 00:17:37.500
And there were 787 guesses.

00:17:37.500 --> 00:17:42.960
And the average guess in the
population was 1,197 pounds.

00:17:42.960 --> 00:17:46.140
So it was 1 pound short of
the actual weight of the ox.

00:17:46.140 --> 00:17:49.620
And the median was actually
just over 1,200 pounds.

00:17:49.620 --> 00:17:52.800
So basically, the
middle this distribution

00:17:52.800 --> 00:17:55.350
was just centered right
on the actual weight.

00:17:55.350 --> 00:17:58.470
And then there was
quite a variance on it.

00:17:58.470 --> 00:18:00.870
But what that tells you
is that, collectively,

00:18:00.870 --> 00:18:03.390
if everybody could
share their information,

00:18:03.390 --> 00:18:06.060
often you can come to the
right kind of decision

00:18:06.060 --> 00:18:10.160
or the right kind of
knowledge about some facts.

00:18:10.160 --> 00:18:13.130
But then we're subject to
all kinds of issues in terms

00:18:13.130 --> 00:18:15.750
of the biases that we face.

00:18:15.750 --> 00:18:18.370
So as we see in these
kinds of networks,

00:18:18.370 --> 00:18:21.810
we're not necessarily
listening to everybody equally.

00:18:21.810 --> 00:18:24.950
So if there's biases in terms
of what kinds of information

00:18:24.950 --> 00:18:28.760
people have-- depending
on ethnicity, age, gender,

00:18:28.760 --> 00:18:30.260
profession, et cetera--

00:18:30.260 --> 00:18:32.790
then if we're only
talking to those people,

00:18:32.790 --> 00:18:34.610
we don't get nearly
the information

00:18:34.610 --> 00:18:38.930
to aggregate up to come to
the wisdom of the crowd.

00:18:38.930 --> 00:18:43.070
And so that's a difficult thing.

00:18:43.070 --> 00:18:48.680
And also, humans are
very good at counting.

00:18:48.680 --> 00:18:53.150
So if you think about
the information you hear.

00:18:53.150 --> 00:18:55.280
So suppose there's
a new movie out.

00:18:55.280 --> 00:18:58.190
And you hear from
seven of your friends

00:18:58.190 --> 00:19:00.080
that this is a movie
you have to go to.

00:19:00.080 --> 00:19:03.170
They've just heard
it's really wonderful.

00:19:03.170 --> 00:19:04.802
You count that implicitly.

00:19:04.802 --> 00:19:06.260
The more people
you hear that from,

00:19:06.260 --> 00:19:09.080
the more you begin
to believe it.

00:19:09.080 --> 00:19:11.900
But it could be that all those
people read the same review.

00:19:11.900 --> 00:19:15.005
So it could be that all of that
is traced back to one source.

00:19:15.005 --> 00:19:17.130
And when you're looking at
these kinds of networks,

00:19:17.130 --> 00:19:20.970
it's very easy for you to be
being bombarded by information

00:19:20.970 --> 00:19:22.910
which is all coming
from the same source

00:19:22.910 --> 00:19:24.320
and then repeating it.

00:19:24.320 --> 00:19:29.700
And these kinds of echo chambers
do lead to false beliefs

00:19:29.700 --> 00:19:32.570
in a variety of settings.

00:19:32.570 --> 00:19:38.840
So what I want to
do to just talk

00:19:38.840 --> 00:19:41.330
a little bit about the
trends in networks--

00:19:41.330 --> 00:19:43.490
and what I'm going to
do here is take you

00:19:43.490 --> 00:19:45.410
through a couple of
pictures of how things

00:19:45.410 --> 00:19:46.850
have been changing over time.

00:19:46.850 --> 00:19:49.130
And it's actually
difficult to find pictures

00:19:49.130 --> 00:19:50.432
of networks that go far back.

00:19:50.432 --> 00:19:51.890
So what I've done
here is-- this is

00:19:51.890 --> 00:19:54.800
from a study I did
with Steven Nigh.

00:19:54.800 --> 00:19:58.100
And this goes all the way
back to the Napoleonic Wars.

00:19:58.100 --> 00:20:01.740
And now what we're looking at is
connections between countries.

00:20:01.740 --> 00:20:03.410
So these are countries.

00:20:03.410 --> 00:20:06.650
And a link between
two of them is if they

00:20:06.650 --> 00:20:09.260
had a military alliance--

00:20:09.260 --> 00:20:12.710
so either a positive
alliance that they

00:20:12.710 --> 00:20:15.440
agreed to be allies
in some confrontation,

00:20:15.440 --> 00:20:17.760
or they agreed not
to attack each other.

00:20:17.760 --> 00:20:20.330
So what we'll start
is just by looking

00:20:20.330 --> 00:20:23.000
at these things over time and
seeing how they're changing.

00:20:23.000 --> 00:20:24.740
So right after the
Napoleonic Wars,

00:20:24.740 --> 00:20:28.130
we had a group that
were connected.

00:20:28.130 --> 00:20:30.810
They lasted together
for a while.

00:20:30.810 --> 00:20:31.520
You keep going.

00:20:31.520 --> 00:20:33.410
Things are bouncing
around a little bit.

00:20:33.410 --> 00:20:37.210
1870s were a pretty
rough period.

00:20:37.210 --> 00:20:39.530
The unification of Germany
happened just after this--

00:20:39.530 --> 00:20:43.130
Otto Von Bismarck
appears in the 1870s.

00:20:43.130 --> 00:20:46.800
And then you start
seeing new connections.

00:20:46.800 --> 00:20:49.940
You get to just before
the First World War.

00:20:49.940 --> 00:20:51.650
1920s were a rough period.

00:20:51.650 --> 00:20:55.650
The 1930s, you begin to
see things take place.

00:20:55.650 --> 00:20:58.340
And now when you look
post 1950, you'll

00:20:58.340 --> 00:21:00.590
see very different
patterns emerging.

00:21:00.590 --> 00:21:04.740
So here things are
getting a lot denser.

00:21:04.740 --> 00:21:06.240
And by the time you
get to 2000, you

00:21:06.240 --> 00:21:08.420
see an incredibly dense network.

00:21:08.420 --> 00:21:11.420
And the network now--

00:21:11.420 --> 00:21:13.970
you can place your favorite
country in this network.

00:21:13.970 --> 00:21:18.350
There's two different features,
before 1950 and after 1950.

00:21:18.350 --> 00:21:20.120
Before 1950, people
tended to have

00:21:20.120 --> 00:21:22.640
about two and a half
allies-- so many fewer.

00:21:22.640 --> 00:21:27.362
And the chance that they lasted
for five years was about 2/3.

00:21:27.362 --> 00:21:29.570
So if you look in an alliance,
look five years later,

00:21:29.570 --> 00:21:31.980
the chance it survives
was about 2/3.

00:21:31.980 --> 00:21:35.810
Now people have about
10 and 1/2 allies.

00:21:35.810 --> 00:21:40.380
And the chance that
it lasts is about 95%.

00:21:40.380 --> 00:21:42.680
So there's a much higher
chance that it lasts.

00:21:42.680 --> 00:21:44.870
And if you begin to
look at this network--

00:21:44.870 --> 00:21:47.120
I don't have the pictures
for the trade networks going

00:21:47.120 --> 00:21:49.100
over this time period,
but they really

00:21:49.100 --> 00:21:51.320
closely overlap with trade.

00:21:51.320 --> 00:21:54.410
And so a lot of it
is cemented by trade.

00:21:54.410 --> 00:21:56.810
And the globalization
that's been going on

00:21:56.810 --> 00:21:59.780
in terms of trade networks,
both directly in terms

00:21:59.780 --> 00:22:03.170
of goods and financial networks,
really are what cement these.

00:22:03.170 --> 00:22:05.900
And that's why they
don't disappear

00:22:05.900 --> 00:22:08.510
and why it's becoming
increasingly dense.

00:22:08.510 --> 00:22:10.190
The good news
about this is that,

00:22:10.190 --> 00:22:13.580
when you look at the
incidence of wars over time,

00:22:13.580 --> 00:22:15.590
basically, once this
network has started

00:22:15.590 --> 00:22:18.560
densifying the wars have
pretty much disappeared

00:22:18.560 --> 00:22:20.310
by historical standards.

00:22:20.310 --> 00:22:22.010
So even though we
still have wars,

00:22:22.010 --> 00:22:24.500
most of the big wars
in the past few decades

00:22:24.500 --> 00:22:26.730
have actually been in Africa.

00:22:26.730 --> 00:22:30.170
But if you look at the history
of what's still going on,

00:22:30.170 --> 00:22:32.660
we have about 1/10
the frequency of wars

00:22:32.660 --> 00:22:35.180
post-1950 as we had before 1950.

00:22:35.180 --> 00:22:37.940
So it's actually a much
more peaceful period

00:22:37.940 --> 00:22:39.560
than people realize.

00:22:39.560 --> 00:22:42.530
And there's different
ways of measuring it.

00:22:42.530 --> 00:22:44.150
This is off of a
data set that we

00:22:44.150 --> 00:22:46.460
used which was called the
Correlates of War data set.

00:22:46.460 --> 00:22:48.710
But basically, things are
becoming much more peaceful.

00:22:48.710 --> 00:22:51.440
And that's really has
an enormous amount

00:22:51.440 --> 00:22:52.370
to do with trade.

00:22:52.370 --> 00:22:55.080
If you throw nuclear
weapons into the mix,

00:22:55.080 --> 00:22:57.980
you really can't explain
the patterns of wars.

00:22:57.980 --> 00:23:01.160
The patterns of wars really seem
to be explained by the trade.

00:23:01.160 --> 00:23:03.575
And when you look at the same--

00:23:03.575 --> 00:23:06.120
this is just world trade
as a percentage of GDP--

00:23:06.120 --> 00:23:07.880
it's just been
going up steadily.

00:23:07.880 --> 00:23:11.660
So the world trade network
has been growing denser.

00:23:11.660 --> 00:23:14.380
That's cementing relationships
and actually leading

00:23:14.380 --> 00:23:15.920
to a lot of peace.

00:23:15.920 --> 00:23:18.550
And when you look at
the remaining conflicts

00:23:18.550 --> 00:23:19.970
in the world--

00:23:19.970 --> 00:23:21.550
for instance, if
you look at what's

00:23:21.550 --> 00:23:23.500
going on in the
Middle East, Israel

00:23:23.500 --> 00:23:26.020
is surrounded by countries
that it doesn't trade with.

00:23:26.020 --> 00:23:28.840
So Jordan is the only country
that has any trade with.

00:23:28.840 --> 00:23:33.550
And I think Jordan ranks 20th
on its list of trade partners.

00:23:33.550 --> 00:23:35.470
When you look at
North Korea, it's

00:23:35.470 --> 00:23:37.270
fairly isolated
in terms of trade.

00:23:37.270 --> 00:23:40.270
When you look at US
trade with Russia,

00:23:40.270 --> 00:23:45.730
it's actually a
relatively low trade

00:23:45.730 --> 00:23:50.030
dyad given the size
of the two economies.

00:23:50.030 --> 00:23:51.850
So just understanding
that, I think,

00:23:51.850 --> 00:23:54.100
gives us a lens into
how these networks

00:23:54.100 --> 00:23:57.270
are changing over time.

00:23:57.270 --> 00:23:59.292
And it's an important
thing in light of Brexit

00:23:59.292 --> 00:24:00.750
and a whole series
of other things.

00:24:00.750 --> 00:24:02.167
You don't want to
be too alarmist.

00:24:02.167 --> 00:24:04.930
But anything that
moves trade backwards

00:24:04.930 --> 00:24:07.640
is moving us in
the wrong direction

00:24:07.640 --> 00:24:09.525
in terms of the networks.

00:24:09.525 --> 00:24:10.900
What I wanted to
end with is just

00:24:10.900 --> 00:24:12.650
a question of whether
the world's actually

00:24:12.650 --> 00:24:14.050
becoming more polarized.

00:24:14.050 --> 00:24:17.530
And before I show you
the full pictures here,

00:24:17.530 --> 00:24:19.910
I want to say a couple
of things about that.

00:24:19.910 --> 00:24:22.540
So one is-- and this is
something that people at Google

00:24:22.540 --> 00:24:23.410
know well--

00:24:23.410 --> 00:24:27.130
is that algorithms are
important in determining

00:24:27.130 --> 00:24:29.290
what people have
access to and how

00:24:29.290 --> 00:24:31.490
they connect to other people.

00:24:31.490 --> 00:24:34.030
And one thing that's
happening over time

00:24:34.030 --> 00:24:37.090
is our world's becoming denser
in terms of the connections.

00:24:37.090 --> 00:24:40.300
So we can maintain relationships
at a much greater distance.

00:24:40.300 --> 00:24:43.120
But we also have
search engines--

00:24:43.120 --> 00:24:46.060
the system is so
difficult to navigate

00:24:46.060 --> 00:24:48.670
that you need some way of
finding things and finding

00:24:48.670 --> 00:24:49.670
people.

00:24:49.670 --> 00:24:52.570
And one thing that
allows us to do

00:24:52.570 --> 00:24:54.370
is find other
people who actually

00:24:54.370 --> 00:24:56.895
have very similar interests
to us, or like things,

00:24:56.895 --> 00:24:58.270
and find things
that we can like,

00:24:58.270 --> 00:25:01.570
and have the systems
show those to us.

00:25:01.570 --> 00:25:04.290
And so that plays off
of this homophily--

00:25:04.290 --> 00:25:07.780
the segregation in networks
that is so prevalent.

00:25:07.780 --> 00:25:09.530
Our natural tendency
is to look for things

00:25:09.530 --> 00:25:11.410
that are similar to ourselves.

00:25:11.410 --> 00:25:13.582
It gets amplified by this.

00:25:13.582 --> 00:25:15.040
And so there's been
some discussion

00:25:15.040 --> 00:25:17.050
about whether the
world's more polarized.

00:25:17.050 --> 00:25:19.390
This is a picture
from Senate co-voting.

00:25:19.390 --> 00:25:22.980
And here, what each
dot is is a senator.

00:25:22.980 --> 00:25:24.700
And this is from
the 1990 Senate.

00:25:24.700 --> 00:25:27.670
And this is from code I got
from Renzo Lucioni, who's

00:25:27.670 --> 00:25:28.600
a computer scientist.

00:25:28.600 --> 00:25:31.870
And all I did was
look at the 1990

00:25:31.870 --> 00:25:34.390
Senate, look at all the
votes that happened.

00:25:34.390 --> 00:25:37.660
And we'll put two
senators together

00:25:37.660 --> 00:25:39.948
if they voted the same way
more than half the time.

00:25:39.948 --> 00:25:41.740
So if they agreed more
than they disagreed,

00:25:41.740 --> 00:25:43.250
we'll put a link between them.

00:25:43.250 --> 00:25:45.520
So it just shows, how
cohesive is the Senate

00:25:45.520 --> 00:25:47.000
in terms of co-voting patterns?

00:25:47.000 --> 00:25:48.940
Are people agreeing,
not agreeing?

00:25:48.940 --> 00:25:53.210
And again, the algorithm doesn't
know the colors of the nodes.

00:25:53.210 --> 00:25:55.960
It puts them on the
page by putting people

00:25:55.960 --> 00:25:58.690
together that co-vote similarly
and pulling them apart

00:25:58.690 --> 00:25:59.840
if they're not.

00:25:59.840 --> 00:26:01.960
And so it gives us a picture.

00:26:01.960 --> 00:26:05.410
And what you can
see-- this is 2015.

00:26:05.410 --> 00:26:07.960
So the question of whether
the voting is becoming more

00:26:07.960 --> 00:26:09.830
polarized-- you
can just see the--

00:26:09.830 --> 00:26:11.640
I didn't pull this apart.

00:26:11.640 --> 00:26:12.790
The algorithm does that.

00:26:12.790 --> 00:26:16.210
So now the chance that you
co-vote with somebody-- before,

00:26:16.210 --> 00:26:17.870
it was 82%.

00:26:17.870 --> 00:26:21.340
So here, 82% of the senators
were linked to each other.

00:26:21.340 --> 00:26:23.290
Now it's 53%.

00:26:23.290 --> 00:26:27.320
And most of them tend to
be within their own party.

00:26:27.320 --> 00:26:29.770
So, very few of the
connections go across parties.

00:26:29.770 --> 00:26:32.810
And you can fill in where
your favorite senator is

00:26:32.810 --> 00:26:34.287
and so forth.

00:26:34.287 --> 00:26:36.370
Interestingly, some of the
Republicans like Rubio,

00:26:36.370 --> 00:26:38.920
and Cruz, and Graham end
up at very different points

00:26:38.920 --> 00:26:40.870
and very different--
so you can begin

00:26:40.870 --> 00:26:44.650
to place people on
a political spectrum

00:26:44.650 --> 00:26:47.200
partly by who they're
co-voting with.

00:26:47.200 --> 00:26:49.585
But what this does
say is that some of--

00:26:49.585 --> 00:26:54.460
the ideas that there's more
tension and less agreement

00:26:54.460 --> 00:26:55.633
is partly true.

00:26:55.633 --> 00:26:57.550
It's a little difficult
with the Senate stuff,

00:26:57.550 --> 00:27:00.280
because what is
actually being voted on

00:27:00.280 --> 00:27:01.660
is changing over time, as well.

00:27:01.660 --> 00:27:08.320
And so there's other things
going on at the same time.

00:27:08.320 --> 00:27:10.480
But you begin to see
that there's definitely

00:27:10.480 --> 00:27:12.780
a pattern here.

00:27:12.780 --> 00:27:14.680
Other kinds of things--

00:27:14.680 --> 00:27:16.300
it took four years
for the plague

00:27:16.300 --> 00:27:19.090
to go from Marseille
to Stockholm.

00:27:19.090 --> 00:27:27.150
It took a week from Ebola to
get from Africa to New York.

00:27:27.150 --> 00:27:29.620
So the world is
becoming more connected.

00:27:29.620 --> 00:27:31.400
That's great in a lot of ways.

00:27:31.400 --> 00:27:32.890
So the globalization
we showed you

00:27:32.890 --> 00:27:34.570
is leading to a lot of peace.

00:27:34.570 --> 00:27:37.030
We see people being able
to be connected that they

00:27:37.030 --> 00:27:38.140
weren't connecting before.

00:27:38.140 --> 00:27:41.380
The world poverty rate has
come down from over 40%

00:27:41.380 --> 00:27:46.463
to less than 10% since 1980.

00:27:46.463 --> 00:27:48.130
There's all kinds of
great news in terms

00:27:48.130 --> 00:27:49.240
of all these connections.

00:27:49.240 --> 00:27:51.290
But at the same time,
I think the fact

00:27:51.290 --> 00:27:52.960
that we're becoming
more connected-- we

00:27:52.960 --> 00:27:55.570
can become more connected
and actually more segregated

00:27:55.570 --> 00:27:56.740
at the same time.

00:27:56.740 --> 00:27:59.050
And you're seeing both of
those effects happening.

00:27:59.050 --> 00:28:02.020
And it's an interesting
time to be studying

00:28:02.020 --> 00:28:04.240
networks for that reason.

00:28:04.240 --> 00:28:08.050
I think that's a good time to
stop and ask for your questions

00:28:08.050 --> 00:28:08.730
and comments.

00:28:13.900 --> 00:28:16.750
AUDIENCE: I was wondering for
your better-off/worse-off group

00:28:16.750 --> 00:28:21.980
scenario, if we establish enough
connection between the groups

00:28:21.980 --> 00:28:25.060
if one group can
simulate the other?

00:28:25.060 --> 00:28:27.720
MATTHEW O. JACKSON:
Yeah, I think--

00:28:27.720 --> 00:28:30.370
so being aware of the
homophily and the segregation

00:28:30.370 --> 00:28:32.770
across groups helps
us understand, look,

00:28:32.770 --> 00:28:35.140
there's not necessarily
information and opportunities

00:28:35.140 --> 00:28:36.640
flowing to these groups.

00:28:36.640 --> 00:28:40.030
Part of the difficulty in
just establishing links

00:28:40.030 --> 00:28:41.968
across the groups
is that you need

00:28:41.968 --> 00:28:44.260
to put a lot of links in
there if you want to do things

00:28:44.260 --> 00:28:46.030
that are peer influenced.

00:28:46.030 --> 00:28:48.550
So if you look inside
the high schools--

00:28:48.550 --> 00:28:52.720
we've been doing studies
on alcohol consumption,

00:28:52.720 --> 00:28:54.580
and drug consumption,
and things.

00:28:54.580 --> 00:28:58.330
And if you look at those,
a rough rule of thumb

00:28:58.330 --> 00:28:59.890
is that the students
sort of act like

00:28:59.890 --> 00:29:02.020
the majority of their friends.

00:29:02.020 --> 00:29:05.320
And that means that, if you've
got these segregation patterns,

00:29:05.320 --> 00:29:07.780
you'd have to put in an
enormous number of connections

00:29:07.780 --> 00:29:11.380
to really correct for the fact
that they're very segmented.

00:29:11.380 --> 00:29:13.760
So it's not an easy
thing to overcome.

00:29:13.760 --> 00:29:17.222
And I think that some
things that can be done

00:29:17.222 --> 00:29:19.180
are mentoring programs,
especially when it gets

00:29:19.180 --> 00:29:20.980
to getting people into college.

00:29:20.980 --> 00:29:23.530
So if it's hard to build
many relationships,

00:29:23.530 --> 00:29:25.820
instead you can build
really strong ones.

00:29:25.820 --> 00:29:28.630
So put somebody in who can
actually go into a student--

00:29:28.630 --> 00:29:31.383
and instead of just sending
them information, say, OK, look,

00:29:31.383 --> 00:29:32.050
here's a mentor.

00:29:32.050 --> 00:29:34.330
Here's somebody who
went to college.

00:29:34.330 --> 00:29:36.280
They can tell you
about what you need

00:29:36.280 --> 00:29:39.550
to do to apply, what your
life is going to be like,

00:29:39.550 --> 00:29:43.120
and spend concentrated
time with them.

00:29:43.120 --> 00:29:45.560
I think that that's
very important.

00:29:45.560 --> 00:29:50.560
AUDIENCE: I just wondering
how the techniques of studying

00:29:50.560 --> 00:29:53.710
things like this-- sociological
networks or economics--

00:29:53.710 --> 00:29:57.130
has changed with
advances in technology,

00:29:57.130 --> 00:29:59.088
and availability of data,
and things like that?

00:29:59.088 --> 00:30:01.172
MATTHEW O. JACKSON: Yeah,
that's a great question.

00:30:01.172 --> 00:30:03.520
And it's really a fun
time to be doing this.

00:30:03.520 --> 00:30:07.900
Because the data are
exploding in terms of--

00:30:07.900 --> 00:30:12.690
the number and
richness of data sets

00:30:12.690 --> 00:30:16.250
is really extraordinary now.

00:30:16.250 --> 00:30:18.520
And there are a
lot more techniques

00:30:18.520 --> 00:30:20.502
that we have for working
with large data sets.

00:30:20.502 --> 00:30:22.960
So the ones I've shown you are
ones that can be visualized,

00:30:22.960 --> 00:30:24.490
which are usually smaller.

00:30:24.490 --> 00:30:28.090
But you can handle ones with
hundreds of millions of nodes.

00:30:28.090 --> 00:30:32.860
And we're actually doing
that with some various media

00:30:32.860 --> 00:30:34.360
platforms in trying
to understand

00:30:34.360 --> 00:30:37.220
how people are connecting and
what the implications are.

00:30:37.220 --> 00:30:39.580
So large data sets are
becoming available.

00:30:39.580 --> 00:30:42.370
And often, a lot of the--
like, when I showed you

00:30:42.370 --> 00:30:44.350
the Indian village
data, those are the ones

00:30:44.350 --> 00:30:46.540
we obtained by surveys.

00:30:46.540 --> 00:30:50.680
And when you ask people for who
their friends are and so forth,

00:30:50.680 --> 00:30:51.490
you get biases.

00:30:51.490 --> 00:30:53.030
And you get measurement error.

00:30:53.030 --> 00:30:55.155
You can't remember all your
friend-- you don't name

00:30:55.155 --> 00:30:56.360
all the people and so forth.

00:30:56.360 --> 00:30:59.830
When you actually look at other
kinds of footprints, especially

00:30:59.830 --> 00:31:02.740
electronic footprints, you
get a different picture

00:31:02.740 --> 00:31:04.280
of what's going on.

00:31:04.280 --> 00:31:06.490
You don't necessarily see
all of the communication.

00:31:06.490 --> 00:31:09.160
But it's hard for
people to forget what's

00:31:09.160 --> 00:31:10.540
actually going on online.

00:31:10.540 --> 00:31:12.352
And so, mixing these
two things together,

00:31:12.352 --> 00:31:13.810
you actually get
different pictures

00:31:13.810 --> 00:31:16.340
of how people are communicating.

00:31:16.340 --> 00:31:21.700
And so I think the richness of
the data and the understanding

00:31:21.700 --> 00:31:24.240
that it actually matters,
both in terms of immobility,

00:31:24.240 --> 00:31:26.920
and equality, polarization,
and these kinds of issues,

00:31:26.920 --> 00:31:30.040
mean that it's becoming--
it's an area of study that's

00:31:30.040 --> 00:31:32.933
exploding, especially
for an economist.

00:31:32.933 --> 00:31:34.350
It's happening in
labor economics.

00:31:34.350 --> 00:31:36.017
It's happening in
development economics,

00:31:36.017 --> 00:31:39.150
where people are trying to
figure out how to help people.

00:31:39.150 --> 00:31:42.610
And then it's happening
in computer science.

00:31:42.610 --> 00:31:44.620
And now there's more
and more realization

00:31:44.620 --> 00:31:46.240
that the algorithms matter.

00:31:46.240 --> 00:31:48.035
And thinking of an
algorithm not just

00:31:48.035 --> 00:31:49.910
for how it's going to
affect a certain person

00:31:49.910 --> 00:31:53.330
but how it's going to affect
a group is a different issue.

00:31:53.330 --> 00:31:55.360
And so I think it's a
really wonderful time

00:31:55.360 --> 00:31:56.920
to be thinking about this.

00:31:56.920 --> 00:31:59.610
AUDIENCE: You were talking
about the rent vouchers study.

00:31:59.610 --> 00:32:02.068
And you were saying that there
were three different groups.

00:32:02.068 --> 00:32:03.310
There was the control.

00:32:03.310 --> 00:32:04.330
Everyone got vouchers.

00:32:04.330 --> 00:32:07.420
And then they got
vouchers if they moved.

00:32:07.420 --> 00:32:11.470
You were talking about better
outcomes for the people who

00:32:11.470 --> 00:32:12.490
moved and got vouchers.

00:32:15.050 --> 00:32:18.955
Were those better outcomes
with respect to the control

00:32:18.955 --> 00:32:20.770
or with respect
to the people who

00:32:20.770 --> 00:32:22.030
got vouchers but didn't move?

00:32:22.030 --> 00:32:24.970
And also, how did the people
who got vouchers but didn't move

00:32:24.970 --> 00:32:26.365
do with respect to the control?

00:32:26.365 --> 00:32:27.490
MATTHEW O. JACKSON: Right--

00:32:27.490 --> 00:32:28.282
very good question.

00:32:28.282 --> 00:32:31.300
So the comparison I
gave for the $300,000

00:32:31.300 --> 00:32:34.840
was between the group that
got vouchers and moved

00:32:34.840 --> 00:32:36.277
and then the control group.

00:32:36.277 --> 00:32:38.110
And then when you look
within the group that

00:32:38.110 --> 00:32:40.800
got vouchers but
didn't have to move,

00:32:40.800 --> 00:32:43.120
the people who
actually chose to move

00:32:43.120 --> 00:32:47.380
ended up looking like the
group that had to move.

00:32:47.380 --> 00:32:49.240
And the people who
didn't move looked

00:32:49.240 --> 00:32:52.780
slightly better than the
control group but not much.

00:32:52.780 --> 00:32:54.370
So I think, for
an eight-year-old,

00:32:54.370 --> 00:32:58.720
it will be more on the
order of like $20,000 as

00:32:58.720 --> 00:32:59.730
opposed to $300,000.

00:32:59.730 --> 00:33:02.770
So it was a small effect for
the people who got the vouchers

00:33:02.770 --> 00:33:04.360
but didn't move.

00:33:04.360 --> 00:33:06.153
And it depended.

00:33:06.153 --> 00:33:08.070
Some of those groups
actually-- they moved in,

00:33:08.070 --> 00:33:10.122
and it made a huge
difference for them.

00:33:10.122 --> 00:33:10.830
AUDIENCE: Thanks.

00:33:10.830 --> 00:33:11.450
MATTHEW O. JACKSON: Yeah.

00:33:11.450 --> 00:33:12.250
AUDIENCE: Another
question that's

00:33:12.250 --> 00:33:13.750
kind of related to
what I was asking

00:33:13.750 --> 00:33:18.970
before is how the practice
of economics has changed.

00:33:18.970 --> 00:33:21.940
With the change
of technologies, I

00:33:21.940 --> 00:33:25.640
don't imagine people were doing
network science and economics

00:33:25.640 --> 00:33:27.760
30 years ago or something.

00:33:27.760 --> 00:33:32.710
And also, what developments
in other fields

00:33:32.710 --> 00:33:36.640
have been adopted to
success in economics?

00:33:36.640 --> 00:33:39.300
I recognize some of these
things from statistical physics,

00:33:39.300 --> 00:33:42.360
like looking at the degree
distribution, following a power

00:33:42.360 --> 00:33:44.600
law, looking like this.

00:33:44.600 --> 00:33:47.190
But I'm just
wondering if there is

00:33:47.190 --> 00:33:50.170
much of an impact
from other fields

00:33:50.170 --> 00:33:53.400
of basic science in
economics and how

00:33:53.400 --> 00:33:54.400
it's changed for people?

00:33:54.400 --> 00:33:56.317
MATTHEW O. JACKSON: Oh,
great question-- yeah,

00:33:56.317 --> 00:33:58.570
so I think of it as--

00:33:58.570 --> 00:34:03.580
classic economics thought about
markets in an anonymous way.

00:34:03.580 --> 00:34:07.380
So you had people who processed
information, made choices,

00:34:07.380 --> 00:34:09.130
weighed costs and benefits.

00:34:09.130 --> 00:34:12.679
And a lot of the basic
economics was driven by that.

00:34:12.679 --> 00:34:16.900
And I think of it as there
had been two influences that

00:34:16.900 --> 00:34:21.130
have a chance to make a big
difference in understanding

00:34:21.130 --> 00:34:22.400
a lot of these things.

00:34:22.400 --> 00:34:25.420
One is social
structure and networks.

00:34:25.420 --> 00:34:28.750
And the other, which brings
in from a different angle,

00:34:28.750 --> 00:34:31.429
is what's known as
behavioral economics,

00:34:31.429 --> 00:34:34.750
which is getting a lot
of play these days,

00:34:34.750 --> 00:34:37.870
where you look at psychological
biases that people have--

00:34:37.870 --> 00:34:40.840
overconfidence, or
procrastination,

00:34:40.840 --> 00:34:41.889
other kinds of things--

00:34:41.889 --> 00:34:44.514
and then try and understand how
that plays into decision making

00:34:44.514 --> 00:34:46.449
and how that systematically
biases things.

00:34:46.449 --> 00:34:49.270
So you can think about it as--

00:34:49.270 --> 00:34:52.889
people were thinking of
fully rational people--

00:34:52.889 --> 00:34:56.110
was the classic setting,
where not only were people

00:34:56.110 --> 00:34:57.920
able to process all
their information,

00:34:57.920 --> 00:35:00.850
but they had all the
information that was out there.

00:35:00.850 --> 00:35:03.513
And this gives you
more of a feeling for--

00:35:03.513 --> 00:35:05.680
look, people are constrained
by their opportunities.

00:35:05.680 --> 00:35:08.980
They're constrained by
their information sets.

00:35:08.980 --> 00:35:12.670
And they also have
behavioral biases.

00:35:12.670 --> 00:35:16.540
For instance, in our
studies, when I talked

00:35:16.540 --> 00:35:19.180
about what's known as
correlation neglect--

00:35:19.180 --> 00:35:22.150
the fact that I get seven
friends who tell me something,

00:35:22.150 --> 00:35:25.210
and I treat that is seven
independent observations.

00:35:25.210 --> 00:35:27.310
It turns out that
they're all correlated.

00:35:27.310 --> 00:35:29.680
They all heard it
from the same person.

00:35:29.680 --> 00:35:32.710
That's something which is both
psychological and influenced

00:35:32.710 --> 00:35:33.940
by the network.

00:35:33.940 --> 00:35:36.580
And it's something
you can measure.

00:35:36.580 --> 00:35:38.950
So if you were a
good Bayesian and you

00:35:38.950 --> 00:35:41.980
understood how these networks
worked, you could undo that.

00:35:41.980 --> 00:35:44.230
And you could say, OK, well,
there's actually a chance

00:35:44.230 --> 00:35:46.030
that I'm hearing
this indirectly.

00:35:46.030 --> 00:35:48.220
And just in my own
thinking, I think

00:35:48.220 --> 00:35:51.790
I am very different
in the way I act now

00:35:51.790 --> 00:35:54.290
because of studying networks.

00:35:54.290 --> 00:35:56.687
So one is, when people
tell me something,

00:35:56.687 --> 00:35:58.270
I ask them where
they heard that from.

00:35:58.270 --> 00:36:00.080
Where did the
information come from?

00:36:00.080 --> 00:36:04.880
And then I also try to
reach out across groups.

00:36:04.880 --> 00:36:06.418
So I go to sociology
conferences.

00:36:06.418 --> 00:36:07.960
I go to computer
science conferences.

00:36:07.960 --> 00:36:09.940
I go to statistical
physics conferences

00:36:09.940 --> 00:36:13.240
to try and find new
ideas and information

00:36:13.240 --> 00:36:15.490
that I wouldn't be getting
just from economists.

00:36:15.490 --> 00:36:19.250
And I think, the more
social sciences can do that,

00:36:19.250 --> 00:36:21.160
the better off we'll be.

00:36:21.160 --> 00:36:24.420
AUDIENCE: It seems like a lot
of the interesting observations

00:36:24.420 --> 00:36:27.130
are generated by this idea
that there are naturally

00:36:27.130 --> 00:36:33.790
clusters within the graph here.

00:36:33.790 --> 00:36:36.282
So I was wondering if you
have good, formalized ways

00:36:36.282 --> 00:36:37.240
of thinking about this?

00:36:37.240 --> 00:36:40.620
I've seen ideas like the
normalized cut and whatnot--

00:36:40.620 --> 00:36:42.472
but are very hard
to actually compute.

00:36:42.472 --> 00:36:44.680
And I was wondering if you
had a good, formalized way

00:36:44.680 --> 00:36:47.090
of thinking about clusters
and whether that's

00:36:47.090 --> 00:36:49.090
the terms in which you
think about these things?

00:36:49.090 --> 00:36:50.790
MATTHEW O. JACKSON: Right.

00:36:50.790 --> 00:36:53.050
So there's an area
of network science

00:36:53.050 --> 00:36:55.090
which is called
community detection.

00:36:55.090 --> 00:36:57.790
And the idea is, as
you're mentioning,

00:36:57.790 --> 00:36:58.780
you put down a graph.

00:36:58.780 --> 00:37:01.060
And then you try
and find the cuts.

00:37:01.060 --> 00:37:03.520
So here, it's not too hard
to see where the cut is.

00:37:03.520 --> 00:37:05.960
It's right in the middle.

00:37:05.960 --> 00:37:09.340
But in these more
complicated areas, how much

00:37:09.340 --> 00:37:12.160
do I dissect a network?

00:37:12.160 --> 00:37:14.170
How do I divide
it up into groups?

00:37:14.170 --> 00:37:17.230
And I actually have a paper
I just wrote with a student

00:37:17.230 --> 00:37:18.520
at Stanford.

00:37:18.520 --> 00:37:20.560
And what we do is say, well--

00:37:20.560 --> 00:37:23.320
and a lot of it works just
off of graph structure.

00:37:23.320 --> 00:37:26.860
So you can look at what's known
as the spectrum of the graph

00:37:26.860 --> 00:37:28.900
or other kinds of
things, and then

00:37:28.900 --> 00:37:30.700
use those to try and
split the graph up.

00:37:30.700 --> 00:37:32.570
There's a lot of
different ways to do it.

00:37:32.570 --> 00:37:35.140
But what we did,
instead, was say, well,

00:37:35.140 --> 00:37:38.230
if we're trying to do an
economic application with it,

00:37:38.230 --> 00:37:42.940
then we want to ask, how would
people behave on this graph?

00:37:42.940 --> 00:37:45.160
And let's build the communities
out of the behaviors

00:37:45.160 --> 00:37:46.630
that they would induce.

00:37:46.630 --> 00:37:50.180
So instead, you actually
say-- for instance,

00:37:50.180 --> 00:37:53.380
let's suppose I have a high
school, and most of the kids

00:37:53.380 --> 00:37:56.500
are going to act like the
majority of their friends.

00:37:56.500 --> 00:37:58.440
How does that split up a graph?

00:37:58.440 --> 00:38:01.890
And which groups will end
up acting like each other

00:38:01.890 --> 00:38:03.910
consistently?

00:38:03.910 --> 00:38:07.220
But none of this turns
out to be easy to compute.

00:38:07.220 --> 00:38:09.130
So all of it, in
large graphs, has

00:38:09.130 --> 00:38:10.530
to be done by some kind of--

00:38:10.530 --> 00:38:13.590
these are all NP-Complete
or NP-Hard problems.

00:38:13.590 --> 00:38:16.880
And so you have no choice but to
somehow use an algorithm that's

00:38:16.880 --> 00:38:18.650
going to do an approximation.

00:38:18.650 --> 00:38:20.150
But in a lot of
graphs, there's ways

00:38:20.150 --> 00:38:25.400
to do it that I think gives
you sensible outcomes.

00:38:25.400 --> 00:38:26.580
And they can help.

00:38:26.580 --> 00:38:28.250
We're doing work
actually in India now,

00:38:28.250 --> 00:38:32.720
where we're trying to get
increase in vaccination uptake.

00:38:32.720 --> 00:38:34.520
So we're going into
villages, and we're

00:38:34.520 --> 00:38:35.840
trying to reach people.

00:38:35.840 --> 00:38:37.890
And we're trying to figure
out how to reach them.

00:38:37.890 --> 00:38:40.640
And part of that involves
figuring out this structure

00:38:40.640 --> 00:38:42.908
and then figuring out
how to target people

00:38:42.908 --> 00:38:45.200
inside different groups, and
make sure that they're all

00:38:45.200 --> 00:38:48.122
hearing about the programs.

00:38:48.122 --> 00:38:50.330
AUDIENCE: It's just a
follow-up on that last comment.

00:38:50.330 --> 00:38:53.180
I was curious what
heuristics or tests

00:38:53.180 --> 00:38:55.250
you could do to
probe a population

00:38:55.250 --> 00:38:58.480
to determine those clusters
without having the graph?

00:38:58.480 --> 00:38:59.810
MATTHEW O. JACKSON: Yeah.

00:38:59.810 --> 00:39:02.030
So that's a really tricky thing.

00:39:02.030 --> 00:39:04.880
Here I've been showing you
graphs where we actually

00:39:04.880 --> 00:39:06.620
have all the information.

00:39:06.620 --> 00:39:09.880
And one study we
did-- so it turns out,

00:39:09.880 --> 00:39:11.930
there's two things that
are true about people

00:39:11.930 --> 00:39:14.750
and what their knowledge of
the graph around them is.

00:39:14.750 --> 00:39:18.860
First of all, suppose I ask
you to name your friends.

00:39:18.860 --> 00:39:20.570
Well, that's
something you can do.

00:39:20.570 --> 00:39:26.780
But now if I ask you to name
the other people in this Google

00:39:26.780 --> 00:39:29.270
cluster that are
friends with each other,

00:39:29.270 --> 00:39:32.450
it turns out people are
slightly better than coin flips

00:39:32.450 --> 00:39:35.450
at doing that but not great.

00:39:35.450 --> 00:39:38.030
So actually knowing who else
is really friends with whom

00:39:38.030 --> 00:39:41.540
and who's talking to
whom is not so easy.

00:39:41.540 --> 00:39:43.850
And so it's very difficult
to actually ask people

00:39:43.850 --> 00:39:45.870
to reconstruct the graph.

00:39:45.870 --> 00:39:49.250
But it turns out that people
are very good at naming

00:39:49.250 --> 00:39:52.700
who's central in the graph--

00:39:52.700 --> 00:39:55.220
and central not just in
terms of popular but central

00:39:55.220 --> 00:40:00.030
in terms of actually Google,
PageRank, and BackRub,

00:40:00.030 --> 00:40:02.510
and other notions of--

00:40:02.510 --> 00:40:03.617
you're popular.

00:40:03.617 --> 00:40:05.450
You're not just popular,
but you're actually

00:40:05.450 --> 00:40:07.670
well-connected to other
well-connected people who

00:40:07.670 --> 00:40:09.560
can be influential.

00:40:09.560 --> 00:40:11.930
And if you ask people, who
are the influential people,

00:40:11.930 --> 00:40:14.150
you can actually get
very good answers.

00:40:14.150 --> 00:40:18.080
And building off of
that, you're able to do

00:40:18.080 --> 00:40:22.340
some statistical
reconstruction of a graph.

00:40:22.340 --> 00:40:24.200
You can't reconstruct
the graph perfectly.

00:40:24.200 --> 00:40:26.580
But you can get some
ideas of at least

00:40:26.580 --> 00:40:28.640
who the key individuals
are and which groups

00:40:28.640 --> 00:40:29.900
don't connect with each other.

00:40:29.900 --> 00:40:31.400
So there's techniques
of doing that.

00:40:31.400 --> 00:40:33.320
And I'd be happy to share
references with you.

00:40:33.320 --> 00:40:35.690
But it's just a growing area.

00:40:35.690 --> 00:40:40.680
It's starting to grow
right now and study.

00:40:40.680 --> 00:40:43.740
AUDIENCE: So I was wondering,
in the example you showed before

00:40:43.740 --> 00:40:47.220
of the graph of social
connections in the village

00:40:47.220 --> 00:40:51.210
in India where they have
these clique-like things

00:40:51.210 --> 00:40:53.070
in the graph--

00:40:53.070 --> 00:40:56.880
so are you able
to identify things

00:40:56.880 --> 00:41:01.530
that we might expect,
like either the leader

00:41:01.530 --> 00:41:07.050
of those cliques or an
ambassador between cliques

00:41:07.050 --> 00:41:09.960
reasonably reliably--
or things like that?

00:41:09.960 --> 00:41:11.730
MATTHEW O. JACKSON:
So two things--

00:41:11.730 --> 00:41:14.490
one, when you're trying
to identify the people who

00:41:14.490 --> 00:41:17.220
turned out to be central-- so
we were partnering with a bank

00:41:17.220 --> 00:41:20.310
in terms of trying to get the
microfinance information out.

00:41:20.310 --> 00:41:24.090
And their algorithm was
to try and locate people

00:41:24.090 --> 00:41:26.060
that they thought were central.

00:41:26.060 --> 00:41:28.560
And the way they were doing
that was looking for people that

00:41:28.560 --> 00:41:31.943
were teachers, self-help
group leaders, shopkeepers,

00:41:31.943 --> 00:41:34.110
people they thought interacted
with a lot of people.

00:41:34.110 --> 00:41:35.610
It turns out that,
in many villages,

00:41:35.610 --> 00:41:37.260
those weren't central people.

00:41:37.260 --> 00:41:38.940
And so identifying
central people--

00:41:38.940 --> 00:41:40.800
part of the technique
we're using now

00:41:40.800 --> 00:41:43.800
is really to go in, and ask,
and then snowball sample.

00:41:43.800 --> 00:41:45.540
So we ask somebody
for somebody central.

00:41:45.540 --> 00:41:46.582
Then we ask those people.

00:41:46.582 --> 00:41:48.960
They tend to be even better
at naming central people.

00:41:48.960 --> 00:41:51.870
And then you can quickly
triangulate on them.

00:41:51.870 --> 00:41:59.130
In terms of identifying the
clusters and who the people are

00:41:59.130 --> 00:42:03.690
that go across them, there
are two extreme groups

00:42:03.690 --> 00:42:07.800
that are people who
are big connectors.

00:42:07.800 --> 00:42:12.510
So one type is a type who
is actually an outcast.

00:42:12.510 --> 00:42:15.090
So in some cases,
you'll find a widow.

00:42:15.090 --> 00:42:16.830
In Indian villages,
being a widow

00:42:16.830 --> 00:42:20.010
without actually being part
of a family is really tough.

00:42:20.010 --> 00:42:22.900
And you'll find some of them
falling between the cracks

00:42:22.900 --> 00:42:25.170
and then reaching
out across groups.

00:42:25.170 --> 00:42:27.090
And then you also
find some people

00:42:27.090 --> 00:42:30.870
who are the major political
figures or connectors

00:42:30.870 --> 00:42:33.000
in the villages,
depending on the politics.

00:42:33.000 --> 00:42:34.920
It depends on which
village you're looking at.

00:42:34.920 --> 00:42:39.030
But some of them actually
reach across the aisle.

00:42:39.030 --> 00:42:43.020
And those people-- there's a
bunch of studies in science now

00:42:43.020 --> 00:42:44.940
that are looking
at teams of people

00:42:44.940 --> 00:42:49.020
doing research and finding that
the people who are actually

00:42:49.020 --> 00:42:51.330
those connectors tend
to often have the most

00:42:51.330 --> 00:42:53.190
creative and innovative work.

00:42:53.190 --> 00:42:55.650
And so there's
actually rewards to it.

00:42:55.650 --> 00:42:58.178
But they come from
both sides of the--

00:42:58.178 --> 00:42:59.970
people who are doing
really well and people

00:42:59.970 --> 00:43:01.255
who are doing really poorly.

00:43:01.255 --> 00:43:02.880
And it depends on
the context, I think,

00:43:02.880 --> 00:43:04.595
as to who those connectors are.

00:43:04.595 --> 00:43:05.970
In the book I
actually spend time

00:43:05.970 --> 00:43:08.430
talking about the
Cosimo de Medici

00:43:08.430 --> 00:43:12.540
and how he engineered the rise
of the Medici in Florence.

00:43:12.540 --> 00:43:13.708
And he was a person--

00:43:13.708 --> 00:43:14.250
it's amazing.

00:43:14.250 --> 00:43:16.140
When you look at
that graph, he looks

00:43:16.140 --> 00:43:17.670
pretty much like a star graph.

00:43:17.670 --> 00:43:19.800
He was really connecting
a lot of other people

00:43:19.800 --> 00:43:21.150
who weren't connected.

00:43:21.150 --> 00:43:24.870
And that was part of the
key to his political clout.

00:43:24.870 --> 00:43:28.110
And they rose, even though they
weren't the wealthiest or most

00:43:28.110 --> 00:43:29.790
politically powerful family.

00:43:29.790 --> 00:43:33.200
But that network position
was really instrumental.

00:43:33.200 --> 00:43:35.470
Thanks a lot for having me.

