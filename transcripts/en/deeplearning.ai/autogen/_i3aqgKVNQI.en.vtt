WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.419
 
hello and welcome to this final week of

00:00:02.419 --> 00:00:02.429
hello and welcome to this final week of
 

00:00:02.429 --> 00:00:04.460
hello and welcome to this final week of
this course as well as to the final week

00:00:04.460 --> 00:00:04.470
this course as well as to the final week
 

00:00:04.470 --> 00:00:07.039
this course as well as to the final week
of this sequence of five courses in the

00:00:07.039 --> 00:00:07.049
of this sequence of five courses in the
 

00:00:07.049 --> 00:00:09.470
of this sequence of five courses in the
deep learning specialization you're

00:00:09.470 --> 00:00:09.480
deep learning specialization you're
 

00:00:09.480 --> 00:00:12.470
deep learning specialization you're
nearly at the finish line in this week

00:00:12.470 --> 00:00:12.480
nearly at the finish line in this week
 

00:00:12.480 --> 00:00:14.539
nearly at the finish line in this week
you hear about sequences sequence models

00:00:14.539 --> 00:00:14.549
you hear about sequences sequence models
 

00:00:14.549 --> 00:00:16.460
you hear about sequences sequence models
which are useful for everything from

00:00:16.460 --> 00:00:16.470
which are useful for everything from
 

00:00:16.470 --> 00:00:18.380
which are useful for everything from
machine translation to speech

00:00:18.380 --> 00:00:18.390
machine translation to speech
 

00:00:18.390 --> 00:00:20.689
machine translation to speech
recognition the start of the basic

00:00:20.689 --> 00:00:20.699
recognition the start of the basic
 

00:00:20.699 --> 00:00:22.910
recognition the start of the basic
models and then later this week you hear

00:00:22.910 --> 00:00:22.920
models and then later this week you hear
 

00:00:22.920 --> 00:00:24.830
models and then later this week you hear
about beam search the attention model

00:00:24.830 --> 00:00:24.840
about beam search the attention model
 

00:00:24.840 --> 00:00:26.599
about beam search the attention model
and we'll wrap up the discussion of

00:00:26.599 --> 00:00:26.609
and we'll wrap up the discussion of
 

00:00:26.609 --> 00:00:29.599
and we'll wrap up the discussion of
models for audio data like speech let's

00:00:29.599 --> 00:00:29.609
models for audio data like speech let's
 

00:00:29.609 --> 00:00:33.410
models for audio data like speech let's
get started let's say you want to input

00:00:33.410 --> 00:00:33.420
get started let's say you want to input
 

00:00:33.420 --> 00:00:36.350
get started let's say you want to input
a French sentence like John vesicular

00:00:36.350 --> 00:00:36.360
a French sentence like John vesicular
 

00:00:36.360 --> 00:00:39.500
a French sentence like John vesicular
freak and September and you want to

00:00:39.500 --> 00:00:39.510
freak and September and you want to
 

00:00:39.510 --> 00:00:41.420
freak and September and you want to
translate it to the English sentence

00:00:41.420 --> 00:00:41.430
translate it to the English sentence
 

00:00:41.430 --> 00:00:44.229
translate it to the English sentence
Jane is visiting Africa in September as

00:00:44.229 --> 00:00:44.239
Jane is visiting Africa in September as
 

00:00:44.239 --> 00:00:48.619
Jane is visiting Africa in September as
usual let's use X 1 through X in this

00:00:48.619 --> 00:00:48.629
usual let's use X 1 through X in this
 

00:00:48.629 --> 00:00:51.080
usual let's use X 1 through X in this
case 5 to represent the words in the

00:00:51.080 --> 00:00:51.090
case 5 to represent the words in the
 

00:00:51.090 --> 00:00:54.529
case 5 to represent the words in the
input sequence and we'll use y1 through

00:00:54.529 --> 00:00:54.539
input sequence and we'll use y1 through
 

00:00:54.539 --> 00:00:57.350
input sequence and we'll use y1 through
y 6 to represent the words in the output

00:00:57.350 --> 00:00:57.360
y 6 to represent the words in the output
 

00:00:57.360 --> 00:01:00.380
y 6 to represent the words in the output
sequence so how can you train a neural

00:01:00.380 --> 00:01:00.390
sequence so how can you train a neural
 

00:01:00.390 --> 00:01:03.799
sequence so how can you train a neural
network to input the sequence X and

00:01:03.799 --> 00:01:03.809
network to input the sequence X and
 

00:01:03.809 --> 00:01:06.560
network to input the sequence X and
output the sequence Y well here's

00:01:06.560 --> 00:01:06.570
output the sequence Y well here's
 

00:01:06.570 --> 00:01:09.260
output the sequence Y well here's
something you could do and the ideas I'm

00:01:09.260 --> 00:01:09.270
something you could do and the ideas I'm
 

00:01:09.270 --> 00:01:12.050
something you could do and the ideas I'm
about to present our mainly from these

00:01:12.050 --> 00:01:12.060
about to present our mainly from these
 

00:01:12.060 --> 00:01:15.920
about to present our mainly from these
two papers due to the Asafa or even

00:01:15.920 --> 00:01:15.930
two papers due to the Asafa or even
 

00:01:15.930 --> 00:01:19.450
two papers due to the Asafa or even
yells and Kotler and that one by

00:01:19.450 --> 00:01:19.460
yells and Kotler and that one by
 

00:01:19.460 --> 00:01:22.850
yells and Kotler and that one by
Jonghyun Chobot then Marienburg kepler

00:01:22.850 --> 00:01:22.860
Jonghyun Chobot then Marienburg kepler
 

00:01:22.860 --> 00:01:26.270
Jonghyun Chobot then Marienburg kepler
golf Sara Dmitry bother Neil veggie

00:01:26.270 --> 00:01:26.280
golf Sara Dmitry bother Neil veggie
 

00:01:26.280 --> 00:01:28.660
golf Sara Dmitry bother Neil veggie
burgers Holger strengthen your ginger

00:01:28.660 --> 00:01:28.670
burgers Holger strengthen your ginger
 

00:01:28.670 --> 00:01:32.420
burgers Holger strengthen your ginger
first let's have a network which we're

00:01:32.420 --> 00:01:32.430
first let's have a network which we're
 

00:01:32.430 --> 00:01:36.319
first let's have a network which we're
gonna call the encoder Network be built

00:01:36.319 --> 00:01:36.329
gonna call the encoder Network be built
 

00:01:36.329 --> 00:01:39.800
gonna call the encoder Network be built
as a RNN and this could be a gr you are

00:01:39.800 --> 00:01:39.810
as a RNN and this could be a gr you are
 

00:01:39.810 --> 00:01:43.639
as a RNN and this could be a gr you are
now STM feed in d input french words one

00:01:43.639 --> 00:01:43.649
now STM feed in d input french words one
 

00:01:43.649 --> 00:01:47.109
now STM feed in d input french words one
word at a time and after ingesting the

00:01:47.109 --> 00:01:47.119
word at a time and after ingesting the
 

00:01:47.119 --> 00:01:51.260
word at a time and after ingesting the
input sequence d RNN then outputs a

00:01:51.260 --> 00:01:51.270
input sequence d RNN then outputs a
 

00:01:51.270 --> 00:01:54.380
input sequence d RNN then outputs a
vector that represents the input

00:01:54.380 --> 00:01:54.390
vector that represents the input
 

00:01:54.390 --> 00:01:57.520
vector that represents the input
sentence after that you can build a

00:01:57.520 --> 00:01:57.530
sentence after that you can build a
 

00:01:57.530 --> 00:02:00.080
sentence after that you can build a
decoder network which you might draw

00:02:00.080 --> 00:02:00.090
decoder network which you might draw
 

00:02:00.090 --> 00:02:03.920
decoder network which you might draw
here which takes as input the encoding

00:02:03.920 --> 00:02:03.930
here which takes as input the encoding
 

00:02:03.930 --> 00:02:06.109
here which takes as input the encoding
output by the encode the network shown

00:02:06.109 --> 00:02:06.119
output by the encode the network shown
 

00:02:06.119 --> 00:02:08.740
output by the encode the network shown
in black on the left and then

00:02:08.740 --> 00:02:08.750
in black on the left and then
 

00:02:08.750 --> 00:02:13.740
in black on the left and then
can be trained to output the translation

00:02:13.740 --> 00:02:13.750
can be trained to output the translation
 

00:02:13.750 --> 00:02:19.150
can be trained to output the translation
one word at a time until eventually it

00:02:19.150 --> 00:02:19.160
one word at a time until eventually it
 

00:02:19.160 --> 00:02:23.740
one word at a time until eventually it
opens dia say the end of sequence and

00:02:23.740 --> 00:02:23.750
opens dia say the end of sequence and
 

00:02:23.750 --> 00:02:26.290
opens dia say the end of sequence and
the sentence token upon which the

00:02:26.290 --> 00:02:26.300
the sentence token upon which the
 

00:02:26.300 --> 00:02:29.800
the sentence token upon which the
decoder stops and as usual we could take

00:02:29.800 --> 00:02:29.810
decoder stops and as usual we could take
 

00:02:29.810 --> 00:02:31.510
decoder stops and as usual we could take
the generated tokens and feed them to

00:02:31.510 --> 00:02:31.520
the generated tokens and feed them to
 

00:02:31.520 --> 00:02:33.390
the generated tokens and feed them to
the Knicks

00:02:33.390 --> 00:02:33.400
the Knicks
 

00:02:33.400 --> 00:02:36.040
the Knicks
so the fated states in the sequence like

00:02:36.040 --> 00:02:36.050
so the fated states in the sequence like
 

00:02:36.050 --> 00:02:38.199
so the fated states in the sequence like
we're doing before when synthesizing

00:02:38.199 --> 00:02:38.209
we're doing before when synthesizing
 

00:02:38.209 --> 00:02:41.110
we're doing before when synthesizing
text using the language model one of the

00:02:41.110 --> 00:02:41.120
text using the language model one of the
 

00:02:41.120 --> 00:02:43.390
text using the language model one of the
most remarkable recent results in deep

00:02:43.390 --> 00:02:43.400
most remarkable recent results in deep
 

00:02:43.400 --> 00:02:45.580
most remarkable recent results in deep
learning is that this model works

00:02:45.580 --> 00:02:45.590
learning is that this model works
 

00:02:45.590 --> 00:02:48.610
learning is that this model works
given enough pairs of French and English

00:02:48.610 --> 00:02:48.620
given enough pairs of French and English
 

00:02:48.620 --> 00:02:52.390
given enough pairs of French and English
sentences if you train a model to input

00:02:52.390 --> 00:02:52.400
sentences if you train a model to input
 

00:02:52.400 --> 00:02:55.270
sentences if you train a model to input
a French sentence and output the

00:02:55.270 --> 00:02:55.280
a French sentence and output the
 

00:02:55.280 --> 00:02:57.190
a French sentence and output the
corresponding English translation this

00:02:57.190 --> 00:02:57.200
corresponding English translation this
 

00:02:57.200 --> 00:02:59.440
corresponding English translation this
won't actually work decently well and

00:02:59.440 --> 00:02:59.450
won't actually work decently well and
 

00:02:59.450 --> 00:03:02.620
won't actually work decently well and
this model simply uses an encoding

00:03:02.620 --> 00:03:02.630
this model simply uses an encoding
 

00:03:02.630 --> 00:03:04.630
this model simply uses an encoding
network whose job it is to find an

00:03:04.630 --> 00:03:04.640
network whose job it is to find an
 

00:03:04.640 --> 00:03:07.270
network whose job it is to find an
encoding of the input French sentence

00:03:07.270 --> 00:03:07.280
encoding of the input French sentence
 

00:03:07.280 --> 00:03:10.510
encoding of the input French sentence
and then use a decoder network to then

00:03:10.510 --> 00:03:10.520
and then use a decoder network to then
 

00:03:10.520 --> 00:03:12.880
and then use a decoder network to then
generate the corresponding English

00:03:12.880 --> 00:03:12.890
generate the corresponding English
 

00:03:12.890 --> 00:03:16.090
generate the corresponding English
translation and architecture very

00:03:16.090 --> 00:03:16.100
translation and architecture very
 

00:03:16.100 --> 00:03:19.360
translation and architecture very
similar to this also works for image

00:03:19.360 --> 00:03:19.370
similar to this also works for image
 

00:03:19.370 --> 00:03:23.289
similar to this also works for image
captioning so given an image like the

00:03:23.289 --> 00:03:23.299
captioning so given an image like the
 

00:03:23.299 --> 00:03:25.240
captioning so given an image like the
one shown here maybe you wanted to be

00:03:25.240 --> 00:03:25.250
one shown here maybe you wanted to be
 

00:03:25.250 --> 00:03:28.000
one shown here maybe you wanted to be
captions automatically as a cat sitting

00:03:28.000 --> 00:03:28.010
captions automatically as a cat sitting
 

00:03:28.010 --> 00:03:30.699
captions automatically as a cat sitting
on the chair so how do you train in your

00:03:30.699 --> 00:03:30.709
on the chair so how do you train in your
 

00:03:30.709 --> 00:03:33.539
on the chair so how do you train in your
network to input an image and output a

00:03:33.539 --> 00:03:33.549
network to input an image and output a
 

00:03:33.549 --> 00:03:39.250
network to input an image and output a
caption like that phrase up there here's

00:03:39.250 --> 00:03:39.260
caption like that phrase up there here's
 

00:03:39.260 --> 00:03:42.190
caption like that phrase up there here's
what you can do from the earlier course

00:03:42.190 --> 00:03:42.200
what you can do from the earlier course
 

00:03:42.200 --> 00:03:44.410
what you can do from the earlier course
on confidence you've seen how you can

00:03:44.410 --> 00:03:44.420
on confidence you've seen how you can
 

00:03:44.420 --> 00:03:47.500
on confidence you've seen how you can
input an image into a convolutional

00:03:47.500 --> 00:03:47.510
input an image into a convolutional
 

00:03:47.510 --> 00:03:50.440
input an image into a convolutional
network maybe a pre trained Alex net and

00:03:50.440 --> 00:03:50.450
network maybe a pre trained Alex net and
 

00:03:50.450 --> 00:03:53.319
network maybe a pre trained Alex net and
have that learn and encoding or learn a

00:03:53.319 --> 00:03:53.329
have that learn and encoding or learn a
 

00:03:53.329 --> 00:03:56.500
have that learn and encoding or learn a
set of features of the input image so

00:03:56.500 --> 00:03:56.510
set of features of the input image so
 

00:03:56.510 --> 00:03:58.539
set of features of the input image so
this is actually the Alex net

00:03:58.539 --> 00:03:58.549
this is actually the Alex net
 

00:03:58.549 --> 00:04:01.890
this is actually the Alex net
architecture and if we get rid of this

00:04:01.890 --> 00:04:01.900
architecture and if we get rid of this
 

00:04:01.900 --> 00:04:05.470
architecture and if we get rid of this
final softmax unit the pre-trained alex

00:04:05.470 --> 00:04:05.480
final softmax unit the pre-trained alex
 

00:04:05.480 --> 00:04:08.440
final softmax unit the pre-trained alex
net can give you a 4096 dimensional

00:04:08.440 --> 00:04:08.450
net can give you a 4096 dimensional
 

00:04:08.450 --> 00:04:10.479
net can give you a 4096 dimensional
feature vector or for each to represent

00:04:10.479 --> 00:04:10.489
feature vector or for each to represent
 

00:04:10.489 --> 00:04:14.380
feature vector or for each to represent
this picture of a cat and so this free

00:04:14.380 --> 00:04:14.390
this picture of a cat and so this free
 

00:04:14.390 --> 00:04:17.170
this picture of a cat and so this free
trained network can be the encoder

00:04:17.170 --> 00:04:17.180
trained network can be the encoder
 

00:04:17.180 --> 00:04:19.750
trained network can be the encoder
network for the image and you now have a

00:04:19.750 --> 00:04:19.760
network for the image and you now have a
 

00:04:19.760 --> 00:04:21.210
network for the image and you now have a
four thousand four thousand

00:04:21.210 --> 00:04:21.220
four thousand four thousand
 

00:04:21.220 --> 00:04:23.160
four thousand four thousand
ninety-six dimensional vector that

00:04:23.160 --> 00:04:23.170
ninety-six dimensional vector that
 

00:04:23.170 --> 00:04:26.010
ninety-six dimensional vector that
represents the image you can then take

00:04:26.010 --> 00:04:26.020
represents the image you can then take
 

00:04:26.020 --> 00:04:30.660
represents the image you can then take
this and feed it to an RNN whose job it

00:04:30.660 --> 00:04:30.670
this and feed it to an RNN whose job it
 

00:04:30.670 --> 00:04:35.490
this and feed it to an RNN whose job it
is to generate the caption one word at a

00:04:35.490 --> 00:04:35.500
is to generate the caption one word at a
 

00:04:35.500 --> 00:04:40.250
is to generate the caption one word at a
time so similar to what we saw with

00:04:40.250 --> 00:04:40.260
time so similar to what we saw with
 

00:04:40.260 --> 00:04:42.780
time so similar to what we saw with
machine translation translating from

00:04:42.780 --> 00:04:42.790
machine translation translating from
 

00:04:42.790 --> 00:04:46.010
machine translation translating from
French to English you can now input a

00:04:46.010 --> 00:04:46.020
French to English you can now input a
 

00:04:46.020 --> 00:04:49.500
French to English you can now input a
beaker vector describing the input and

00:04:49.500 --> 00:04:49.510
beaker vector describing the input and
 

00:04:49.510 --> 00:04:54.960
beaker vector describing the input and
then have it generate an output sequence

00:04:54.960 --> 00:04:54.970
then have it generate an output sequence
 

00:04:54.970 --> 00:04:57.450
then have it generate an output sequence
or output set of words one word at a

00:04:57.450 --> 00:04:57.460
or output set of words one word at a
 

00:04:57.460 --> 00:04:58.020
or output set of words one word at a
time

00:04:58.020 --> 00:04:58.030
time
 

00:04:58.030 --> 00:05:00.750
time
and this actually works pretty well for

00:05:00.750 --> 00:05:00.760
and this actually works pretty well for
 

00:05:00.760 --> 00:05:03.510
and this actually works pretty well for
image captioning especially the caption

00:05:03.510 --> 00:05:03.520
image captioning especially the caption
 

00:05:03.520 --> 00:05:06.960
image captioning especially the caption
want to generate is not too long as far

00:05:06.960 --> 00:05:06.970
want to generate is not too long as far
 

00:05:06.970 --> 00:05:09.960
want to generate is not too long as far
as I know this model this type of model

00:05:09.960 --> 00:05:09.970
as I know this model this type of model
 

00:05:09.970 --> 00:05:13.620
as I know this model this type of model
was first proposed by Chinua Malaysia Yi

00:05:13.620 --> 00:05:13.630
was first proposed by Chinua Malaysia Yi
 

00:05:13.630 --> 00:05:15.360
was first proposed by Chinua Malaysia Yi
Jung Yonghwa joo hyung-hwan

00:05:15.360 --> 00:05:15.370
Jung Yonghwa joo hyung-hwan
 

00:05:15.370 --> 00:05:17.760
Jung Yonghwa joo hyung-hwan
and alan zero although it turns out

00:05:17.760 --> 00:05:17.770
and alan zero although it turns out
 

00:05:17.770 --> 00:05:19.770
and alan zero although it turns out
there are multiple groups coming out

00:05:19.770 --> 00:05:19.780
there are multiple groups coming out
 

00:05:19.780 --> 00:05:21.810
there are multiple groups coming out
with very similar models independently

00:05:21.810 --> 00:05:21.820
with very similar models independently
 

00:05:21.820 --> 00:05:26.970
with very similar models independently
and at about the same time so two other

00:05:26.970 --> 00:05:26.980
and at about the same time so two other
 

00:05:26.980 --> 00:05:29.220
and at about the same time so two other
groups that had done very similar work

00:05:29.220 --> 00:05:29.230
groups that had done very similar work
 

00:05:29.230 --> 00:05:30.690
groups that had done very similar work
at about the same time and I think

00:05:30.690 --> 00:05:30.700
at about the same time and I think
 

00:05:30.700 --> 00:05:33.060
at about the same time and I think
independently of mouthal were all your

00:05:33.060 --> 00:05:33.070
independently of mouthal were all your
 

00:05:33.070 --> 00:05:35.850
independently of mouthal were all your
videos exams Atocha of Sammy banjo and

00:05:35.850 --> 00:05:35.860
videos exams Atocha of Sammy banjo and
 

00:05:35.860 --> 00:05:38.520
videos exams Atocha of Sammy banjo and
Dmitri Iran as well as our chica Posse

00:05:38.520 --> 00:05:38.530
Dmitri Iran as well as our chica Posse
 

00:05:38.530 --> 00:05:42.300
Dmitri Iran as well as our chica Posse
and David Lee so you've now seen how a

00:05:42.300 --> 00:05:42.310
and David Lee so you've now seen how a
 

00:05:42.310 --> 00:05:44.909
and David Lee so you've now seen how a
basic sequence the sequence model works

00:05:44.909 --> 00:05:44.919
basic sequence the sequence model works
 

00:05:44.919 --> 00:05:47.159
basic sequence the sequence model works
or how a basic image the sequence or

00:05:47.159 --> 00:05:47.169
or how a basic image the sequence or
 

00:05:47.169 --> 00:05:49.920
or how a basic image the sequence or
image captioning model works but there

00:05:49.920 --> 00:05:49.930
image captioning model works but there
 

00:05:49.930 --> 00:05:51.360
image captioning model works but there
are some differences between how you

00:05:51.360 --> 00:05:51.370
are some differences between how you
 

00:05:51.370 --> 00:05:53.969
are some differences between how you
would run a model like this to generate

00:05:53.969 --> 00:05:53.979
would run a model like this to generate
 

00:05:53.979 --> 00:05:56.340
would run a model like this to generate
the sequence compared to how you were

00:05:56.340 --> 00:05:56.350
the sequence compared to how you were
 

00:05:56.350 --> 00:05:59.400
the sequence compared to how you were
synthesizing novel text using a language

00:05:59.400 --> 00:05:59.410
synthesizing novel text using a language
 

00:05:59.410 --> 00:06:02.159
synthesizing novel text using a language
model one of the key differences is you

00:06:02.159 --> 00:06:02.169
model one of the key differences is you
 

00:06:02.169 --> 00:06:04.740
model one of the key differences is you
don't want a randomly chosen translation

00:06:04.740 --> 00:06:04.750
don't want a randomly chosen translation
 

00:06:04.750 --> 00:06:06.480
don't want a randomly chosen translation
you maybe want the most likely

00:06:06.480 --> 00:06:06.490
you maybe want the most likely
 

00:06:06.490 --> 00:06:08.550
you maybe want the most likely
translation you don't want the randomly

00:06:08.550 --> 00:06:08.560
translation you don't want the randomly
 

00:06:08.560 --> 00:06:10.860
translation you don't want the randomly
chosen caption maybe not but you might

00:06:10.860 --> 00:06:10.870
chosen caption maybe not but you might
 

00:06:10.870 --> 00:06:12.900
chosen caption maybe not but you might
want the best caption the most likely

00:06:12.900 --> 00:06:12.910
want the best caption the most likely
 

00:06:12.910 --> 00:06:15.450
want the best caption the most likely
caption so let's see in the next video

00:06:15.450 --> 00:06:15.460
caption so let's see in the next video
 

00:06:15.460 --> 00:06:19.350
caption so let's see in the next video
how you go about generating that

