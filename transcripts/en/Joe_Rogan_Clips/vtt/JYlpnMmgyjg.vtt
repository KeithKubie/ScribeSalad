WEBVTT

1
00:00:00.960 --> 00:00:02.460
The Joe Rogan experience,

2
00:00:03.000 --> 00:00:05.970
how do you think it's going to play out in terms of how people,

3
00:00:05.971 --> 00:00:10.050
various religions perceive this?
Yeah,
so there's a real variation.

4
00:00:10.051 --> 00:00:15.051
So there are people on one end of the spectrum who believe that this is quote

5
00:00:15.061 --> 00:00:16.410
unquote playing God.

6
00:00:16.500 --> 00:00:21.500
And if you believe that the world was created exactly as it is by some kind of,

7
00:00:22.590 --> 00:00:24.750
uh,
of divine force,
um,

8
00:00:24.810 --> 00:00:28.300
and that it's wrong for humans to change to,

9
00:00:28.301 --> 00:00:30.090
to quote unquote play God.

10
00:00:30.360 --> 00:00:34.110
It's hard to explain how you could justify everything that we've done.
I mean,

11
00:00:34.111 --> 00:00:37.710
we've changed the face of this,
uh,
of life on this planet earth.

12
00:00:38.190 --> 00:00:42.180
But I really respect people who say,
look,
I think that there's a line that,

13
00:00:42.570 --> 00:00:42.991
you know,
the,

14
00:00:42.991 --> 00:00:47.991
I believe that life begins at conception and that any kind of manipulation after

15
00:00:48.360 --> 00:00:52.590
conception is interfering.
That's going too far and I respect that.
Um,

16
00:00:52.920 --> 00:00:55.850
and those people need to have a seat at the table.
Um,

17
00:00:55.920 --> 00:01:00.060
and that's in there certainly very strong religious views.
In Judaism.

18
00:01:00.061 --> 00:01:04.350
There's an idea called Tikun Olam,
which means that the world is created,

19
00:01:04.380 --> 00:01:07.740
cracked and broken,
and it's the responsibility of each person to try to fix it.

20
00:01:07.741 --> 00:01:11.460
And that's a justification for using science and doing things to try to make the

21
00:01:11.461 --> 00:01:14.640
world a better place.
And then there are now these new kind of,

22
00:01:14.670 --> 00:01:17.580
I mean transhumanism,
it's almost like a religion.

23
00:01:17.581 --> 00:01:21.900
It's this religion of science.
And so we're going to have,
we're humans,

24
00:01:21.901 --> 00:01:26.670
we're so diverse.
We are going to have this level of diversity.

25
00:01:26.671 --> 00:01:30.750
And the challenge is how do we make,
how do we have a process that brings,

26
00:01:30.960 --> 00:01:34.800
brings everybody in.
But it's tough.
So when we're talking about genetic,

27
00:01:36.060 --> 00:01:38.100
any sort of genetic manipulation,

28
00:01:38.101 --> 00:01:41.640
we're basically talking about doing stuff to the wetwear,

29
00:01:41.670 --> 00:01:43.440
doing stuff to the biology.
Right?

30
00:01:43.950 --> 00:01:48.520
What do you think about symbiotic interactions with technology?
Because I was,

31
00:01:48.630 --> 00:01:52.530
one of the things that I'm concerned with more than anything is this sort of

32
00:01:52.531 --> 00:01:57.090
inevitable path of technology getting into our bodies,

33
00:01:57.091 --> 00:02:01.350
whether it's through nanobots fix diseases through implementation.

34
00:02:01.351 --> 00:02:03.930
When we were talking yesterday about chips,
right?
Like,
what would,

35
00:02:03.931 --> 00:02:06.660
what would they have to do to get you to get up,
put a chip in your body?

36
00:02:06.661 --> 00:02:10.410
Like what,
what kind of powers would it have to have before you accepted it?
Yeah.

37
00:02:10.411 --> 00:02:12.360
Well people already doing it in Sweden.
Yeah,
sure.

38
00:02:12.690 --> 00:02:14.490
And so how they're doing in Sweden?
Yeah.
They're just,

39
00:02:14.491 --> 00:02:17.450
they're putting this little chips in their hands and their and under their skin

40
00:02:17.451 --> 00:02:21.720
or their using it to open doors and access things.
Um,
so it's just starting.

41
00:02:21.721 --> 00:02:24.570
So I definitely believe that,
you know,
right now you look at,

42
00:02:24.571 --> 00:02:26.540
we look at photographs of our parents and he's like,

43
00:02:26.550 --> 00:02:31.470
God look at your hair or your clothes.
That's crazy.
Definitely.
I think that,

44
00:02:31.790 --> 00:02:33.240
you know,
20 years from now,
30 years from now,

45
00:02:33.241 --> 00:02:36.120
people are going to look at pictures of us and gonna say what's that little

46
00:02:36.121 --> 00:02:39.900
rectangular thing?
And you're going to say that was a phone.
What?

47
00:02:39.901 --> 00:02:41.100
And they'll say what it's like,
yeah,

48
00:02:41.101 --> 00:02:44.340
we used to carry it around in our pocket and like Michael Douglas,

49
00:02:44.341 --> 00:02:46.110
when you watch him in the movie Wall Street,

50
00:02:46.111 --> 00:02:50.510
he's got that giant phone on the beach.
Exactly.
So we are state of the art.

51
00:02:50.550 --> 00:02:54.240
We are all,
we are all Michael Douglas.
Because our technology,

52
00:02:54.241 --> 00:02:57.210
you're absolute right is not going to be something that we carry around.

53
00:02:57.211 --> 00:03:00.550
It's technology is coming inside of our bodies.

54
00:03:00.551 --> 00:03:05.080
That is the future of where it's going.
And you know,
people say,
well what,

55
00:03:05.081 --> 00:03:09.670
what is human genetic engineering have to do when we know that AI is going to

56
00:03:09.671 --> 00:03:14.320
get more and more powerful,
but the future of technology,
future of all of this,

57
00:03:14.321 --> 00:03:18.760
it's not human or AI,
it's human plus Ai.

58
00:03:18.760 --> 00:03:20.710
And that is what's going to drive our,

59
00:03:20.711 --> 00:03:23.620
we are co evolving with our technology and that's what's going to drive our

60
00:03:23.840 --> 00:03:27.970
drive us for it.
But you're exactly right to be afraid and to be concerned.

61
00:03:28.180 --> 00:03:30.610
And again,
everything has a little,
how are we going to regulate it?

62
00:03:30.611 --> 00:03:33.610
What are we going to have guardrails of?
How far is too far?

63
00:03:33.611 --> 00:03:37.210
Are we going to let companies just do whatever they want or are we going to put

64
00:03:37.211 --> 00:03:38.590
restrictions on what they can do?

65
00:03:38.860 --> 00:03:41.160
I think letting the whole world to Assad though you're,

66
00:03:41.161 --> 00:03:44.620
you're gonna run into those religious roadblocks.
If for sure.
And that's,

67
00:03:44.800 --> 00:03:48.820
and that's the challenge is that the science is advancing exponentially.

68
00:03:48.821 --> 00:03:49.840
Whatever we do.

69
00:03:50.290 --> 00:03:55.290
And so we have to have our understanding of the science needs to at least try to

70
00:03:56.501 --> 00:04:01.000
keep pace regulations need to keep up on part of the World Health Organization,

71
00:04:01.330 --> 00:04:03.790
International Advisory Committee on human genome editing.

72
00:04:03.790 --> 00:04:05.980
So we're meeting six times this year in Geneva.

73
00:04:06.280 --> 00:04:11.230
And the question that we're asking is how do we think about global regulation,

74
00:04:11.231 --> 00:04:15.940
at least to try to put limits on the far ends of what's possible.

75
00:04:15.941 --> 00:04:18.550
And it's,
it's really,
really difficult.

76
00:04:18.640 --> 00:04:21.550
But that's why we need to have this kind of process.

77
00:04:21.551 --> 00:04:24.130
And it seems impossibly ambitious,

78
00:04:24.131 --> 00:04:26.290
but every crazy idea it has to begin somewhere.

79
00:04:26.320 --> 00:04:31.210
So you're doing every couple months?
Yeah.
Yes.
Wow.

80
00:04:31.240 --> 00:04:36.160
Yeah.
Cause they'd want to be on top of it as things change.
Well that's the goal.

81
00:04:36.220 --> 00:04:39.790
It's just,
it's so hard because almost impossible.
It's impossible.

82
00:04:39.791 --> 00:04:42.820
It's impossible.
I said,
and that's why even the World Health Organization,

83
00:04:42.821 --> 00:04:46.840
which is the lead Health Organization of the United Nations,
it's not enough.

84
00:04:47.500 --> 00:04:52.420
The task is so much bigger and that's why we need to have this kind of grunt

85
00:04:52.421 --> 00:04:54.610
bottom of groundswell that I'm pushing for.

86
00:04:54.611 --> 00:04:55.960
And you're absolutely right what you said before,

87
00:04:56.530 --> 00:04:59.980
like because there's not a crisis,
people are focusing on other things.

88
00:04:59.980 --> 00:05:02.800
Open any news site,
like what do you see?

89
00:05:02.801 --> 00:05:05.460
It's not like the really important stuff.
It's,
you know,

90
00:05:05.500 --> 00:05:08.950
Trump did this or Kardashians did that.

91
00:05:08.951 --> 00:05:12.400
And like we're in this culture where there are a lot of draws on our attention,

92
00:05:12.401 --> 00:05:15.730
but sometimes there's really important stuff and people are afraid of it.

93
00:05:15.731 --> 00:05:17.460
People are afraid of science.
People feel like,
yeah,

94
00:05:17.461 --> 00:05:22.070
I remember science from high school.
I didn't like it.
I was uncomfortable.
Um,

95
00:05:22.440 --> 00:05:25.810
you know,
this is,
this is for technical people and I just feel like we can't,

96
00:05:26.110 --> 00:05:29.170
science is so deeply transforming the world,

97
00:05:29.530 --> 00:05:31.420
not just around us but within us.

98
00:05:31.480 --> 00:05:36.480
And so we have to understand it and people who are explaining science like me,

99
00:05:37.061 --> 00:05:39.910
the onus is on us.
Like if somebody reads my book and says,
well,

100
00:05:39.911 --> 00:05:42.490
that was really dense,
that was too hard.

101
00:05:42.940 --> 00:05:47.890
Like that's my failure.
Like I was giving a talk in New York a couple of,

102
00:05:47.930 --> 00:05:48.850
a couple of weeks ago,

103
00:05:48.851 --> 00:05:53.140
and so I gave my talk and I try to make this really accessible for people.

104
00:05:53.260 --> 00:05:57.100
People were all jazzed up.
They got it.
And then there was this wonderful guys,

105
00:05:57.650 --> 00:06:01.520
senior scientist at this mid,
this major,
um,
stem cell research center.

106
00:06:02.000 --> 00:06:06.300
And so the,
the,
the host said,
all right,
Jamie just talked,
um,

107
00:06:06.350 --> 00:06:09.360
can you sign?
Can you give us a little background on the science?

108
00:06:09.370 --> 00:06:10.910
This guy knows so much.

109
00:06:10.970 --> 00:06:14.360
And he started going and it was very technical and you could just,

110
00:06:14.361 --> 00:06:17.690
I could just see the faces of the people in the audience.
It was like,
Oh God,

111
00:06:17.691 --> 00:06:20.060
what's happening here?
And just like their level of excitement,

112
00:06:20.061 --> 00:06:24.250
it just shrunk because they couldn't really put it on the,
yeah.
And so,

113
00:06:24.530 --> 00:06:25.700
and scientists,

114
00:06:26.030 --> 00:06:31.030
scientists aren't trained by and large to communicate and to see in the fishes.

115
00:06:31.371 --> 00:06:32.660
So a little more than a month ago,

116
00:06:32.661 --> 00:06:37.661
I was in Kyoto in Japan and I went to the laboratory of the world's leading

117
00:06:38.300 --> 00:06:41.570
scientists who's doing a process of what I mentioned earlier.

118
00:06:41.810 --> 00:06:46.190
I've turning adult cells into stem cells into eggs.
And so this,

119
00:06:46.250 --> 00:06:49.670
this will revolutionize the way humans reproduce.
And so I had,

120
00:06:49.890 --> 00:06:53.300
I was in a meeting,
um,
with his,
uh,
top postdocs dude.

121
00:06:53.310 --> 00:06:55.970
So these are like really the cutting edge of these technologies.

122
00:06:56.450 --> 00:06:58.620
And I went around to each of them and I said,
here's my question.

123
00:06:58.621 --> 00:06:59.990
You have two questions for each of you.
One,

124
00:07:00.410 --> 00:07:05.240
tell me what you're doing now and to tell me what are the implications of what

125
00:07:05.241 --> 00:07:08.800
you're doing now for 50 years from now.
And the first,

126
00:07:08.810 --> 00:07:09.800
the first question because Oh,

127
00:07:09.801 --> 00:07:12.950
I'm doing this and we're doing this with mouse models and people were so

128
00:07:12.951 --> 00:07:17.390
animated and then 50 years from now people just froze and it was so

129
00:07:17.391 --> 00:07:17.841
uncomfortable.

130
00:07:17.841 --> 00:07:22.310
They were like squeezing the table just because that's not what scientists do.

131
00:07:22.311 --> 00:07:25.680
They are trained to say,
well,
this is the thing just in front of me.
So,
right.

132
00:07:25.760 --> 00:07:27.980
I thought I was writing this book for the general public,

133
00:07:27.981 --> 00:07:32.690
but I'm being invited to speak to thousands of doctors and scientists because

134
00:07:32.691 --> 00:07:36.800
what they're saying is we get that we're doing this little piece of this and

135
00:07:36.801 --> 00:07:40.490
whether it's lab research or fertility doctors or all sorts of things,

136
00:07:40.940 --> 00:07:45.290
but it's really hard to put together the whole story of the genetics revolution

137
00:07:45.291 --> 00:07:47.030
and what it means for us and for society.

