WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:01.490
we've all been hearing that deep neural

00:00:01.490 --> 00:00:01.500
we've all been hearing that deep neural
 

00:00:01.500 --> 00:00:03.200
we've all been hearing that deep neural
networks work really well for a lot of

00:00:03.200 --> 00:00:03.210
networks work really well for a lot of
 

00:00:03.210 --> 00:00:05.059
networks work really well for a lot of
problems it's not just that they need to

00:00:05.059 --> 00:00:05.069
problems it's not just that they need to
 

00:00:05.069 --> 00:00:06.530
problems it's not just that they need to
be big neural networks is that

00:00:06.530 --> 00:00:06.540
be big neural networks is that
 

00:00:06.540 --> 00:00:09.020
be big neural networks is that
specifically they need to be deep or to

00:00:09.020 --> 00:00:09.030
specifically they need to be deep or to
 

00:00:09.030 --> 00:00:11.600
specifically they need to be deep or to
have a lot of hidden layers so why is

00:00:11.600 --> 00:00:11.610
have a lot of hidden layers so why is
 

00:00:11.610 --> 00:00:13.400
have a lot of hidden layers so why is
that let's go for a couple examples and

00:00:13.400 --> 00:00:13.410
that let's go for a couple examples and
 

00:00:13.410 --> 00:00:15.709
that let's go for a couple examples and
try to gain some intuition for why deep

00:00:15.709 --> 00:00:15.719
try to gain some intuition for why deep
 

00:00:15.719 --> 00:00:19.730
try to gain some intuition for why deep
networks might work well so first what

00:00:19.730 --> 00:00:19.740
networks might work well so first what
 

00:00:19.740 --> 00:00:22.820
networks might work well so first what
is a deep network computing if you're

00:00:22.820 --> 00:00:22.830
is a deep network computing if you're
 

00:00:22.830 --> 00:00:24.800
is a deep network computing if you're
building a system for face recognition

00:00:24.800 --> 00:00:24.810
building a system for face recognition
 

00:00:24.810 --> 00:00:27.200
building a system for face recognition
or face detection here's what the deep

00:00:27.200 --> 00:00:27.210
or face detection here's what the deep
 

00:00:27.210 --> 00:00:29.599
or face detection here's what the deep
neural network could be doing

00:00:29.599 --> 00:00:29.609
neural network could be doing
 

00:00:29.609 --> 00:00:32.049
neural network could be doing
perhaps you input a picture of a face

00:00:32.049 --> 00:00:32.059
perhaps you input a picture of a face
 

00:00:32.059 --> 00:00:34.160
perhaps you input a picture of a face
then the first layer of the neural

00:00:34.160 --> 00:00:34.170
then the first layer of the neural
 

00:00:34.170 --> 00:00:36.830
then the first layer of the neural
network you can think of as maybe being

00:00:36.830 --> 00:00:36.840
network you can think of as maybe being
 

00:00:36.840 --> 00:00:39.830
network you can think of as maybe being
a feature detector or an edge detector

00:00:39.830 --> 00:00:39.840
a feature detector or an edge detector
 

00:00:39.840 --> 00:00:43.250
a feature detector or an edge detector
in this example I'm plotting what a

00:00:43.250 --> 00:00:43.260
in this example I'm plotting what a
 

00:00:43.260 --> 00:00:45.560
in this example I'm plotting what a
neural network with maybe twenty hidden

00:00:45.560 --> 00:00:45.570
neural network with maybe twenty hidden
 

00:00:45.570 --> 00:00:47.540
neural network with maybe twenty hidden
units might be trying to compute on this

00:00:47.540 --> 00:00:47.550
units might be trying to compute on this
 

00:00:47.550 --> 00:00:49.160
units might be trying to compute on this
image with the twenty hidden units

00:00:49.160 --> 00:00:49.170
image with the twenty hidden units
 

00:00:49.170 --> 00:00:52.220
image with the twenty hidden units
visualized by these little square boxes

00:00:52.220 --> 00:00:52.230
visualized by these little square boxes
 

00:00:52.230 --> 00:00:55.100
visualized by these little square boxes
so for example this little visualization

00:00:55.100 --> 00:00:55.110
so for example this little visualization
 

00:00:55.110 --> 00:00:56.930
so for example this little visualization
represents a hidden unit that's trying

00:00:56.930 --> 00:00:56.940
represents a hidden unit that's trying
 

00:00:56.940 --> 00:00:58.819
represents a hidden unit that's trying
to figure out if you know where the

00:00:58.819 --> 00:00:58.829
to figure out if you know where the
 

00:00:58.829 --> 00:01:01.400
to figure out if you know where the
edges of that orientation are in the

00:01:01.400 --> 00:01:01.410
edges of that orientation are in the
 

00:01:01.410 --> 00:01:05.630
edges of that orientation are in the
image and maybe this hidden unit might

00:01:05.630 --> 00:01:05.640
image and maybe this hidden unit might
 

00:01:05.640 --> 00:01:07.280
image and maybe this hidden unit might
be trying to figure out where are the

00:01:07.280 --> 00:01:07.290
be trying to figure out where are the
 

00:01:07.290 --> 00:01:10.609
be trying to figure out where are the
horizontal edges in this image and when

00:01:10.609 --> 00:01:10.619
horizontal edges in this image and when
 

00:01:10.619 --> 00:01:12.590
horizontal edges in this image and when
we talk about convolutional networks in

00:01:12.590 --> 00:01:12.600
we talk about convolutional networks in
 

00:01:12.600 --> 00:01:14.090
we talk about convolutional networks in
a later course of this particular

00:01:14.090 --> 00:01:14.100
a later course of this particular
 

00:01:14.100 --> 00:01:15.620
a later course of this particular
visualization we'll make a bit more

00:01:15.620 --> 00:01:15.630
visualization we'll make a bit more
 

00:01:15.630 --> 00:01:17.420
visualization we'll make a bit more
sense but the form you can think of the

00:01:17.420 --> 00:01:17.430
sense but the form you can think of the
 

00:01:17.430 --> 00:01:19.399
sense but the form you can think of the
first lived in your network as looking a

00:01:19.399 --> 00:01:19.409
first lived in your network as looking a
 

00:01:19.409 --> 00:01:20.719
first lived in your network as looking a
picture and trying to figure out you

00:01:20.719 --> 00:01:20.729
picture and trying to figure out you
 

00:01:20.729 --> 00:01:22.280
picture and trying to figure out you
know where are the edges in this picture

00:01:22.280 --> 00:01:22.290
know where are the edges in this picture
 

00:01:22.290 --> 00:01:24.800
know where are the edges in this picture
now let's figure out where the edges in

00:01:24.800 --> 00:01:24.810
now let's figure out where the edges in
 

00:01:24.810 --> 00:01:27.170
now let's figure out where the edges in
this picture by grouping together pixels

00:01:27.170 --> 00:01:27.180
this picture by grouping together pixels
 

00:01:27.180 --> 00:01:30.469
this picture by grouping together pixels
to form edges it can then take the

00:01:30.469 --> 00:01:30.479
to form edges it can then take the
 

00:01:30.479 --> 00:01:32.510
to form edges it can then take the
detected edges and group edges together

00:01:32.510 --> 00:01:32.520
detected edges and group edges together
 

00:01:32.520 --> 00:01:35.210
detected edges and group edges together
to form parts of faces so for example

00:01:35.210 --> 00:01:35.220
to form parts of faces so for example
 

00:01:35.220 --> 00:01:37.580
to form parts of faces so for example
you might have a loner on trying to see

00:01:37.580 --> 00:01:37.590
you might have a loner on trying to see
 

00:01:37.590 --> 00:01:40.460
you might have a loner on trying to see
if is finding an eye or a different

00:01:40.460 --> 00:01:40.470
if is finding an eye or a different
 

00:01:40.470 --> 00:01:43.069
if is finding an eye or a different
neuron trying to find that part of the

00:01:43.069 --> 00:01:43.079
neuron trying to find that part of the
 

00:01:43.079 --> 00:01:46.429
neuron trying to find that part of the
nose and so by putting together lots of

00:01:46.429 --> 00:01:46.439
nose and so by putting together lots of
 

00:01:46.439 --> 00:01:49.490
nose and so by putting together lots of
edges it can start to detect different

00:01:49.490 --> 00:01:49.500
edges it can start to detect different
 

00:01:49.500 --> 00:01:52.429
edges it can start to detect different
parts of faces and then finally by

00:01:52.429 --> 00:01:52.439
parts of faces and then finally by
 

00:01:52.439 --> 00:01:54.889
parts of faces and then finally by
putting together different parts of

00:01:54.889 --> 00:01:54.899
putting together different parts of
 

00:01:54.899 --> 00:01:57.230
putting together different parts of
faces that can I or a nose or an ear or

00:01:57.230 --> 00:01:57.240
faces that can I or a nose or an ear or
 

00:01:57.240 --> 00:02:00.109
faces that can I or a nose or an ear or
chin it can then try to recognize or

00:02:00.109 --> 00:02:00.119
chin it can then try to recognize or
 

00:02:00.119 --> 00:02:04.429
chin it can then try to recognize or
detect different types of faces so

00:02:04.429 --> 00:02:04.439
detect different types of faces so
 

00:02:04.439 --> 00:02:06.440
detect different types of faces so
intuitively you can think of the earlier

00:02:06.440 --> 00:02:06.450
intuitively you can think of the earlier
 

00:02:06.450 --> 00:02:08.419
intuitively you can think of the earlier
layers of a neural network is detecting

00:02:08.419 --> 00:02:08.429
layers of a neural network is detecting
 

00:02:08.429 --> 00:02:10.800
layers of a neural network is detecting
simpler functions like edges

00:02:10.800 --> 00:02:10.810
simpler functions like edges
 

00:02:10.810 --> 00:02:13.110
simpler functions like edges
then composing them together in the

00:02:13.110 --> 00:02:13.120
then composing them together in the
 

00:02:13.120 --> 00:02:15.300
then composing them together in the
later layers of a neural network so that

00:02:15.300 --> 00:02:15.310
later layers of a neural network so that
 

00:02:15.310 --> 00:02:16.860
later layers of a neural network so that
they can learn one more complex

00:02:16.860 --> 00:02:16.870
they can learn one more complex
 

00:02:16.870 --> 00:02:20.699
they can learn one more complex
functions these visualizations will make

00:02:20.699 --> 00:02:20.709
functions these visualizations will make
 

00:02:20.709 --> 00:02:21.720
functions these visualizations will make
more sense when we talk about

00:02:21.720 --> 00:02:21.730
more sense when we talk about
 

00:02:21.730 --> 00:02:24.750
more sense when we talk about
convolutional nets and one technical

00:02:24.750 --> 00:02:24.760
convolutional nets and one technical
 

00:02:24.760 --> 00:02:26.820
convolutional nets and one technical
detail of this visualization the edge

00:02:26.820 --> 00:02:26.830
detail of this visualization the edge
 

00:02:26.830 --> 00:02:28.589
detail of this visualization the edge
detectors are looking in relatively

00:02:28.589 --> 00:02:28.599
detectors are looking in relatively
 

00:02:28.599 --> 00:02:30.449
detectors are looking in relatively
small areas of an image may be very

00:02:30.449 --> 00:02:30.459
small areas of an image may be very
 

00:02:30.459 --> 00:02:32.940
small areas of an image may be very
small regions like that and then the

00:02:32.940 --> 00:02:32.950
small regions like that and then the
 

00:02:32.950 --> 00:02:35.520
small regions like that and then the
facial detectors you know can look at

00:02:35.520 --> 00:02:35.530
facial detectors you know can look at
 

00:02:35.530 --> 00:02:37.830
facial detectors you know can look at
may be much larger areas of the image

00:02:37.830 --> 00:02:37.840
may be much larger areas of the image
 

00:02:37.840 --> 00:02:39.330
may be much larger areas of the image
but the main intuition when you take

00:02:39.330 --> 00:02:39.340
but the main intuition when you take
 

00:02:39.340 --> 00:02:41.610
but the main intuition when you take
away from this is just finding simpler

00:02:41.610 --> 00:02:41.620
away from this is just finding simpler
 

00:02:41.620 --> 00:02:43.350
away from this is just finding simpler
things like edges and then building them

00:02:43.350 --> 00:02:43.360
things like edges and then building them
 

00:02:43.360 --> 00:02:45.570
things like edges and then building them
up composing them together to detect

00:02:45.570 --> 00:02:45.580
up composing them together to detect
 

00:02:45.580 --> 00:02:47.130
up composing them together to detect
more complex things like an iron there

00:02:47.130 --> 00:02:47.140
more complex things like an iron there
 

00:02:47.140 --> 00:02:48.960
more complex things like an iron there
was in the composing those together to

00:02:48.960 --> 00:02:48.970
was in the composing those together to
 

00:02:48.970 --> 00:02:52.140
was in the composing those together to
find even more complex things and this

00:02:52.140 --> 00:02:52.150
find even more complex things and this
 

00:02:52.150 --> 00:02:55.199
find even more complex things and this
type of simple to complex hierarchical

00:02:55.199 --> 00:02:55.209
type of simple to complex hierarchical
 

00:02:55.209 --> 00:02:57.000
type of simple to complex hierarchical
representation or compositional

00:02:57.000 --> 00:02:57.010
representation or compositional
 

00:02:57.010 --> 00:03:00.539
representation or compositional
representation applies in other types of

00:03:00.539 --> 00:03:00.549
representation applies in other types of
 

00:03:00.549 --> 00:03:02.970
representation applies in other types of
data than images and and face

00:03:02.970 --> 00:03:02.980
data than images and and face
 

00:03:02.980 --> 00:03:05.100
data than images and and face
recognition as well for example if

00:03:05.100 --> 00:03:05.110
recognition as well for example if
 

00:03:05.110 --> 00:03:06.030
recognition as well for example if
you're trying to build a speech

00:03:06.030 --> 00:03:06.040
you're trying to build a speech
 

00:03:06.040 --> 00:03:07.680
you're trying to build a speech
recognition system it's hard to do

00:03:07.680 --> 00:03:07.690
recognition system it's hard to do
 

00:03:07.690 --> 00:03:10.140
recognition system it's hard to do
visualise speech but if you input an

00:03:10.140 --> 00:03:10.150
visualise speech but if you input an
 

00:03:10.150 --> 00:03:12.539
visualise speech but if you input an
audio clip there may be the first level

00:03:12.539 --> 00:03:12.549
audio clip there may be the first level
 

00:03:12.549 --> 00:03:14.699
audio clip there may be the first level
of a neural network might learn to

00:03:14.699 --> 00:03:14.709
of a neural network might learn to
 

00:03:14.709 --> 00:03:18.300
of a neural network might learn to
detect you know low level audio waveform

00:03:18.300 --> 00:03:18.310
detect you know low level audio waveform
 

00:03:18.310 --> 00:03:20.970
detect you know low level audio waveform
features such as is this tone going up

00:03:20.970 --> 00:03:20.980
features such as is this tone going up
 

00:03:20.980 --> 00:03:23.849
features such as is this tone going up
is this going down is it a white noise

00:03:23.849 --> 00:03:23.859
is this going down is it a white noise
 

00:03:23.859 --> 00:03:27.330
is this going down is it a white noise
or sibilant sound lights right and what

00:03:27.330 --> 00:03:27.340
or sibilant sound lights right and what
 

00:03:27.340 --> 00:03:28.949
or sibilant sound lights right and what
is the pitch but it can select to type

00:03:28.949 --> 00:03:28.959
is the pitch but it can select to type
 

00:03:28.959 --> 00:03:30.569
is the pitch but it can select to type
low level waveform features like that

00:03:30.569 --> 00:03:30.579
low level waveform features like that
 

00:03:30.579 --> 00:03:33.120
low level waveform features like that
and then by composing low level

00:03:33.120 --> 00:03:33.130
and then by composing low level
 

00:03:33.130 --> 00:03:35.490
and then by composing low level
waveforms maybe of learn to detect basic

00:03:35.490 --> 00:03:35.500
waveforms maybe of learn to detect basic
 

00:03:35.500 --> 00:03:39.000
waveforms maybe of learn to detect basic
units of sound so in linguistics they

00:03:39.000 --> 00:03:39.010
units of sound so in linguistics they
 

00:03:39.010 --> 00:03:41.580
units of sound so in linguistics they
called phonemes but for example in the

00:03:41.580 --> 00:03:41.590
called phonemes but for example in the
 

00:03:41.590 --> 00:03:44.910
called phonemes but for example in the
word cat the cup is a phoneme that up is

00:03:44.910 --> 00:03:44.920
word cat the cup is a phoneme that up is
 

00:03:44.920 --> 00:03:46.860
word cat the cup is a phoneme that up is
a phoneme the term is another phoneme

00:03:46.860 --> 00:03:46.870
a phoneme the term is another phoneme
 

00:03:46.870 --> 00:03:49.199
a phoneme the term is another phoneme
but learns to find maybe the basic units

00:03:49.199 --> 00:03:49.209
but learns to find maybe the basic units
 

00:03:49.209 --> 00:03:51.030
but learns to find maybe the basic units
of sound and then composing that

00:03:51.030 --> 00:03:51.040
of sound and then composing that
 

00:03:51.040 --> 00:03:52.979
of sound and then composing that
together maybe you learn to recognize

00:03:52.979 --> 00:03:52.989
together maybe you learn to recognize
 

00:03:52.989 --> 00:03:55.440
together maybe you learn to recognize
words in the audio and then maybe

00:03:55.440 --> 00:03:55.450
words in the audio and then maybe
 

00:03:55.450 --> 00:03:58.349
words in the audio and then maybe
compose those together in order to

00:03:58.349 --> 00:03:58.359
compose those together in order to
 

00:03:58.359 --> 00:04:00.720
compose those together in order to
recognize entire you know phrases or

00:04:00.720 --> 00:04:00.730
recognize entire you know phrases or
 

00:04:00.730 --> 00:04:04.349
recognize entire you know phrases or
sentences so deep neural network with

00:04:04.349 --> 00:04:04.359
sentences so deep neural network with
 

00:04:04.359 --> 00:04:06.270
sentences so deep neural network with
multiple hidden layers might be able to

00:04:06.270 --> 00:04:06.280
multiple hidden layers might be able to
 

00:04:06.280 --> 00:04:08.039
multiple hidden layers might be able to
have the earlier layers learn these

00:04:08.039 --> 00:04:08.049
have the earlier layers learn these
 

00:04:08.049 --> 00:04:10.259
have the earlier layers learn these
lower levels simpler features and then

00:04:10.259 --> 00:04:10.269
lower levels simpler features and then
 

00:04:10.269 --> 00:04:13.440
lower levels simpler features and then
have the later deeper layers then put

00:04:13.440 --> 00:04:13.450
have the later deeper layers then put
 

00:04:13.450 --> 00:04:15.569
have the later deeper layers then put
together the simpler things is detected

00:04:15.569 --> 00:04:15.579
together the simpler things is detected
 

00:04:15.579 --> 00:04:17.340
together the simpler things is detected
in order to detect more complex things

00:04:17.340 --> 00:04:17.350
in order to detect more complex things
 

00:04:17.350 --> 00:04:19.440
in order to detect more complex things
like recognize specific words or even

00:04:19.440 --> 00:04:19.450
like recognize specific words or even
 

00:04:19.450 --> 00:04:21.620
like recognize specific words or even
phrases or sentences that you

00:04:21.620 --> 00:04:21.630
phrases or sentences that you
 

00:04:21.630 --> 00:04:23.840
phrases or sentences that you
serving in order to carry-out speech

00:04:23.840 --> 00:04:23.850
serving in order to carry-out speech
 

00:04:23.850 --> 00:04:26.630
serving in order to carry-out speech
recognition and what we see is that

00:04:26.630 --> 00:04:26.640
recognition and what we see is that
 

00:04:26.640 --> 00:04:29.180
recognition and what we see is that
whereas the earlier layers are computing

00:04:29.180 --> 00:04:29.190
whereas the earlier layers are computing
 

00:04:29.190 --> 00:04:31.310
whereas the earlier layers are computing
what seems like relatively simple

00:04:31.310 --> 00:04:31.320
what seems like relatively simple
 

00:04:31.320 --> 00:04:33.620
what seems like relatively simple
functions of the input such as we're at

00:04:33.620 --> 00:04:33.630
functions of the input such as we're at
 

00:04:33.630 --> 00:04:36.350
functions of the input such as we're at
the edges by the time you get deep in

00:04:36.350 --> 00:04:36.360
the edges by the time you get deep in
 

00:04:36.360 --> 00:04:38.690
the edges by the time you get deep in
the network you can actually do you know

00:04:38.690 --> 00:04:38.700
the network you can actually do you know
 

00:04:38.700 --> 00:04:41.480
the network you can actually do you know
surprisingly complex things such as

00:04:41.480 --> 00:04:41.490
surprisingly complex things such as
 

00:04:41.490 --> 00:04:43.610
surprisingly complex things such as
detect faces or detect words or phrases

00:04:43.610 --> 00:04:43.620
detect faces or detect words or phrases
 

00:04:43.620 --> 00:04:46.250
detect faces or detect words or phrases
or sentences some people like to make an

00:04:46.250 --> 00:04:46.260
or sentences some people like to make an
 

00:04:46.260 --> 00:04:48.260
or sentences some people like to make an
analogy between deep neural networks and

00:04:48.260 --> 00:04:48.270
analogy between deep neural networks and
 

00:04:48.270 --> 00:04:50.630
analogy between deep neural networks and
the human brain where we believe on

00:04:50.630 --> 00:04:50.640
the human brain where we believe on
 

00:04:50.640 --> 00:04:52.010
the human brain where we believe on
neuroscientists believe that the human

00:04:52.010 --> 00:04:52.020
neuroscientists believe that the human
 

00:04:52.020 --> 00:04:54.740
neuroscientists believe that the human
brain also starts off detecting simple

00:04:54.740 --> 00:04:54.750
brain also starts off detecting simple
 

00:04:54.750 --> 00:04:57.260
brain also starts off detecting simple
things like edges in what your eyes see

00:04:57.260 --> 00:04:57.270
things like edges in what your eyes see
 

00:04:57.270 --> 00:04:59.060
things like edges in what your eyes see
and then builds those up to detect more

00:04:59.060 --> 00:04:59.070
and then builds those up to detect more
 

00:04:59.070 --> 00:05:01.880
and then builds those up to detect more
complex things like the faces that you

00:05:01.880 --> 00:05:01.890
complex things like the faces that you
 

00:05:01.890 --> 00:05:05.060
complex things like the faces that you
see I think analogies between deep

00:05:05.060 --> 00:05:05.070
see I think analogies between deep
 

00:05:05.070 --> 00:05:06.740
see I think analogies between deep
learning and the human brain are

00:05:06.740 --> 00:05:06.750
learning and the human brain are
 

00:05:06.750 --> 00:05:08.780
learning and the human brain are
sometimes a little bit dangerous but you

00:05:08.780 --> 00:05:08.790
sometimes a little bit dangerous but you
 

00:05:08.790 --> 00:05:11.930
sometimes a little bit dangerous but you
know there is a lot of truth to this

00:05:11.930 --> 00:05:11.940
know there is a lot of truth to this
 

00:05:11.940 --> 00:05:13.880
know there is a lot of truth to this
being how we think the human brain works

00:05:13.880 --> 00:05:13.890
being how we think the human brain works
 

00:05:13.890 --> 00:05:15.560
being how we think the human brain works
and that the human brain probably

00:05:15.560 --> 00:05:15.570
and that the human brain probably
 

00:05:15.570 --> 00:05:17.840
and that the human brain probably
detects simple things like edges first

00:05:17.840 --> 00:05:17.850
detects simple things like edges first
 

00:05:17.850 --> 00:05:19.700
detects simple things like edges first
and then puts them together to form more

00:05:19.700 --> 00:05:19.710
and then puts them together to form more
 

00:05:19.710 --> 00:05:22.970
and then puts them together to form more
and more complex objects and so that has

00:05:22.970 --> 00:05:22.980
and more complex objects and so that has
 

00:05:22.980 --> 00:05:25.100
and more complex objects and so that has
served as a loose form of inspiration

00:05:25.100 --> 00:05:25.110
served as a loose form of inspiration
 

00:05:25.110 --> 00:05:28.130
served as a loose form of inspiration
for some deep learning as well we'll say

00:05:28.130 --> 00:05:28.140
for some deep learning as well we'll say
 

00:05:28.140 --> 00:05:30.230
for some deep learning as well we'll say
a bit more about the human brain or

00:05:30.230 --> 00:05:30.240
a bit more about the human brain or
 

00:05:30.240 --> 00:05:32.030
a bit more about the human brain or
about the biological brain in a later

00:05:32.030 --> 00:05:32.040
about the biological brain in a later
 

00:05:32.040 --> 00:05:36.980
about the biological brain in a later
video this week the other piece of

00:05:36.980 --> 00:05:36.990
video this week the other piece of
 

00:05:36.990 --> 00:05:40.070
video this week the other piece of
intuition about why deep networks seems

00:05:40.070 --> 00:05:40.080
intuition about why deep networks seems
 

00:05:40.080 --> 00:05:43.310
intuition about why deep networks seems
to work well is the following so this

00:05:43.310 --> 00:05:43.320
to work well is the following so this
 

00:05:43.320 --> 00:05:46.310
to work well is the following so this
result comes from circuit theory which

00:05:46.310 --> 00:05:46.320
result comes from circuit theory which
 

00:05:46.320 --> 00:05:48.710
result comes from circuit theory which
pertains to thinking about what types of

00:05:48.710 --> 00:05:48.720
pertains to thinking about what types of
 

00:05:48.720 --> 00:05:50.720
pertains to thinking about what types of
functions you can compute with different

00:05:50.720 --> 00:05:50.730
functions you can compute with different
 

00:05:50.730 --> 00:05:52.460
functions you can compute with different
hand gates and or gates and not gates

00:05:52.460 --> 00:05:52.470
hand gates and or gates and not gates
 

00:05:52.470 --> 00:05:55.040
hand gates and or gates and not gates
bassy logic gates so informally their

00:05:55.040 --> 00:05:55.050
bassy logic gates so informally their
 

00:05:55.050 --> 00:05:56.630
bassy logic gates so informally their
functions in computer were viral ative

00:05:56.630 --> 00:05:56.640
functions in computer were viral ative
 

00:05:56.640 --> 00:05:59.600
functions in computer were viral ative
Li small but deep neural network and by

00:05:59.600 --> 00:05:59.610
Li small but deep neural network and by
 

00:05:59.610 --> 00:06:01.040
Li small but deep neural network and by
small I mean the number of hidden units

00:06:01.040 --> 00:06:01.050
small I mean the number of hidden units
 

00:06:01.050 --> 00:06:04.700
small I mean the number of hidden units
is relatively small but that if you try

00:06:04.700 --> 00:06:04.710
is relatively small but that if you try
 

00:06:04.710 --> 00:06:06.020
is relatively small but that if you try
to compute the same function with a

00:06:06.020 --> 00:06:06.030
to compute the same function with a
 

00:06:06.030 --> 00:06:07.880
to compute the same function with a
shallow network so if you aren't allowed

00:06:07.880 --> 00:06:07.890
shallow network so if you aren't allowed
 

00:06:07.890 --> 00:06:09.860
shallow network so if you aren't allowed
enough hidden layers then you might

00:06:09.860 --> 00:06:09.870
enough hidden layers then you might
 

00:06:09.870 --> 00:06:12.230
enough hidden layers then you might
require exponentially more hidden units

00:06:12.230 --> 00:06:12.240
require exponentially more hidden units
 

00:06:12.240 --> 00:06:14.660
require exponentially more hidden units
to compute so let me just give you one

00:06:14.660 --> 00:06:14.670
to compute so let me just give you one
 

00:06:14.670 --> 00:06:17.210
to compute so let me just give you one
example and illustrate this a bit

00:06:17.210 --> 00:06:17.220
example and illustrate this a bit
 

00:06:17.220 --> 00:06:19.040
example and illustrate this a bit
informally but let's say you're trying

00:06:19.040 --> 00:06:19.050
informally but let's say you're trying
 

00:06:19.050 --> 00:06:20.990
informally but let's say you're trying
to compute the exclusive-or or the

00:06:20.990 --> 00:06:21.000
to compute the exclusive-or or the
 

00:06:21.000 --> 00:06:23.510
to compute the exclusive-or or the
parity of all your input features you

00:06:23.510 --> 00:06:23.520
parity of all your input features you
 

00:06:23.520 --> 00:06:26.900
parity of all your input features you
can't compute X 1 X 4 X 2 X 4 X 3 X or

00:06:26.900 --> 00:06:26.910
can't compute X 1 X 4 X 2 X 4 X 3 X or
 

00:06:26.910 --> 00:06:29.690
can't compute X 1 X 4 X 2 X 4 X 3 X or
up to UM it

00:06:29.690 --> 00:06:29.700
up to UM it
 

00:06:29.700 --> 00:06:34.640
up to UM it
and if you have n or NX features so if

00:06:34.640 --> 00:06:34.650
and if you have n or NX features so if
 

00:06:34.650 --> 00:06:37.670
and if you have n or NX features so if
you build an X or tree like this right

00:06:37.670 --> 00:06:37.680
you build an X or tree like this right
 

00:06:37.680 --> 00:06:40.190
you build an X or tree like this right
so first compute the XOR of X 1 the next

00:06:40.190 --> 00:06:40.200
so first compute the XOR of X 1 the next
 

00:06:40.200 --> 00:06:43.460
so first compute the XOR of X 1 the next
two then take X 3 and X 4 and compute

00:06:43.460 --> 00:06:43.470
two then take X 3 and X 4 and compute
 

00:06:43.470 --> 00:06:45.890
two then take X 3 and X 4 and compute
their XOR and technically if you're just

00:06:45.890 --> 00:06:45.900
their XOR and technically if you're just
 

00:06:45.900 --> 00:06:48.320
their XOR and technically if you're just
using and or not gate you might need a

00:06:48.320 --> 00:06:48.330
using and or not gate you might need a
 

00:06:48.330 --> 00:06:49.820
using and or not gate you might need a
couple layers to compute the XOR

00:06:49.820 --> 00:06:49.830
couple layers to compute the XOR
 

00:06:49.830 --> 00:06:52.450
couple layers to compute the XOR
function rather than just one layer but

00:06:52.450 --> 00:06:52.460
function rather than just one layer but
 

00:06:52.460 --> 00:06:55.700
function rather than just one layer but
with a relatively small circuit you can

00:06:55.700 --> 00:06:55.710
with a relatively small circuit you can
 

00:06:55.710 --> 00:06:59.630
with a relatively small circuit you can
compute the XOR right and so on and then

00:06:59.630 --> 00:06:59.640
compute the XOR right and so on and then
 

00:06:59.640 --> 00:07:02.740
compute the XOR right and so on and then
you can you know build really an X or

00:07:02.740 --> 00:07:02.750
you can you know build really an X or
 

00:07:02.750 --> 00:07:07.690
you can you know build really an X or
tree like so until eventually you have a

00:07:07.690 --> 00:07:07.700
tree like so until eventually you have a
 

00:07:07.700 --> 00:07:10.670
tree like so until eventually you have a
circuit here that outputs you know the

00:07:10.670 --> 00:07:10.680
circuit here that outputs you know the
 

00:07:10.680 --> 00:07:14.120
circuit here that outputs you know the
all let's call this Y that outputs y hat

00:07:14.120 --> 00:07:14.130
all let's call this Y that outputs y hat
 

00:07:14.130 --> 00:07:17.090
all let's call this Y that outputs y hat
equals y the exclusive or the parity of

00:07:17.090 --> 00:07:17.100
equals y the exclusive or the parity of
 

00:07:17.100 --> 00:07:19.220
equals y the exclusive or the parity of
all of these input bits so the compute

00:07:19.220 --> 00:07:19.230
all of these input bits so the compute
 

00:07:19.230 --> 00:07:22.250
all of these input bits so the compute
the XOR the depth of the network will be

00:07:22.250 --> 00:07:22.260
the XOR the depth of the network will be
 

00:07:22.260 --> 00:07:25.220
the XOR the depth of the network will be
on the order of log n right when this

00:07:25.220 --> 00:07:25.230
on the order of log n right when this
 

00:07:25.230 --> 00:07:28.760
on the order of log n right when this
type of XOR tree so the number of nodes

00:07:28.760 --> 00:07:28.770
type of XOR tree so the number of nodes
 

00:07:28.770 --> 00:07:30.650
type of XOR tree so the number of nodes
and the number of circuit circuit

00:07:30.650 --> 00:07:30.660
and the number of circuit circuit
 

00:07:30.660 --> 00:07:32.450
and the number of circuit circuit
components or the number of gates in

00:07:32.450 --> 00:07:32.460
components or the number of gates in
 

00:07:32.460 --> 00:07:34.310
components or the number of gates in
this network is not that large you don't

00:07:34.310 --> 00:07:34.320
this network is not that large you don't
 

00:07:34.320 --> 00:07:36.890
this network is not that large you don't
need that many gates in order to compute

00:07:36.890 --> 00:07:36.900
need that many gates in order to compute
 

00:07:36.900 --> 00:07:39.830
need that many gates in order to compute
the exclusive-or but now if you're not

00:07:39.830 --> 00:07:39.840
the exclusive-or but now if you're not
 

00:07:39.840 --> 00:07:42.620
the exclusive-or but now if you're not
allowed to use a new network with

00:07:42.620 --> 00:07:42.630
allowed to use a new network with
 

00:07:42.630 --> 00:07:45.170
allowed to use a new network with
multiple hidden layers with in this case

00:07:45.170 --> 00:07:45.180
multiple hidden layers with in this case
 

00:07:45.180 --> 00:07:47.660
multiple hidden layers with in this case
order log and hidden layers if you're

00:07:47.660 --> 00:07:47.670
order log and hidden layers if you're
 

00:07:47.670 --> 00:07:50.090
order log and hidden layers if you're
forced to compute this function with

00:07:50.090 --> 00:07:50.100
forced to compute this function with
 

00:07:50.100 --> 00:07:52.970
forced to compute this function with
just one hidden layer right so you have

00:07:52.970 --> 00:07:52.980
just one hidden layer right so you have
 

00:07:52.980 --> 00:07:56.290
just one hidden layer right so you have
all these things going into you know

00:07:56.290 --> 00:07:56.300
all these things going into you know
 

00:07:56.300 --> 00:07:58.700
all these things going into you know
sort of hidden units and then these

00:07:58.700 --> 00:07:58.710
sort of hidden units and then these
 

00:07:58.710 --> 00:08:03.140
sort of hidden units and then these
things then outputs Y then in order to

00:08:03.140 --> 00:08:03.150
things then outputs Y then in order to
 

00:08:03.150 --> 00:08:05.780
things then outputs Y then in order to
compute the parity of X to compute this

00:08:05.780 --> 00:08:05.790
compute the parity of X to compute this
 

00:08:05.790 --> 00:08:09.350
compute the parity of X to compute this
XOR function this hidden layer will need

00:08:09.350 --> 00:08:09.360
XOR function this hidden layer will need
 

00:08:09.360 --> 00:08:11.810
XOR function this hidden layer will need
to be exponentially large because

00:08:11.810 --> 00:08:11.820
to be exponentially large because
 

00:08:11.820 --> 00:08:14.930
to be exponentially large because
essentially you need to exhaustively

00:08:14.930 --> 00:08:14.940
essentially you need to exhaustively
 

00:08:14.940 --> 00:08:17.330
essentially you need to exhaustively
enumerate all 2 to the N possible

00:08:17.330 --> 00:08:17.340
enumerate all 2 to the N possible
 

00:08:17.340 --> 00:08:19.970
enumerate all 2 to the N possible
configurations so on the order of 2 to

00:08:19.970 --> 00:08:19.980
configurations so on the order of 2 to
 

00:08:19.980 --> 00:08:23.720
configurations so on the order of 2 to
the N possible configurations of the

00:08:23.720 --> 00:08:23.730
the N possible configurations of the
 

00:08:23.730 --> 00:08:26.120
the N possible configurations of the
input bits that result in the exclusive

00:08:26.120 --> 00:08:26.130
input bits that result in the exclusive
 

00:08:26.130 --> 00:08:27.429
input bits that result in the exclusive
or being either

00:08:27.429 --> 00:08:27.439
or being either
 

00:08:27.439 --> 00:08:29.769
or being either
zero so you end up needing a hidden

00:08:29.769 --> 00:08:29.779
zero so you end up needing a hidden
 

00:08:29.779 --> 00:08:32.259
zero so you end up needing a hidden
layer that is exponentially large in the

00:08:32.259 --> 00:08:32.269
layer that is exponentially large in the
 

00:08:32.269 --> 00:08:34.629
layer that is exponentially large in the
number of bits I think technically you

00:08:34.629 --> 00:08:34.639
number of bits I think technically you
 

00:08:34.639 --> 00:08:37.240
number of bits I think technically you
could do this we have 2 to the N minus 1

00:08:37.240 --> 00:08:37.250
could do this we have 2 to the N minus 1
 

00:08:37.250 --> 00:08:39.219
could do this we have 2 to the N minus 1
hidden units right but that's the order

00:08:39.219 --> 00:08:39.229
hidden units right but that's the order
 

00:08:39.229 --> 00:08:41.680
hidden units right but that's the order
2 to the N is gonna be exponentially

00:08:41.680 --> 00:08:41.690
2 to the N is gonna be exponentially
 

00:08:41.690 --> 00:08:44.769
2 to the N is gonna be exponentially
large in the number of bits so hope this

00:08:44.769 --> 00:08:44.779
large in the number of bits so hope this
 

00:08:44.779 --> 00:08:46.769
large in the number of bits so hope this
gives a sense that there are

00:08:46.769 --> 00:08:46.779
gives a sense that there are
 

00:08:46.779 --> 00:08:49.929
gives a sense that there are
mathematical functions that are much

00:08:49.929 --> 00:08:49.939
mathematical functions that are much
 

00:08:49.939 --> 00:08:51.999
mathematical functions that are much
easier to compute with deep networks

00:08:51.999 --> 00:08:52.009
easier to compute with deep networks
 

00:08:52.009 --> 00:08:55.900
easier to compute with deep networks
than with shallow networks I have to

00:08:55.900 --> 00:08:55.910
than with shallow networks I have to
 

00:08:55.910 --> 00:08:58.809
than with shallow networks I have to
admit I personally found the result from

00:08:58.809 --> 00:08:58.819
admit I personally found the result from
 

00:08:58.819 --> 00:09:00.970
admit I personally found the result from
circuit theory less useful for gaining

00:09:00.970 --> 00:09:00.980
circuit theory less useful for gaining
 

00:09:00.980 --> 00:09:03.129
circuit theory less useful for gaining
intuitions but this is one of the

00:09:03.129 --> 00:09:03.139
intuitions but this is one of the
 

00:09:03.139 --> 00:09:05.559
intuitions but this is one of the
results that people often cite when just

00:09:05.559 --> 00:09:05.569
results that people often cite when just
 

00:09:05.569 --> 00:09:08.290
results that people often cite when just
when explaining the value of having very

00:09:08.290 --> 00:09:08.300
when explaining the value of having very
 

00:09:08.300 --> 00:09:12.369
when explaining the value of having very
deep representations now in addition to

00:09:12.369 --> 00:09:12.379
deep representations now in addition to
 

00:09:12.379 --> 00:09:15.220
deep representations now in addition to
these reasons for preferring deep neural

00:09:15.220 --> 00:09:15.230
these reasons for preferring deep neural
 

00:09:15.230 --> 00:09:17.980
these reasons for preferring deep neural
networks to be perfectly honest I think

00:09:17.980 --> 00:09:17.990
networks to be perfectly honest I think
 

00:09:17.990 --> 00:09:19.840
networks to be perfectly honest I think
the other reason the term term deep

00:09:19.840 --> 00:09:19.850
the other reason the term term deep
 

00:09:19.850 --> 00:09:20.980
the other reason the term term deep
learning has taken off

00:09:20.980 --> 00:09:20.990
learning has taken off
 

00:09:20.990 --> 00:09:22.689
learning has taken off
it's just branding right these things

00:09:22.689 --> 00:09:22.699
it's just branding right these things
 

00:09:22.699 --> 00:09:24.220
it's just branding right these things
used to be called neural networks above

00:09:24.220 --> 00:09:24.230
used to be called neural networks above
 

00:09:24.230 --> 00:09:26.350
used to be called neural networks above
all of hidden layers but the phrase deep

00:09:26.350 --> 00:09:26.360
all of hidden layers but the phrase deep
 

00:09:26.360 --> 00:09:28.809
all of hidden layers but the phrase deep
learning you know it's just a great

00:09:28.809 --> 00:09:28.819
learning you know it's just a great
 

00:09:28.819 --> 00:09:31.809
learning you know it's just a great
brand it just is so deep right so I

00:09:31.809 --> 00:09:31.819
brand it just is so deep right so I
 

00:09:31.819 --> 00:09:34.179
brand it just is so deep right so I
think that once that term called on that

00:09:34.179 --> 00:09:34.189
think that once that term called on that
 

00:09:34.189 --> 00:09:36.879
think that once that term called on that
really neuro networks rebranded or new

00:09:36.879 --> 00:09:36.889
really neuro networks rebranded or new
 

00:09:36.889 --> 00:09:38.199
really neuro networks rebranded or new
networks with many hidden layers

00:09:38.199 --> 00:09:38.209
networks with many hidden layers
 

00:09:38.209 --> 00:09:41.710
networks with many hidden layers
rebranded helped to capture the popular

00:09:41.710 --> 00:09:41.720
rebranded helped to capture the popular
 

00:09:41.720 --> 00:09:44.019
rebranded helped to capture the popular
imagination as well but regardless of

00:09:44.019 --> 00:09:44.029
imagination as well but regardless of
 

00:09:44.029 --> 00:09:46.809
imagination as well but regardless of
the PR branding deep networks do work

00:09:46.809 --> 00:09:46.819
the PR branding deep networks do work
 

00:09:46.819 --> 00:09:49.210
the PR branding deep networks do work
well sometimes people go overboard and

00:09:49.210 --> 00:09:49.220
well sometimes people go overboard and
 

00:09:49.220 --> 00:09:51.009
well sometimes people go overboard and
insist on using tons of hidden layers

00:09:51.009 --> 00:09:51.019
insist on using tons of hidden layers
 

00:09:51.019 --> 00:09:53.259
insist on using tons of hidden layers
but when I'm starting on a new problem I

00:09:53.259 --> 00:09:53.269
but when I'm starting on a new problem I
 

00:09:53.269 --> 00:09:55.090
but when I'm starting on a new problem I
often really start out with even

00:09:55.090 --> 00:09:55.100
often really start out with even
 

00:09:55.100 --> 00:09:57.040
often really start out with even
logistic regression and try something

00:09:57.040 --> 00:09:57.050
logistic regression and try something
 

00:09:57.050 --> 00:09:59.470
logistic regression and try something
with one or two hidden layers and use

00:09:59.470 --> 00:09:59.480
with one or two hidden layers and use
 

00:09:59.480 --> 00:10:02.410
with one or two hidden layers and use
that as a hyper parameter you said as a

00:10:02.410 --> 00:10:02.420
that as a hyper parameter you said as a
 

00:10:02.420 --> 00:10:04.660
that as a hyper parameter you said as a
parameter or hyper parameter that you

00:10:04.660 --> 00:10:04.670
parameter or hyper parameter that you
 

00:10:04.670 --> 00:10:06.819
parameter or hyper parameter that you
tune in order to try to find the right

00:10:06.819 --> 00:10:06.829
tune in order to try to find the right
 

00:10:06.829 --> 00:10:08.650
tune in order to try to find the right
therefore your neural network but over

00:10:08.650 --> 00:10:08.660
therefore your neural network but over
 

00:10:08.660 --> 00:10:10.059
therefore your neural network but over
the last several years there has been a

00:10:10.059 --> 00:10:10.069
the last several years there has been a
 

00:10:10.069 --> 00:10:12.790
the last several years there has been a
trend toward people finding that for

00:10:12.790 --> 00:10:12.800
trend toward people finding that for
 

00:10:12.800 --> 00:10:15.069
trend toward people finding that for
some applications very very deep neural

00:10:15.069 --> 00:10:15.079
some applications very very deep neural
 

00:10:15.079 --> 00:10:17.230
some applications very very deep neural
networks you know maybe many dozens of

00:10:17.230 --> 00:10:17.240
networks you know maybe many dozens of
 

00:10:17.240 --> 00:10:19.809
networks you know maybe many dozens of
layers sometimes can sometimes be the

00:10:19.809 --> 00:10:19.819
layers sometimes can sometimes be the
 

00:10:19.819 --> 00:10:23.410
layers sometimes can sometimes be the
best model for a problem so that's it

00:10:23.410 --> 00:10:23.420
best model for a problem so that's it
 

00:10:23.420 --> 00:10:25.749
best model for a problem so that's it
for the intuitions for why deep learning

00:10:25.749 --> 00:10:25.759
for the intuitions for why deep learning
 

00:10:25.759 --> 00:10:28.689
for the intuitions for why deep learning
seems to work well let's now take a look

00:10:28.689 --> 00:10:28.699
seems to work well let's now take a look
 

00:10:28.699 --> 00:10:30.939
seems to work well let's now take a look
at the mechanics of how to implement not

00:10:30.939 --> 00:10:30.949
at the mechanics of how to implement not
 

00:10:30.949 --> 00:10:32.889
at the mechanics of how to implement not
just for propagation but also back

00:10:32.889 --> 00:10:32.899
just for propagation but also back
 

00:10:32.899 --> 00:10:35.379
just for propagation but also back
propagation

