WEBVTT
Kind: captions
Language: en

00:00:09.460 --> 00:00:13.530
 
well by 2020 we'll have computers that

00:00:13.530 --> 00:00:13.540
well by 2020 we'll have computers that
 

00:00:13.540 --> 00:00:15.090
well by 2020 we'll have computers that
are powerful enough to simulate the

00:00:15.090 --> 00:00:15.100
are powerful enough to simulate the
 

00:00:15.100 --> 00:00:17.580
are powerful enough to simulate the
human brain but we won't be finished yet

00:00:17.580 --> 00:00:17.590
human brain but we won't be finished yet
 

00:00:17.590 --> 00:00:19.530
human brain but we won't be finished yet
with reverse engineering the UN brain

00:00:19.530 --> 00:00:19.540
with reverse engineering the UN brain
 

00:00:19.540 --> 00:00:22.800
with reverse engineering the UN brain
and understanding its methods one of my

00:00:22.800 --> 00:00:22.810
and understanding its methods one of my
 

00:00:22.810 --> 00:00:26.790
and understanding its methods one of my
main themes and and I've developed this

00:00:26.790 --> 00:00:26.800
main themes and and I've developed this
 

00:00:26.800 --> 00:00:29.820
main themes and and I've developed this
thesis over 30 years is that information

00:00:29.820 --> 00:00:29.830
thesis over 30 years is that information
 

00:00:29.830 --> 00:00:32.430
thesis over 30 years is that information
technology grows exponentially the power

00:00:32.430 --> 00:00:32.440
technology grows exponentially the power
 

00:00:32.440 --> 00:00:34.200
technology grows exponentially the power
of computers are understanding the human

00:00:34.200 --> 00:00:34.210
of computers are understanding the human
 

00:00:34.210 --> 00:00:35.939
of computers are understanding the human
brain the spatial resolution of

00:00:35.939 --> 00:00:35.949
brain the spatial resolution of
 

00:00:35.949 --> 00:00:37.560
brain the spatial resolution of
brain-scanning the number of bits we

00:00:37.560 --> 00:00:37.570
brain-scanning the number of bits we
 

00:00:37.570 --> 00:00:39.060
brain-scanning the number of bits we
move around the internet I mean many

00:00:39.060 --> 00:00:39.070
move around the internet I mean many
 

00:00:39.070 --> 00:00:41.130
move around the internet I mean many
different measures of information

00:00:41.130 --> 00:00:41.140
different measures of information
 

00:00:41.140 --> 00:00:44.760
different measures of information
technology double every one year or

00:00:44.760 --> 00:00:44.770
technology double every one year or
 

00:00:44.770 --> 00:00:46.830
technology double every one year or
every 11 months 13 months depending on

00:00:46.830 --> 00:00:46.840
every 11 months 13 months depending on
 

00:00:46.840 --> 00:00:48.870
every 11 months 13 months depending on
what you're measuring so these

00:00:48.870 --> 00:00:48.880
what you're measuring so these
 

00:00:48.880 --> 00:00:51.660
what you're measuring so these
technologies will be a million times

00:00:51.660 --> 00:00:51.670
technologies will be a million times
 

00:00:51.670 --> 00:00:53.940
technologies will be a million times
more powerful within 20 years 20 years

00:00:53.940 --> 00:00:53.950
more powerful within 20 years 20 years
 

00:00:53.950 --> 00:00:56.400
more powerful within 20 years 20 years
in fact the speed of exponential growth

00:00:56.400 --> 00:00:56.410
in fact the speed of exponential growth
 

00:00:56.410 --> 00:00:59.010
in fact the speed of exponential growth
is itself speeding up so in 25 years

00:00:59.010 --> 00:00:59.020
is itself speeding up so in 25 years
 

00:00:59.020 --> 00:01:01.260
is itself speeding up so in 25 years
these these technologies will be a

00:01:01.260 --> 00:01:01.270
these these technologies will be a
 

00:01:01.270 --> 00:01:02.880
these these technologies will be a
billion times more powerful than they

00:01:02.880 --> 00:01:02.890
billion times more powerful than they
 

00:01:02.890 --> 00:01:05.219
billion times more powerful than they
are today and we've already seen that

00:01:05.219 --> 00:01:05.229
are today and we've already seen that
 

00:01:05.229 --> 00:01:06.420
are today and we've already seen that
kind of progress when I was an

00:01:06.420 --> 00:01:06.430
kind of progress when I was an
 

00:01:06.430 --> 00:01:08.760
kind of progress when I was an
undergraduate we all shared computer at

00:01:08.760 --> 00:01:08.770
undergraduate we all shared computer at
 

00:01:08.770 --> 00:01:11.130
undergraduate we all shared computer at
MIT that took up half a building the

00:01:11.130 --> 00:01:11.140
MIT that took up half a building the
 

00:01:11.140 --> 00:01:12.660
MIT that took up half a building the
computer in your cell phone today is a

00:01:12.660 --> 00:01:12.670
computer in your cell phone today is a
 

00:01:12.670 --> 00:01:15.210
computer in your cell phone today is a
million times cheaper and a thousand

00:01:15.210 --> 00:01:15.220
million times cheaper and a thousand
 

00:01:15.220 --> 00:01:17.039
million times cheaper and a thousand
times more powerful that's a billion

00:01:17.039 --> 00:01:17.049
times more powerful that's a billion
 

00:01:17.049 --> 00:01:19.620
times more powerful that's a billion
fold increase in price performance of

00:01:19.620 --> 00:01:19.630
fold increase in price performance of
 

00:01:19.630 --> 00:01:21.710
fold increase in price performance of
computing since I was an undergraduate

00:01:21.710 --> 00:01:21.720
computing since I was an undergraduate
 

00:01:21.720 --> 00:01:24.690
computing since I was an undergraduate
by 2029 and I've been quite consistent

00:01:24.690 --> 00:01:24.700
by 2029 and I've been quite consistent
 

00:01:24.700 --> 00:01:27.420
by 2029 and I've been quite consistent
on this date we will have completed the

00:01:27.420 --> 00:01:27.430
on this date we will have completed the
 

00:01:27.430 --> 00:01:29.070
on this date we will have completed the
reverse engineering at the human brain

00:01:29.070 --> 00:01:29.080
reverse engineering at the human brain
 

00:01:29.080 --> 00:01:31.170
reverse engineering at the human brain
and we're already made very good

00:01:31.170 --> 00:01:31.180
and we're already made very good
 

00:01:31.180 --> 00:01:32.820
and we're already made very good
progress on that we've reverse

00:01:32.820 --> 00:01:32.830
progress on that we've reverse
 

00:01:32.830 --> 00:01:35.010
progress on that we've reverse
engineered a number of different regions

00:01:35.010 --> 00:01:35.020
engineered a number of different regions
 

00:01:35.020 --> 00:01:36.960
engineered a number of different regions
like the cerebellum which is responsible

00:01:36.960 --> 00:01:36.970
like the cerebellum which is responsible
 

00:01:36.970 --> 00:01:39.330
like the cerebellum which is responsible
for our skill formation and slices of

00:01:39.330 --> 00:01:39.340
for our skill formation and slices of
 

00:01:39.340 --> 00:01:41.010
for our skill formation and slices of
the cerebral cortex where we do our

00:01:41.010 --> 00:01:41.020
the cerebral cortex where we do our
 

00:01:41.020 --> 00:01:43.380
the cerebral cortex where we do our
recursive thinking and the auditory

00:01:43.380 --> 00:01:43.390
recursive thinking and the auditory
 

00:01:43.390 --> 00:01:46.649
recursive thinking and the auditory
cortex the visual cortex and so on by

00:01:46.649 --> 00:01:46.659
cortex the visual cortex and so on by
 

00:01:46.659 --> 00:01:49.980
cortex the visual cortex and so on by
2029 we'll have reverse-engineered and

00:01:49.980 --> 00:01:49.990
2029 we'll have reverse-engineered and
 

00:01:49.990 --> 00:01:52.050
2029 we'll have reverse-engineered and
modeled and simulated all the regions of

00:01:52.050 --> 00:01:52.060
modeled and simulated all the regions of
 

00:01:52.060 --> 00:01:54.149
modeled and simulated all the regions of
the brain and that will provide us the

00:01:54.149 --> 00:01:54.159
the brain and that will provide us the
 

00:01:54.159 --> 00:01:57.270
the brain and that will provide us the
software algorithmic methods to simulate

00:01:57.270 --> 00:01:57.280
software algorithmic methods to simulate
 

00:01:57.280 --> 00:01:59.399
software algorithmic methods to simulate
you know all of the human brain's

00:01:59.399 --> 00:01:59.409
you know all of the human brain's
 

00:01:59.409 --> 00:02:01.410
you know all of the human brain's
capabilities including our emotional

00:02:01.410 --> 00:02:01.420
capabilities including our emotional
 

00:02:01.420 --> 00:02:03.749
capabilities including our emotional
intelligence and computers at that time

00:02:03.749 --> 00:02:03.759
intelligence and computers at that time
 

00:02:03.759 --> 00:02:06.300
intelligence and computers at that time
will be far more powerful than the human

00:02:06.300 --> 00:02:06.310
will be far more powerful than the human
 

00:02:06.310 --> 00:02:07.980
will be far more powerful than the human
brain and we'll be able to create

00:02:07.980 --> 00:02:07.990
brain and we'll be able to create
 

00:02:07.990 --> 00:02:09.330
brain and we'll be able to create
machines that really do have the

00:02:09.330 --> 00:02:09.340
machines that really do have the
 

00:02:09.340 --> 00:02:10.889
machines that really do have the
subtlety and suppleness of human

00:02:10.889 --> 00:02:10.899
subtlety and suppleness of human
 

00:02:10.899 --> 00:02:13.080
subtlety and suppleness of human
intelligence and they'll combine that

00:02:13.080 --> 00:02:13.090
intelligence and they'll combine that
 

00:02:13.090 --> 00:02:15.539
intelligence and they'll combine that
power with ways in which machines

00:02:15.539 --> 00:02:15.549
power with ways in which machines
 

00:02:15.549 --> 00:02:18.990
power with ways in which machines
already superior to us they can harness

00:02:18.990 --> 00:02:19.000
already superior to us they can harness
 

00:02:19.000 --> 00:02:22.050
already superior to us they can harness
all of human knowledge with a few

00:02:22.050 --> 00:02:22.060
all of human knowledge with a few
 

00:02:22.060 --> 00:02:23.040
all of human knowledge with a few
keystrokes it can

00:02:23.040 --> 00:02:23.050
keystrokes it can
 

00:02:23.050 --> 00:02:24.270
keystrokes it can
member billions of things accurately

00:02:24.270 --> 00:02:24.280
member billions of things accurately
 

00:02:24.280 --> 00:02:26.160
member billions of things accurately
they can share knowledge electronic

00:02:26.160 --> 00:02:26.170
they can share knowledge electronic
 

00:02:26.170 --> 00:02:27.330
they can share knowledge electronic
speeds that are a million times faster

00:02:27.330 --> 00:02:27.340
speeds that are a million times faster
 

00:02:27.340 --> 00:02:30.390
speeds that are a million times faster
than the human language so it'll be a

00:02:30.390 --> 00:02:30.400
than the human language so it'll be a
 

00:02:30.400 --> 00:02:33.240
than the human language so it'll be a
very powerful combination but the last

00:02:33.240 --> 00:02:33.250
very powerful combination but the last
 

00:02:33.250 --> 00:02:34.740
very powerful combination but the last
point I'll make is that it's not some

00:02:34.740 --> 00:02:34.750
point I'll make is that it's not some
 

00:02:34.750 --> 00:02:36.480
point I'll make is that it's not some
alien invasion of intelligent machines

00:02:36.480 --> 00:02:36.490
alien invasion of intelligent machines
 

00:02:36.490 --> 00:02:39.420
alien invasion of intelligent machines
coming from artists to invade us it's

00:02:39.420 --> 00:02:39.430
coming from artists to invade us it's
 

00:02:39.430 --> 00:02:41.430
coming from artists to invade us it's
coming from within our civilization and

00:02:41.430 --> 00:02:41.440
coming from within our civilization and
 

00:02:41.440 --> 00:02:43.290
coming from within our civilization and
the whole point of it is to extend our

00:02:43.290 --> 00:02:43.300
the whole point of it is to extend our
 

00:02:43.300 --> 00:02:45.450
the whole point of it is to extend our
reach ever since we picked up a stick to

00:02:45.450 --> 00:02:45.460
reach ever since we picked up a stick to
 

00:02:45.460 --> 00:02:46.950
reach ever since we picked up a stick to
reach a higher branch we have used our

00:02:46.950 --> 00:02:46.960
reach a higher branch we have used our
 

00:02:46.960 --> 00:02:49.620
reach a higher branch we have used our
tools to extend our reach we can now

00:02:49.620 --> 00:02:49.630
tools to extend our reach we can now
 

00:02:49.630 --> 00:02:52.380
tools to extend our reach we can now
already extend our reach mentally I can

00:02:52.380 --> 00:02:52.390
already extend our reach mentally I can
 

00:02:52.390 --> 00:02:53.910
already extend our reach mentally I can
take out device from my pocket and

00:02:53.910 --> 00:02:53.920
take out device from my pocket and
 

00:02:53.920 --> 00:02:55.710
take out device from my pocket and
access all of human knowledge with a few

00:02:55.710 --> 00:02:55.720
access all of human knowledge with a few
 

00:02:55.720 --> 00:02:58.080
access all of human knowledge with a few
keystrokes half the farmers in China

00:02:58.080 --> 00:02:58.090
keystrokes half the farmers in China
 

00:02:58.090 --> 00:02:59.820
keystrokes half the farmers in China
have these devices and can do the same

00:02:59.820 --> 00:02:59.830
have these devices and can do the same
 

00:02:59.830 --> 00:03:01.950
have these devices and can do the same
thing it is pointing a real Cultural

00:03:01.950 --> 00:03:01.960
thing it is pointing a real Cultural
 

00:03:01.960 --> 00:03:05.280
thing it is pointing a real Cultural
Revolution in China and around the world

00:03:05.280 --> 00:03:05.290
Revolution in China and around the world
 

00:03:05.290 --> 00:03:07.470
Revolution in China and around the world
and these tools are continued to grow

00:03:07.470 --> 00:03:07.480
and these tools are continued to grow
 

00:03:07.480 --> 00:03:11.670
and these tools are continued to grow
exponentially in power the singularity

00:03:11.670 --> 00:03:11.680
exponentially in power the singularity
 

00:03:11.680 --> 00:03:14.250
exponentially in power the singularity
is not just that point where we achieve

00:03:14.250 --> 00:03:14.260
is not just that point where we achieve
 

00:03:14.260 --> 00:03:15.870
is not just that point where we achieve
human level of intelligence and machine

00:03:15.870 --> 00:03:15.880
human level of intelligence and machine
 

00:03:15.880 --> 00:03:18.090
human level of intelligence and machine
and that will start a new revolution

00:03:18.090 --> 00:03:18.100
and that will start a new revolution
 

00:03:18.100 --> 00:03:20.250
and that will start a new revolution
where these machines will continue to

00:03:20.250 --> 00:03:20.260
where these machines will continue to
 

00:03:20.260 --> 00:03:22.470
where these machines will continue to
grow exponentially in power they'll be

00:03:22.470 --> 00:03:22.480
grow exponentially in power they'll be
 

00:03:22.480 --> 00:03:24.210
grow exponentially in power they'll be
able to actually improve their own

00:03:24.210 --> 00:03:24.220
able to actually improve their own
 

00:03:24.220 --> 00:03:27.270
able to actually improve their own
software design by 2045 we'll have

00:03:27.270 --> 00:03:27.280
software design by 2045 we'll have
 

00:03:27.280 --> 00:03:29.790
software design by 2045 we'll have
expanded the intelligence of our human

00:03:29.790 --> 00:03:29.800
expanded the intelligence of our human
 

00:03:29.800 --> 00:03:32.490
expanded the intelligence of our human
machine civilization a billion fold that

00:03:32.490 --> 00:03:32.500
machine civilization a billion fold that
 

00:03:32.500 --> 00:03:34.800
machine civilization a billion fold that
will be singularity we borrowed this

00:03:34.800 --> 00:03:34.810
will be singularity we borrowed this
 

00:03:34.810 --> 00:03:36.660
will be singularity we borrowed this
metaphor from physics to talk about an

00:03:36.660 --> 00:03:36.670
metaphor from physics to talk about an
 

00:03:36.670 --> 00:03:41.980
metaphor from physics to talk about an
event horizon it's hard to see beyond

00:03:41.980 --> 00:03:41.990
 
 

00:03:41.990 --> 00:03:43.740
 
well it's not the case

00:03:43.740 --> 00:03:43.750
well it's not the case
 

00:03:43.750 --> 00:03:45.480
well it's not the case
I'm only looking at the optimistic side

00:03:45.480 --> 00:03:45.490
I'm only looking at the optimistic side
 

00:03:45.490 --> 00:03:47.280
I'm only looking at the optimistic side
I mean I am an optimist and I do think

00:03:47.280 --> 00:03:47.290
I mean I am an optimist and I do think
 

00:03:47.290 --> 00:03:49.350
I mean I am an optimist and I do think
we've been helped more than we've been

00:03:49.350 --> 00:03:49.360
we've been helped more than we've been
 

00:03:49.360 --> 00:03:52.110
we've been helped more than we've been
hurt by technology already human life

00:03:52.110 --> 00:03:52.120
hurt by technology already human life
 

00:03:52.120 --> 00:03:56.520
hurt by technology already human life
expectancy was 37 in 1800 and human life

00:03:56.520 --> 00:03:56.530
expectancy was 37 in 1800 and human life
 

00:03:56.530 --> 00:03:58.860
expectancy was 37 in 1800 and human life
was very hard disaster-prone labor

00:03:58.860 --> 00:03:58.870
was very hard disaster-prone labor
 

00:03:58.870 --> 00:04:02.100
was very hard disaster-prone labor
filled disease filled and so on but I've

00:04:02.100 --> 00:04:02.110
filled disease filled and so on but I've
 

00:04:02.110 --> 00:04:04.500
filled disease filled and so on but I've
actually written extensively about the

00:04:04.500 --> 00:04:04.510
actually written extensively about the
 

00:04:04.510 --> 00:04:07.650
actually written extensively about the
dangers of all this bill Joy's article

00:04:07.650 --> 00:04:07.660
dangers of all this bill Joy's article
 

00:04:07.660 --> 00:04:09.630
dangers of all this bill Joy's article
on the cover of Wired magazine while the

00:04:09.630 --> 00:04:09.640
on the cover of Wired magazine while the
 

00:04:09.640 --> 00:04:11.180
on the cover of Wired magazine while the
future does need us which talked about

00:04:11.180 --> 00:04:11.190
future does need us which talked about
 

00:04:11.190 --> 00:04:14.220
future does need us which talked about
the grave dangers of genetics

00:04:14.220 --> 00:04:14.230
the grave dangers of genetics
 

00:04:14.230 --> 00:04:15.810
the grave dangers of genetics
nanotechnology and robotics

00:04:15.810 --> 00:04:15.820
nanotechnology and robotics
 

00:04:15.820 --> 00:04:18.180
nanotechnology and robotics
came from my book he said he says at the

00:04:18.180 --> 00:04:18.190
came from my book he said he says at the
 

00:04:18.190 --> 00:04:19.470
came from my book he said he says at the
beginning of the article he got these

00:04:19.470 --> 00:04:19.480
beginning of the article he got these
 

00:04:19.480 --> 00:04:21.240
beginning of the article he got these
ideas from my book at the age of

00:04:21.240 --> 00:04:21.250
ideas from my book at the age of
 

00:04:21.250 --> 00:04:25.530
ideas from my book at the age of
spiritual machines and chapter 8 of the

00:04:25.530 --> 00:04:25.540
spiritual machines and chapter 8 of the
 

00:04:25.540 --> 00:04:27.810
spiritual machines and chapter 8 of the
singularity's nears is called the deeply

00:04:27.810 --> 00:04:27.820
singularity's nears is called the deeply
 

00:04:27.820 --> 00:04:31.140
singularity's nears is called the deeply
intertwined promise versus peril of GNR

00:04:31.140 --> 00:04:31.150
intertwined promise versus peril of GNR
 

00:04:31.150 --> 00:04:34.380
intertwined promise versus peril of GNR
genetics nanotechnology and robotics I'm

00:04:34.380 --> 00:04:34.390
genetics nanotechnology and robotics I'm
 

00:04:34.390 --> 00:04:36.690
genetics nanotechnology and robotics I'm
working extensively with the army to

00:04:36.690 --> 00:04:36.700
working extensively with the army to
 

00:04:36.700 --> 00:04:39.030
working extensively with the army to
develop a rapid response system to deal

00:04:39.030 --> 00:04:39.040
develop a rapid response system to deal
 

00:04:39.040 --> 00:04:41.159
develop a rapid response system to deal
with the possible abuse of biotechnology

00:04:41.159 --> 00:04:41.169
with the possible abuse of biotechnology
 

00:04:41.169 --> 00:04:44.010
with the possible abuse of biotechnology
so about the same technologies that are

00:04:44.010 --> 00:04:44.020
so about the same technologies that are
 

00:04:44.020 --> 00:04:46.890
so about the same technologies that are
empowering us to reprogram biology away

00:04:46.890 --> 00:04:46.900
empowering us to reprogram biology away
 

00:04:46.900 --> 00:04:48.690
empowering us to reprogram biology away
from cancer and heart disease could also

00:04:48.690 --> 00:04:48.700
from cancer and heart disease could also
 

00:04:48.700 --> 00:04:51.990
from cancer and heart disease could also
be used by a bioterrorist to reprogram a

00:04:51.990 --> 00:04:52.000
be used by a bioterrorist to reprogram a
 

00:04:52.000 --> 00:04:54.180
be used by a bioterrorist to reprogram a
biological virus to be more deadly or

00:04:54.180 --> 00:04:54.190
biological virus to be more deadly or
 

00:04:54.190 --> 00:04:57.480
biological virus to be more deadly or
more communicable and the good news is

00:04:57.480 --> 00:04:57.490
more communicable and the good news is
 

00:04:57.490 --> 00:04:59.100
more communicable and the good news is
we actually have the scientific tools to

00:04:59.100 --> 00:04:59.110
we actually have the scientific tools to
 

00:04:59.110 --> 00:05:00.030
we actually have the scientific tools to
defend ourselves

00:05:00.030 --> 00:05:00.040
defend ourselves
 

00:05:00.040 --> 00:05:01.770
defend ourselves
just like we defend ourselves from

00:05:01.770 --> 00:05:01.780
just like we defend ourselves from
 

00:05:01.780 --> 00:05:04.200
just like we defend ourselves from
software viruses with a rapid response

00:05:04.200 --> 00:05:04.210
software viruses with a rapid response
 

00:05:04.210 --> 00:05:06.090
software viruses with a rapid response
system and we need to put a system like

00:05:06.090 --> 00:05:06.100
system and we need to put a system like
 

00:05:06.100 --> 00:05:09.000
system and we need to put a system like
that in place but it's up it's not

00:05:09.000 --> 00:05:09.010
that in place but it's up it's not
 

00:05:09.010 --> 00:05:11.850
that in place but it's up it's not
accurate to say that I'm only painting a

00:05:11.850 --> 00:05:11.860
accurate to say that I'm only painting a
 

00:05:11.860 --> 00:05:13.969
accurate to say that I'm only painting a
rosy future and that I have a utopian

00:05:13.969 --> 00:05:13.979
rosy future and that I have a utopian
 

00:05:13.979 --> 00:05:16.560
rosy future and that I have a utopian
vision my vision is not utopian the

00:05:16.560 --> 00:05:16.570
vision my vision is not utopian the
 

00:05:16.570 --> 00:05:18.600
vision my vision is not utopian the
power of these technologies will grow

00:05:18.600 --> 00:05:18.610
power of these technologies will grow
 

00:05:18.610 --> 00:05:20.719
power of these technologies will grow
exponentially I believe that is

00:05:20.719 --> 00:05:20.729
exponentially I believe that is
 

00:05:20.729 --> 00:05:23.240
exponentially I believe that is
inexorable that has gone on for the last

00:05:23.240 --> 00:05:23.250
inexorable that has gone on for the last
 

00:05:23.250 --> 00:05:26.880
inexorable that has gone on for the last
110 years since the 1890 census what we

00:05:26.880 --> 00:05:26.890
110 years since the 1890 census what we
 

00:05:26.890 --> 00:05:28.680
110 years since the 1890 census what we
do with these technologies is not

00:05:28.680 --> 00:05:28.690
do with these technologies is not
 

00:05:28.690 --> 00:05:31.650
do with these technologies is not
preordained that future history has not

00:05:31.650 --> 00:05:31.660
preordained that future history has not
 

00:05:31.660 --> 00:05:34.500
preordained that future history has not
been written I am very concerned about

00:05:34.500 --> 00:05:34.510
been written I am very concerned about
 

00:05:34.510 --> 00:05:36.630
been written I am very concerned about
the downsides I've written extensively

00:05:36.630 --> 00:05:36.640
the downsides I've written extensively
 

00:05:36.640 --> 00:05:39.500
the downsides I've written extensively
about them and in fact I'm working on on

00:05:39.500 --> 00:05:39.510
about them and in fact I'm working on on
 

00:05:39.510 --> 00:05:42.780
about them and in fact I'm working on on
defending against those I am optimistic

00:05:42.780 --> 00:05:42.790
defending against those I am optimistic
 

00:05:42.790 --> 00:05:47.280
defending against those I am optimistic
that we will get more promise than peril

00:05:47.280 --> 00:05:47.290
that we will get more promise than peril
 

00:05:47.290 --> 00:05:50.010
that we will get more promise than peril
but they both exist technology has been

00:05:50.010 --> 00:05:50.020
but they both exist technology has been
 

00:05:50.020 --> 00:05:51.060
but they both exist technology has been
a double-edged sword

00:05:51.060 --> 00:05:51.070
a double-edged sword
 

00:05:51.070 --> 00:05:56.330
a double-edged sword
ever since fire and stone tools

00:05:56.330 --> 00:05:56.340
 
 

00:05:56.340 --> 00:05:58.790
 
well I've been very active in talking

00:05:58.790 --> 00:05:58.800
well I've been very active in talking
 

00:05:58.800 --> 00:06:00.920
well I've been very active in talking
about the down side of technology and

00:06:00.920 --> 00:06:00.930
about the down side of technology and
 

00:06:00.930 --> 00:06:04.190
about the down side of technology and
there are dangers a danger we face right

00:06:04.190 --> 00:06:04.200
there are dangers a danger we face right
 

00:06:04.200 --> 00:06:08.480
there are dangers a danger we face right
now is the ability for a bioterrorist to

00:06:08.480 --> 00:06:08.490
now is the ability for a bioterrorist to
 

00:06:08.490 --> 00:06:11.120
now is the ability for a bioterrorist to
use our biological sciences to reprogram

00:06:11.120 --> 00:06:11.130
use our biological sciences to reprogram
 

00:06:11.130 --> 00:06:15.050
use our biological sciences to reprogram
a biological virus to be deadly or

00:06:15.050 --> 00:06:15.060
a biological virus to be deadly or
 

00:06:15.060 --> 00:06:18.170
a biological virus to be deadly or
communicable and we have the ideas to

00:06:18.170 --> 00:06:18.180
communicable and we have the ideas to
 

00:06:18.180 --> 00:06:19.879
communicable and we have the ideas to
combat that but if they're not yet in

00:06:19.879 --> 00:06:19.889
combat that but if they're not yet in
 

00:06:19.889 --> 00:06:21.980
combat that but if they're not yet in
place and so I think that's an

00:06:21.980 --> 00:06:21.990
place and so I think that's an
 

00:06:21.990 --> 00:06:23.540
place and so I think that's an
existential risk we need to deal with

00:06:23.540 --> 00:06:23.550
existential risk we need to deal with
 

00:06:23.550 --> 00:06:26.600
existential risk we need to deal with
very quickly there will be new dangers

00:06:26.600 --> 00:06:26.610
very quickly there will be new dangers
 

00:06:26.610 --> 00:06:28.400
very quickly there will be new dangers
from these new technologies I mean I'm

00:06:28.400 --> 00:06:28.410
from these new technologies I mean I'm
 

00:06:28.410 --> 00:06:32.360
from these new technologies I mean I'm
optimistic but not sanguine and I'm not

00:06:32.360 --> 00:06:32.370
optimistic but not sanguine and I'm not
 

00:06:32.370 --> 00:06:35.120
optimistic but not sanguine and I'm not
necessarily convinced that we won't

00:06:35.120 --> 00:06:35.130
necessarily convinced that we won't
 

00:06:35.130 --> 00:06:39.050
necessarily convinced that we won't
encounter painful episodes I think

00:06:39.050 --> 00:06:39.060
encounter painful episodes I think
 

00:06:39.060 --> 00:06:41.330
encounter painful episodes I think
overall we'll be helped more than we're

00:06:41.330 --> 00:06:41.340
overall we'll be helped more than we're
 

00:06:41.340 --> 00:06:42.740
overall we'll be helped more than we're
heard but I mean you don't have to look

00:06:42.740 --> 00:06:42.750
heard but I mean you don't have to look
 

00:06:42.750 --> 00:06:44.930
heard but I mean you don't have to look
at the 20th century we had 180 million

00:06:44.930 --> 00:06:44.940
at the 20th century we had 180 million
 

00:06:44.940 --> 00:06:47.300
at the 20th century we had 180 million
people die in the wards of the 20th

00:06:47.300 --> 00:06:47.310
people die in the wards of the 20th
 

00:06:47.310 --> 00:06:49.460
people die in the wards of the 20th
century that scale of destruction was

00:06:49.460 --> 00:06:49.470
century that scale of destruction was
 

00:06:49.470 --> 00:06:51.770
century that scale of destruction was
made possible by technology we've also

00:06:51.770 --> 00:06:51.780
made possible by technology we've also
 

00:06:51.780 --> 00:06:54.230
made possible by technology we've also
helped ourselves enormous Lee because

00:06:54.230 --> 00:06:54.240
helped ourselves enormous Lee because
 

00:06:54.240 --> 00:06:58.190
helped ourselves enormous Lee because
human life expectancy was 48 in 1900 so

00:06:58.190 --> 00:06:58.200
human life expectancy was 48 in 1900 so
 

00:06:58.200 --> 00:07:01.340
human life expectancy was 48 in 1900 so
we need to address these these dangers

00:07:01.340 --> 00:07:01.350
we need to address these these dangers
 

00:07:01.350 --> 00:07:03.110
we need to address these these dangers
and downsides I mean that's what worries

00:07:03.110 --> 00:07:03.120
and downsides I mean that's what worries
 

00:07:03.120 --> 00:07:05.150
and downsides I mean that's what worries
me

