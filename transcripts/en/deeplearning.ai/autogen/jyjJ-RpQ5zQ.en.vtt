WEBVTT
Kind: captions
Language: en

00:00:00.210 --> 00:00:02.149
the data for your supervised learning

00:00:02.149 --> 00:00:02.159
the data for your supervised learning
 

00:00:02.159 --> 00:00:05.780
the data for your supervised learning
problem comprises input X and output

00:00:05.780 --> 00:00:05.790
problem comprises input X and output
 

00:00:05.790 --> 00:00:08.000
problem comprises input X and output
labels Y what have you going through

00:00:08.000 --> 00:00:08.010
labels Y what have you going through
 

00:00:08.010 --> 00:00:09.799
labels Y what have you going through
your data you find that some of these

00:00:09.799 --> 00:00:09.809
your data you find that some of these
 

00:00:09.809 --> 00:00:12.799
your data you find that some of these
upper labels Y are incorrect the up data

00:00:12.799 --> 00:00:12.809
upper labels Y are incorrect the up data
 

00:00:12.809 --> 00:00:15.259
upper labels Y are incorrect the up data
which is incorrectly labeled is it worth

00:00:15.259 --> 00:00:15.269
which is incorrectly labeled is it worth
 

00:00:15.269 --> 00:00:17.480
which is incorrectly labeled is it worth
your while to go in to fix up some of

00:00:17.480 --> 00:00:17.490
your while to go in to fix up some of
 

00:00:17.490 --> 00:00:20.060
your while to go in to fix up some of
these labels let's take a look in the

00:00:20.060 --> 00:00:20.070
these labels let's take a look in the
 

00:00:20.070 --> 00:00:22.580
these labels let's take a look in the
classification problem y equals 1 for

00:00:22.580 --> 00:00:22.590
classification problem y equals 1 for
 

00:00:22.590 --> 00:00:25.910
classification problem y equals 1 for
cats and 0 for non cats so let's say

00:00:25.910 --> 00:00:25.920
cats and 0 for non cats so let's say
 

00:00:25.920 --> 00:00:27.349
cats and 0 for non cats so let's say
you're looking through some data and

00:00:27.349 --> 00:00:27.359
you're looking through some data and
 

00:00:27.359 --> 00:00:29.839
you're looking through some data and
that's a cat that smelly cat does the

00:00:29.839 --> 00:00:29.849
that's a cat that smelly cat does the
 

00:00:29.849 --> 00:00:31.849
that's a cat that smelly cat does the
cat there's a cat that's not a cat

00:00:31.849 --> 00:00:31.859
cat there's a cat that's not a cat
 

00:00:31.859 --> 00:00:32.749
cat there's a cat that's not a cat
that's a cat

00:00:32.749 --> 00:00:32.759
that's a cat
 

00:00:32.759 --> 00:00:35.120
that's a cat
you know wait that's actually not a cat

00:00:35.120 --> 00:00:35.130
you know wait that's actually not a cat
 

00:00:35.130 --> 00:00:39.470
you know wait that's actually not a cat
so this is an example with an incorrect

00:00:39.470 --> 00:00:39.480
so this is an example with an incorrect
 

00:00:39.480 --> 00:00:43.160
so this is an example with an incorrect
label so I've used the term mislabeled

00:00:43.160 --> 00:00:43.170
label so I've used the term mislabeled
 

00:00:43.170 --> 00:00:45.260
label so I've used the term mislabeled
examples to refer to if your learning

00:00:45.260 --> 00:00:45.270
examples to refer to if your learning
 

00:00:45.270 --> 00:00:47.420
examples to refer to if your learning
algorithm I'll put the wrong value of Y

00:00:47.420 --> 00:00:47.430
algorithm I'll put the wrong value of Y
 

00:00:47.430 --> 00:00:50.119
algorithm I'll put the wrong value of Y
but I'm going to say incorrectly labeled

00:00:50.119 --> 00:00:50.129
but I'm going to say incorrectly labeled
 

00:00:50.129 --> 00:00:53.360
but I'm going to say incorrectly labeled
examples when to refer to if in the data

00:00:53.360 --> 00:00:53.370
examples when to refer to if in the data
 

00:00:53.370 --> 00:00:55.160
examples when to refer to if in the data
set you have in a training set or the

00:00:55.160 --> 00:00:55.170
set you have in a training set or the
 

00:00:55.170 --> 00:00:57.619
set you have in a training set or the
death set or the test set the label for

00:00:57.619 --> 00:00:57.629
death set or the test set the label for
 

00:00:57.629 --> 00:00:59.689
death set or the test set the label for
Y whenever a human label assigned to

00:00:59.689 --> 00:00:59.699
Y whenever a human label assigned to
 

00:00:59.699 --> 00:01:01.880
Y whenever a human label assigned to
this piece of data is actually incorrect

00:01:01.880 --> 00:01:01.890
this piece of data is actually incorrect
 

00:01:01.890 --> 00:01:04.219
this piece of data is actually incorrect
and that's actually a dog so that Y

00:01:04.219 --> 00:01:04.229
and that's actually a dog so that Y
 

00:01:04.229 --> 00:01:07.850
and that's actually a dog so that Y
really should have been 0 but maybe the

00:01:07.850 --> 00:01:07.860
really should have been 0 but maybe the
 

00:01:07.860 --> 00:01:10.640
really should have been 0 but maybe the
laborer got that one wrong so if you

00:01:10.640 --> 00:01:10.650
laborer got that one wrong so if you
 

00:01:10.650 --> 00:01:13.429
laborer got that one wrong so if you
find that your data has some incorrectly

00:01:13.429 --> 00:01:13.439
find that your data has some incorrectly
 

00:01:13.439 --> 00:01:16.700
find that your data has some incorrectly
labeled examples what should you do well

00:01:16.700 --> 00:01:16.710
labeled examples what should you do well
 

00:01:16.710 --> 00:01:21.740
labeled examples what should you do well
first let's consider the training set it

00:01:21.740 --> 00:01:21.750
first let's consider the training set it
 

00:01:21.750 --> 00:01:24.020
first let's consider the training set it
turns out that deep learning algorithms

00:01:24.020 --> 00:01:24.030
turns out that deep learning algorithms
 

00:01:24.030 --> 00:01:26.450
turns out that deep learning algorithms
are quite robust to random errors in the

00:01:26.450 --> 00:01:26.460
are quite robust to random errors in the
 

00:01:26.460 --> 00:01:29.480
are quite robust to random errors in the
training set so so long as your errors

00:01:29.480 --> 00:01:29.490
training set so so long as your errors
 

00:01:29.490 --> 00:01:32.630
training set so so long as your errors
or your incorrectly labeled examples so

00:01:32.630 --> 00:01:32.640
or your incorrectly labeled examples so
 

00:01:32.640 --> 00:01:34.490
or your incorrectly labeled examples so
once those errors are not too far from

00:01:34.490 --> 00:01:34.500
once those errors are not too far from
 

00:01:34.500 --> 00:01:38.510
once those errors are not too far from
random you know maybe sometimes on the

00:01:38.510 --> 00:01:38.520
random you know maybe sometimes on the
 

00:01:38.520 --> 00:01:40.370
random you know maybe sometimes on the
labourer just wasn't paying attention or

00:01:40.370 --> 00:01:40.380
labourer just wasn't paying attention or
 

00:01:40.380 --> 00:01:42.590
labourer just wasn't paying attention or
they accidentally randomly hit the wrong

00:01:42.590 --> 00:01:42.600
they accidentally randomly hit the wrong
 

00:01:42.600 --> 00:01:45.109
they accidentally randomly hit the wrong
key on keyboard if the errors are

00:01:45.109 --> 00:01:45.119
key on keyboard if the errors are
 

00:01:45.119 --> 00:01:48.380
key on keyboard if the errors are
reasonably random then it's probably ok

00:01:48.380 --> 00:01:48.390
reasonably random then it's probably ok
 

00:01:48.390 --> 00:01:50.539
reasonably random then it's probably ok
to just leave the errors as they are and

00:01:50.539 --> 00:01:50.549
to just leave the errors as they are and
 

00:01:50.549 --> 00:01:52.730
to just leave the errors as they are and
not spend too much time fixing them

00:01:52.730 --> 00:01:52.740
not spend too much time fixing them
 

00:01:52.740 --> 00:01:54.980
not spend too much time fixing them
there's certainly no harm to going into

00:01:54.980 --> 00:01:54.990
there's certainly no harm to going into
 

00:01:54.990 --> 00:01:56.630
there's certainly no harm to going into
your training set and be examining the

00:01:56.630 --> 00:01:56.640
your training set and be examining the
 

00:01:56.640 --> 00:01:58.609
your training set and be examining the
labels and fixing them sometimes that is

00:01:58.609 --> 00:01:58.619
labels and fixing them sometimes that is
 

00:01:58.619 --> 00:02:01.190
labels and fixing them sometimes that is
worth doing but your alpha might be okay

00:02:01.190 --> 00:02:01.200
worth doing but your alpha might be okay
 

00:02:01.200 --> 00:02:03.770
worth doing but your alpha might be okay
even if you don't so long as the total

00:02:03.770 --> 00:02:03.780
even if you don't so long as the total
 

00:02:03.780 --> 00:02:06.340
even if you don't so long as the total
data set size is big enough

00:02:06.340 --> 00:02:06.350
data set size is big enough
 

00:02:06.350 --> 00:02:08.980
data set size is big enough
and actual percentage of errors is you

00:02:08.980 --> 00:02:08.990
and actual percentage of errors is you
 

00:02:08.990 --> 00:02:11.470
and actual percentage of errors is you
know maybe not too high so I see a lot

00:02:11.470 --> 00:02:11.480
know maybe not too high so I see a lot
 

00:02:11.480 --> 00:02:13.150
know maybe not too high so I see a lot
of machine learning algorithms that are

00:02:13.150 --> 00:02:13.160
of machine learning algorithms that are
 

00:02:13.160 --> 00:02:15.400
of machine learning algorithms that are
trained even when we know that there are

00:02:15.400 --> 00:02:15.410
trained even when we know that there are
 

00:02:15.410 --> 00:02:18.010
trained even when we know that there are
a few it's mistakes in the training side

00:02:18.010 --> 00:02:18.020
a few it's mistakes in the training side
 

00:02:18.020 --> 00:02:21.610
a few it's mistakes in the training side
labels and usually works ok there is one

00:02:21.610 --> 00:02:21.620
labels and usually works ok there is one
 

00:02:21.620 --> 00:02:25.930
labels and usually works ok there is one
caveat to this which is that people only

00:02:25.930 --> 00:02:25.940
caveat to this which is that people only
 

00:02:25.940 --> 00:02:29.350
caveat to this which is that people only
albums are robust random errors they are

00:02:29.350 --> 00:02:29.360
albums are robust random errors they are
 

00:02:29.360 --> 00:02:35.559
albums are robust random errors they are
less robust to systematic errors so for

00:02:35.559 --> 00:02:35.569
less robust to systematic errors so for
 

00:02:35.569 --> 00:02:37.840
less robust to systematic errors so for
example if your labels consistently

00:02:37.840 --> 00:02:37.850
example if your labels consistently
 

00:02:37.850 --> 00:02:41.320
example if your labels consistently
labeled white dogs as we had then that

00:02:41.320 --> 00:02:41.330
labeled white dogs as we had then that
 

00:02:41.330 --> 00:02:43.030
labeled white dogs as we had then that
is a problem because your classifier

00:02:43.030 --> 00:02:43.040
is a problem because your classifier
 

00:02:43.040 --> 00:02:45.280
is a problem because your classifier
will learn to classify on white colored

00:02:45.280 --> 00:02:45.290
will learn to classify on white colored
 

00:02:45.290 --> 00:02:49.270
will learn to classify on white colored
dogs as cats for random errors or near

00:02:49.270 --> 00:02:49.280
dogs as cats for random errors or near
 

00:02:49.280 --> 00:02:51.220
dogs as cats for random errors or near
random errors are usually not too bad

00:02:51.220 --> 00:02:51.230
random errors are usually not too bad
 

00:02:51.230 --> 00:02:55.059
random errors are usually not too bad
for most deep learning algorithms now

00:02:55.059 --> 00:02:55.069
for most deep learning algorithms now
 

00:02:55.069 --> 00:02:57.580
for most deep learning algorithms now
this discussion has focus on what to do

00:02:57.580 --> 00:02:57.590
this discussion has focus on what to do
 

00:02:57.590 --> 00:02:59.650
this discussion has focus on what to do
about incorrectly labeled examples in

00:02:59.650 --> 00:02:59.660
about incorrectly labeled examples in
 

00:02:59.660 --> 00:03:01.840
about incorrectly labeled examples in
your training set how about incorrectly

00:03:01.840 --> 00:03:01.850
your training set how about incorrectly
 

00:03:01.850 --> 00:03:04.210
your training set how about incorrectly
labeled examples in your def set or test

00:03:04.210 --> 00:03:04.220
labeled examples in your def set or test
 

00:03:04.220 --> 00:03:06.699
labeled examples in your def set or test
set if you're worried about the impact

00:03:06.699 --> 00:03:06.709
set if you're worried about the impact
 

00:03:06.709 --> 00:03:09.100
set if you're worried about the impact
of incorrectly labeled examples on your

00:03:09.100 --> 00:03:09.110
of incorrectly labeled examples on your
 

00:03:09.110 --> 00:03:11.259
of incorrectly labeled examples on your
deaf set or test set what I recommend

00:03:11.259 --> 00:03:11.269
deaf set or test set what I recommend
 

00:03:11.269 --> 00:03:14.199
deaf set or test set what I recommend
you do is drink error analysis to add

00:03:14.199 --> 00:03:14.209
you do is drink error analysis to add
 

00:03:14.209 --> 00:03:17.110
you do is drink error analysis to add
one extra column so that you can also

00:03:17.110 --> 00:03:17.120
one extra column so that you can also
 

00:03:17.120 --> 00:03:19.300
one extra column so that you can also
count up the number of examples where

00:03:19.300 --> 00:03:19.310
count up the number of examples where
 

00:03:19.310 --> 00:03:22.569
count up the number of examples where
the label Y was in your eggs so for

00:03:22.569 --> 00:03:22.579
the label Y was in your eggs so for
 

00:03:22.579 --> 00:03:25.090
the label Y was in your eggs so for
example maybe when you count up the

00:03:25.090 --> 00:03:25.100
example maybe when you count up the
 

00:03:25.100 --> 00:03:28.120
example maybe when you count up the
impact on a hundreds label deficit

00:03:28.120 --> 00:03:28.130
impact on a hundreds label deficit
 

00:03:28.130 --> 00:03:29.979
impact on a hundreds label deficit
examples so you're going to find 100

00:03:29.979 --> 00:03:29.989
examples so you're going to find 100
 

00:03:29.989 --> 00:03:32.500
examples so you're going to find 100
examples where your concise output

00:03:32.500 --> 00:03:32.510
examples where your concise output
 

00:03:32.510 --> 00:03:35.050
examples where your concise output
disagrees with the label in your def set

00:03:35.050 --> 00:03:35.060
disagrees with the label in your def set
 

00:03:35.060 --> 00:03:37.270
disagrees with the label in your def set
and sometimes for a few of those

00:03:37.270 --> 00:03:37.280
and sometimes for a few of those
 

00:03:37.280 --> 00:03:40.090
and sometimes for a few of those
examples your classifier disagrees with

00:03:40.090 --> 00:03:40.100
examples your classifier disagrees with
 

00:03:40.100 --> 00:03:42.039
examples your classifier disagrees with
the label because the label was wrong

00:03:42.039 --> 00:03:42.049
the label because the label was wrong
 

00:03:42.049 --> 00:03:43.690
the label because the label was wrong
rather than because you caused by wrong

00:03:43.690 --> 00:03:43.700
rather than because you caused by wrong
 

00:03:43.700 --> 00:03:46.780
rather than because you caused by wrong
so maybe in this example you find that

00:03:46.780 --> 00:03:46.790
so maybe in this example you find that
 

00:03:46.790 --> 00:03:48.880
so maybe in this example you find that
the label amidst a cat in the background

00:03:48.880 --> 00:03:48.890
the label amidst a cat in the background
 

00:03:48.890 --> 00:03:52.780
the label amidst a cat in the background
so um put a check mark there to signify

00:03:52.780 --> 00:03:52.790
so um put a check mark there to signify
 

00:03:52.790 --> 00:03:55.449
so um put a check mark there to signify
that example 98 had an incorrect label

00:03:55.449 --> 00:03:55.459
that example 98 had an incorrect label
 

00:03:55.459 --> 00:03:58.690
that example 98 had an incorrect label
and maybe for this one the picture is

00:03:58.690 --> 00:03:58.700
and maybe for this one the picture is
 

00:03:58.700 --> 00:04:00.280
and maybe for this one the picture is
actually a picture of a drawing of a cat

00:04:00.280 --> 00:04:00.290
actually a picture of a drawing of a cat
 

00:04:00.290 --> 00:04:02.470
actually a picture of a drawing of a cat
garden in a row cat and maybe you want

00:04:02.470 --> 00:04:02.480
garden in a row cat and maybe you want
 

00:04:02.480 --> 00:04:04.870
garden in a row cat and maybe you want
the neighborhoods of label that y equals

00:04:04.870 --> 00:04:04.880
the neighborhoods of label that y equals
 

00:04:04.880 --> 00:04:06.910
the neighborhoods of label that y equals
zero while rather than y equals one and

00:04:06.910 --> 00:04:06.920
zero while rather than y equals one and
 

00:04:06.920 --> 00:04:09.660
zero while rather than y equals one and
so you put another check mark there and

00:04:09.660 --> 00:04:09.670
so you put another check mark there and
 

00:04:09.670 --> 00:04:12.460
so you put another check mark there and
just as you count up the percent of

00:04:12.460 --> 00:04:12.470
just as you count up the percent of
 

00:04:12.470 --> 00:04:14.439
just as you count up the percent of
errors due to other categories like we

00:04:14.439 --> 00:04:14.449
errors due to other categories like we
 

00:04:14.449 --> 00:04:16.509
errors due to other categories like we
saw in a previous video you'd also count

00:04:16.509 --> 00:04:16.519
saw in a previous video you'd also count
 

00:04:16.519 --> 00:04:17.560
saw in a previous video you'd also count
up

00:04:17.560 --> 00:04:17.570
up
 

00:04:17.570 --> 00:04:19.600
up
percentage of errors due to incorrect

00:04:19.600 --> 00:04:19.610
percentage of errors due to incorrect
 

00:04:19.610 --> 00:04:22.870
percentage of errors due to incorrect
labels whether Y value in the DEF set

00:04:22.870 --> 00:04:22.880
labels whether Y value in the DEF set
 

00:04:22.880 --> 00:04:25.300
labels whether Y value in the DEF set
was wrong and that accounted for while

00:04:25.300 --> 00:04:25.310
was wrong and that accounted for while
 

00:04:25.310 --> 00:04:26.920
was wrong and that accounted for while
your learning algorithm made the

00:04:26.920 --> 00:04:26.930
your learning algorithm made the
 

00:04:26.930 --> 00:04:29.680
your learning algorithm made the
prediction that differed from what the

00:04:29.680 --> 00:04:29.690
prediction that differed from what the
 

00:04:29.690 --> 00:04:33.100
prediction that differed from what the
label on your data says so the question

00:04:33.100 --> 00:04:33.110
label on your data says so the question
 

00:04:33.110 --> 00:04:35.590
label on your data says so the question
now is is it worthwhile going in to try

00:04:35.590 --> 00:04:35.600
now is is it worthwhile going in to try
 

00:04:35.600 --> 00:04:38.290
now is is it worthwhile going in to try
to fix up you know this six percent of

00:04:38.290 --> 00:04:38.300
to fix up you know this six percent of
 

00:04:38.300 --> 00:04:41.200
to fix up you know this six percent of
the incorrectly labeled examples my

00:04:41.200 --> 00:04:41.210
the incorrectly labeled examples my
 

00:04:41.210 --> 00:04:43.750
the incorrectly labeled examples my
advice is if it makes a significant

00:04:43.750 --> 00:04:43.760
advice is if it makes a significant
 

00:04:43.760 --> 00:04:45.730
advice is if it makes a significant
difference to your ability to evaluate

00:04:45.730 --> 00:04:45.740
difference to your ability to evaluate
 

00:04:45.740 --> 00:04:48.010
difference to your ability to evaluate
algorithms on your def set then go ahead

00:04:48.010 --> 00:04:48.020
algorithms on your def set then go ahead
 

00:04:48.020 --> 00:04:49.870
algorithms on your def set then go ahead
and spend the time to fix the incorrect

00:04:49.870 --> 00:04:49.880
and spend the time to fix the incorrect
 

00:04:49.880 --> 00:04:51.670
and spend the time to fix the incorrect
labels but if it doesn't make a

00:04:51.670 --> 00:04:51.680
labels but if it doesn't make a
 

00:04:51.680 --> 00:04:53.380
labels but if it doesn't make a
significant difference to your ability

00:04:53.380 --> 00:04:53.390
significant difference to your ability
 

00:04:53.390 --> 00:04:55.690
significant difference to your ability
to use the DEF set to value classifiers

00:04:55.690 --> 00:04:55.700
to use the DEF set to value classifiers
 

00:04:55.700 --> 00:04:57.640
to use the DEF set to value classifiers
then it might not be the best use of

00:04:57.640 --> 00:04:57.650
then it might not be the best use of
 

00:04:57.650 --> 00:04:59.470
then it might not be the best use of
your time let me show you an example

00:04:59.470 --> 00:04:59.480
your time let me show you an example
 

00:04:59.480 --> 00:05:01.780
your time let me show you an example
that illustrates what I mean by this

00:05:01.780 --> 00:05:01.790
that illustrates what I mean by this
 

00:05:01.790 --> 00:05:04.510
that illustrates what I mean by this
so three numbers I recommend you look at

00:05:04.510 --> 00:05:04.520
so three numbers I recommend you look at
 

00:05:04.520 --> 00:05:06.400
so three numbers I recommend you look at
to try to decide if it's worth going in

00:05:06.400 --> 00:05:06.410
to try to decide if it's worth going in
 

00:05:06.410 --> 00:05:08.170
to try to decide if it's worth going in
and reducing the number of miss labor

00:05:08.170 --> 00:05:08.180
and reducing the number of miss labor
 

00:05:08.180 --> 00:05:10.060
and reducing the number of miss labor
examples are the following recommend you

00:05:10.060 --> 00:05:10.070
examples are the following recommend you
 

00:05:10.070 --> 00:05:13.540
examples are the following recommend you
look at the overall def set error and so

00:05:13.540 --> 00:05:13.550
look at the overall def set error and so
 

00:05:13.550 --> 00:05:15.730
look at the overall def set error and so
in the example we had from the previous

00:05:15.730 --> 00:05:15.740
in the example we had from the previous
 

00:05:15.740 --> 00:05:18.610
in the example we had from the previous
video we said that maybe a system has

00:05:18.610 --> 00:05:18.620
video we said that maybe a system has
 

00:05:18.620 --> 00:05:22.410
video we said that maybe a system has
90% overall accuracy so 10 percent error

00:05:22.410 --> 00:05:22.420
90% overall accuracy so 10 percent error
 

00:05:22.420 --> 00:05:25.930
90% overall accuracy so 10 percent error
then you should look at the number of

00:05:25.930 --> 00:05:25.940
then you should look at the number of
 

00:05:25.940 --> 00:05:28.600
then you should look at the number of
errors or the percentage of errors

00:05:28.600 --> 00:05:28.610
errors or the percentage of errors
 

00:05:28.610 --> 00:05:31.060
errors or the percentage of errors
they're due to incorrect labels so it

00:05:31.060 --> 00:05:31.070
they're due to incorrect labels so it
 

00:05:31.070 --> 00:05:33.610
they're due to incorrect labels so it
looks like in this case 6 percent of the

00:05:33.610 --> 00:05:33.620
looks like in this case 6 percent of the
 

00:05:33.620 --> 00:05:35.830
looks like in this case 6 percent of the
errors are due to incorrect labels so

00:05:35.830 --> 00:05:35.840
errors are due to incorrect labels so
 

00:05:35.840 --> 00:05:40.240
errors are due to incorrect labels so
six percent of 10 percent is 0.6 percent

00:05:40.240 --> 00:05:40.250
six percent of 10 percent is 0.6 percent
 

00:05:40.250 --> 00:05:43.390
six percent of 10 percent is 0.6 percent
and then you should look at errors due

00:05:43.390 --> 00:05:43.400
and then you should look at errors due
 

00:05:43.400 --> 00:05:47.110
and then you should look at errors due
to all other causes so if you made 10

00:05:47.110 --> 00:05:47.120
to all other causes so if you made 10
 

00:05:47.120 --> 00:05:48.880
to all other causes so if you made 10
percent error on your def set and a

00:05:48.880 --> 00:05:48.890
percent error on your def set and a
 

00:05:48.890 --> 00:05:50.710
percent error on your def set and a
point 6 percent of those are because the

00:05:50.710 --> 00:05:50.720
point 6 percent of those are because the
 

00:05:50.720 --> 00:05:53.020
point 6 percent of those are because the
labels are wrong then the remainder 9

00:05:53.020 --> 00:05:53.030
labels are wrong then the remainder 9
 

00:05:53.030 --> 00:05:55.330
labels are wrong then the remainder 9
point 4 percent of them are due to other

00:05:55.330 --> 00:05:55.340
point 4 percent of them are due to other
 

00:05:55.340 --> 00:05:57.340
point 4 percent of them are due to other
causes such as miss recognizing dark

00:05:57.340 --> 00:05:57.350
causes such as miss recognizing dark
 

00:05:57.350 --> 00:05:59.200
causes such as miss recognizing dark
spring attacks great calves and very

00:05:59.200 --> 00:05:59.210
spring attacks great calves and very
 

00:05:59.210 --> 00:06:03.150
spring attacks great calves and very
images so in this case I would say

00:06:03.150 --> 00:06:03.160
images so in this case I would say
 

00:06:03.160 --> 00:06:05.860
images so in this case I would say
there's nine point four percent worth of

00:06:05.860 --> 00:06:05.870
there's nine point four percent worth of
 

00:06:05.870 --> 00:06:07.890
there's nine point four percent worth of
error that you could focus on fixing

00:06:07.890 --> 00:06:07.900
error that you could focus on fixing
 

00:06:07.900 --> 00:06:11.170
error that you could focus on fixing
whereas you know the errors due to

00:06:11.170 --> 00:06:11.180
whereas you know the errors due to
 

00:06:11.180 --> 00:06:13.270
whereas you know the errors due to
incorrect labels is a relatively small

00:06:13.270 --> 00:06:13.280
incorrect labels is a relatively small
 

00:06:13.280 --> 00:06:16.330
incorrect labels is a relatively small
fraction of the overall set of errors so

00:06:16.330 --> 00:06:16.340
fraction of the overall set of errors so
 

00:06:16.340 --> 00:06:18.670
fraction of the overall set of errors so
by all means go in and fix these

00:06:18.670 --> 00:06:18.680
by all means go in and fix these
 

00:06:18.680 --> 00:06:21.010
by all means go in and fix these
incorrect labels if you want but this

00:06:21.010 --> 00:06:21.020
incorrect labels if you want but this
 

00:06:21.020 --> 00:06:22.630
incorrect labels if you want but this
may be not the most important thing to

00:06:22.630 --> 00:06:22.640
may be not the most important thing to
 

00:06:22.640 --> 00:06:25.750
may be not the most important thing to
do right now now let's take another

00:06:25.750 --> 00:06:25.760
do right now now let's take another
 

00:06:25.760 --> 00:06:28.360
do right now now let's take another
example suppose you've made a lot more

00:06:28.360 --> 00:06:28.370
example suppose you've made a lot more
 

00:06:28.370 --> 00:06:30.190
example suppose you've made a lot more
progress on your learning problem so

00:06:30.190 --> 00:06:30.200
progress on your learning problem so
 

00:06:30.200 --> 00:06:31.260
progress on your learning problem so
instead of 10

00:06:31.260 --> 00:06:31.270
instead of 10
 

00:06:31.270 --> 00:06:33.150
instead of 10
era let's say you brought the arrows

00:06:33.150 --> 00:06:33.160
era let's say you brought the arrows
 

00:06:33.160 --> 00:06:39.030
era let's say you brought the arrows
down to two percent but still zero point

00:06:39.030 --> 00:06:39.040
down to two percent but still zero point
 

00:06:39.040 --> 00:06:41.250
down to two percent but still zero point
six percent of your overall errors are

00:06:41.250 --> 00:06:41.260
six percent of your overall errors are
 

00:06:41.260 --> 00:06:44.070
six percent of your overall errors are
due to incorrect labels so now if you

00:06:44.070 --> 00:06:44.080
due to incorrect labels so now if you
 

00:06:44.080 --> 00:06:46.770
due to incorrect labels so now if you
were to examine a set of mislabel def

00:06:46.770 --> 00:06:46.780
were to examine a set of mislabel def
 

00:06:46.780 --> 00:06:49.440
were to examine a set of mislabel def
set images so set that comes from this

00:06:49.440 --> 00:06:49.450
set images so set that comes from this
 

00:06:49.450 --> 00:06:51.660
set images so set that comes from this
two percent of deficit data you're

00:06:51.660 --> 00:06:51.670
two percent of deficit data you're
 

00:06:51.670 --> 00:06:54.990
two percent of deficit data you're
misleading then a lot a very large

00:06:54.990 --> 00:06:55.000
misleading then a lot a very large
 

00:06:55.000 --> 00:06:58.530
misleading then a lot a very large
fraction of them 0.6 divided by two

00:06:58.530 --> 00:06:58.540
fraction of them 0.6 divided by two
 

00:06:58.540 --> 00:07:00.900
fraction of them 0.6 divided by two
percent so there's actually 30 percent

00:07:00.900 --> 00:07:00.910
percent so there's actually 30 percent
 

00:07:00.910 --> 00:07:05.160
percent so there's actually 30 percent
rather than 6 percent of your labels of

00:07:05.160 --> 00:07:05.170
rather than 6 percent of your labels of
 

00:07:05.170 --> 00:07:06.930
rather than 6 percent of your labels of
your incorrect examples are actually due

00:07:06.930 --> 00:07:06.940
your incorrect examples are actually due
 

00:07:06.940 --> 00:07:09.660
your incorrect examples are actually due
to incorrectly labeled examples and so

00:07:09.660 --> 00:07:09.670
to incorrectly labeled examples and so
 

00:07:09.670 --> 00:07:12.240
to incorrectly labeled examples and so
errors due to other causes are now 1.4

00:07:12.240 --> 00:07:12.250
errors due to other causes are now 1.4
 

00:07:12.250 --> 00:07:16.340
errors due to other causes are now 1.4
percent when such a higher fraction of

00:07:16.340 --> 00:07:16.350
percent when such a higher fraction of
 

00:07:16.350 --> 00:07:20.730
percent when such a higher fraction of
your mistakes at least as measured on

00:07:20.730 --> 00:07:20.740
your mistakes at least as measured on
 

00:07:20.740 --> 00:07:23.430
your mistakes at least as measured on
your def set are due to incorrect labels

00:07:23.430 --> 00:07:23.440
your def set are due to incorrect labels
 

00:07:23.440 --> 00:07:25.860
your def set are due to incorrect labels
then it maybe seems much more worthwhile

00:07:25.860 --> 00:07:25.870
then it maybe seems much more worthwhile
 

00:07:25.870 --> 00:07:28.980
then it maybe seems much more worthwhile
to fix up the incorrect labels in your

00:07:28.980 --> 00:07:28.990
to fix up the incorrect labels in your
 

00:07:28.990 --> 00:07:32.070
to fix up the incorrect labels in your
depth set and if you remember the goal

00:07:32.070 --> 00:07:32.080
depth set and if you remember the goal
 

00:07:32.080 --> 00:07:33.780
depth set and if you remember the goal
of the death set the main purpose of the

00:07:33.780 --> 00:07:33.790
of the death set the main purpose of the
 

00:07:33.790 --> 00:07:35.940
of the death set the main purpose of the
death set is you want to really use it

00:07:35.940 --> 00:07:35.950
death set is you want to really use it
 

00:07:35.950 --> 00:07:37.200
death set is you want to really use it
to help you select between two

00:07:37.200 --> 00:07:37.210
to help you select between two
 

00:07:37.210 --> 00:07:40.410
to help you select between two
qualifiers a and B so they're trying out

00:07:40.410 --> 00:07:40.420
qualifiers a and B so they're trying out
 

00:07:40.420 --> 00:07:44.670
qualifiers a and B so they're trying out
two confines a and B and one has 2.1

00:07:44.670 --> 00:07:44.680
two confines a and B and one has 2.1
 

00:07:44.680 --> 00:07:47.400
two confines a and B and one has 2.1
percent error and the other has 1.9

00:07:47.400 --> 00:07:47.410
percent error and the other has 1.9
 

00:07:47.410 --> 00:07:49.890
percent error and the other has 1.9
percent error on your death sentence but

00:07:49.890 --> 00:07:49.900
percent error on your death sentence but
 

00:07:49.900 --> 00:07:51.630
percent error on your death sentence but
if you don't trust your deathbed anymore

00:07:51.630 --> 00:07:51.640
if you don't trust your deathbed anymore
 

00:07:51.640 --> 00:07:54.300
if you don't trust your deathbed anymore
to be correctly telling you whether this

00:07:54.300 --> 00:07:54.310
to be correctly telling you whether this
 

00:07:54.310 --> 00:07:56.370
to be correctly telling you whether this
classifier is actually better than this

00:07:56.370 --> 00:07:56.380
classifier is actually better than this
 

00:07:56.380 --> 00:07:58.950
classifier is actually better than this
because you're open 6 percent of these

00:07:58.950 --> 00:07:58.960
because you're open 6 percent of these
 

00:07:58.960 --> 00:08:01.370
because you're open 6 percent of these
mistakes I'll do two incorrect labels

00:08:01.370 --> 00:08:01.380
mistakes I'll do two incorrect labels
 

00:08:01.380 --> 00:08:03.930
mistakes I'll do two incorrect labels
then that's a good reason to go in and

00:08:03.930 --> 00:08:03.940
then that's a good reason to go in and
 

00:08:03.940 --> 00:08:05.760
then that's a good reason to go in and
fix the incorrect labels in your death

00:08:05.760 --> 00:08:05.770
fix the incorrect labels in your death
 

00:08:05.770 --> 00:08:08.610
fix the incorrect labels in your death
set because in this example on the right

00:08:08.610 --> 00:08:08.620
set because in this example on the right
 

00:08:08.620 --> 00:08:10.800
set because in this example on the right
is just having a very large impact on

00:08:10.800 --> 00:08:10.810
is just having a very large impact on
 

00:08:10.810 --> 00:08:12.960
is just having a very large impact on
the overall assessments of the errors of

00:08:12.960 --> 00:08:12.970
the overall assessments of the errors of
 

00:08:12.970 --> 00:08:15.330
the overall assessments of the errors of
the algorithm roasting example the nut

00:08:15.330 --> 00:08:15.340
the algorithm roasting example the nut
 

00:08:15.340 --> 00:08:17.760
the algorithm roasting example the nut
you know the percentage impact is having

00:08:17.760 --> 00:08:17.770
you know the percentage impact is having
 

00:08:17.770 --> 00:08:21.360
you know the percentage impact is having
on your algorithm is still smaller now

00:08:21.360 --> 00:08:21.370
on your algorithm is still smaller now
 

00:08:21.370 --> 00:08:23.730
on your algorithm is still smaller now
if you decide to go into your dev set

00:08:23.730 --> 00:08:23.740
if you decide to go into your dev set
 

00:08:23.740 --> 00:08:26.370
if you decide to go into your dev set
and manually re-examine the labels and

00:08:26.370 --> 00:08:26.380
and manually re-examine the labels and
 

00:08:26.380 --> 00:08:28.470
and manually re-examine the labels and
try to fix up some of the labels here

00:08:28.470 --> 00:08:28.480
try to fix up some of the labels here
 

00:08:28.480 --> 00:08:31.350
try to fix up some of the labels here
are a few additional guidelines or

00:08:31.350 --> 00:08:31.360
are a few additional guidelines or
 

00:08:31.360 --> 00:08:35.310
are a few additional guidelines or
principles to consider first I would

00:08:35.310 --> 00:08:35.320
principles to consider first I would
 

00:08:35.320 --> 00:08:37.650
principles to consider first I would
encourage you to apply whatever process

00:08:37.650 --> 00:08:37.660
encourage you to apply whatever process
 

00:08:37.660 --> 00:08:39.780
encourage you to apply whatever process
you apply to both your depth and test

00:08:39.780 --> 00:08:39.790
you apply to both your depth and test
 

00:08:39.790 --> 00:08:42.060
you apply to both your depth and test
set at the same time we talked

00:08:42.060 --> 00:08:42.070
set at the same time we talked
 

00:08:42.070 --> 00:08:44.460
set at the same time we talked
previously about why you want your depth

00:08:44.460 --> 00:08:44.470
previously about why you want your depth
 

00:08:44.470 --> 00:08:45.160
previously about why you want your depth
intense

00:08:45.160 --> 00:08:45.170
intense
 

00:08:45.170 --> 00:08:47.259
intense
as the conferencing distribution the DEF

00:08:47.259 --> 00:08:47.269
as the conferencing distribution the DEF
 

00:08:47.269 --> 00:08:49.210
as the conferencing distribution the DEF
set is sort of telling you where to aim

00:08:49.210 --> 00:08:49.220
set is sort of telling you where to aim
 

00:08:49.220 --> 00:08:51.460
set is sort of telling you where to aim
target and when you hit it you want that

00:08:51.460 --> 00:08:51.470
target and when you hit it you want that
 

00:08:51.470 --> 00:08:54.129
target and when you hit it you want that
to generalize to the test set so your

00:08:54.129 --> 00:08:54.139
to generalize to the test set so your
 

00:08:54.139 --> 00:08:56.259
to generalize to the test set so your
team really works more efficiently the

00:08:56.259 --> 00:08:56.269
team really works more efficiently the
 

00:08:56.269 --> 00:08:57.910
team really works more efficiently the
debit test sets come from the same

00:08:57.910 --> 00:08:57.920
debit test sets come from the same
 

00:08:57.920 --> 00:09:00.400
debit test sets come from the same
distribution so if you're going in to

00:09:00.400 --> 00:09:00.410
distribution so if you're going in to
 

00:09:00.410 --> 00:09:02.170
distribution so if you're going in to
fix up your dev sets I would apply the

00:09:02.170 --> 00:09:02.180
fix up your dev sets I would apply the
 

00:09:02.180 --> 00:09:04.210
fix up your dev sets I would apply the
same process the test set to make sure

00:09:04.210 --> 00:09:04.220
same process the test set to make sure
 

00:09:04.220 --> 00:09:06.370
same process the test set to make sure
that they continue to come from the same

00:09:06.370 --> 00:09:06.380
that they continue to come from the same
 

00:09:06.380 --> 00:09:08.259
that they continue to come from the same
distribution so if you hire someone to

00:09:08.259 --> 00:09:08.269
distribution so if you hire someone to
 

00:09:08.269 --> 00:09:10.840
distribution so if you hire someone to
examine your labels will carefully do

00:09:10.840 --> 00:09:10.850
examine your labels will carefully do
 

00:09:10.850 --> 00:09:12.550
examine your labels will carefully do
that for both your dev and test sets

00:09:12.550 --> 00:09:12.560
that for both your dev and test sets
 

00:09:12.560 --> 00:09:15.329
that for both your dev and test sets
second I would urge you to consider

00:09:15.329 --> 00:09:15.339
second I would urge you to consider
 

00:09:15.339 --> 00:09:18.100
second I would urge you to consider
examining examples your algorithm got

00:09:18.100 --> 00:09:18.110
examining examples your algorithm got
 

00:09:18.110 --> 00:09:21.189
examining examples your algorithm got
right as was once it got wrong it is

00:09:21.189 --> 00:09:21.199
right as was once it got wrong it is
 

00:09:21.199 --> 00:09:23.710
right as was once it got wrong it is
easy to look at the examples your album

00:09:23.710 --> 00:09:23.720
easy to look at the examples your album
 

00:09:23.720 --> 00:09:25.540
easy to look at the examples your album
got wrong and just see if any of those

00:09:25.540 --> 00:09:25.550
got wrong and just see if any of those
 

00:09:25.550 --> 00:09:28.090
got wrong and just see if any of those
need to be fixed but it's possible that

00:09:28.090 --> 00:09:28.100
need to be fixed but it's possible that
 

00:09:28.100 --> 00:09:29.740
need to be fixed but it's possible that
there are some examples that you haven't

00:09:29.740 --> 00:09:29.750
there are some examples that you haven't
 

00:09:29.750 --> 00:09:31.960
there are some examples that you haven't
got right that should also be fixed and

00:09:31.960 --> 00:09:31.970
got right that should also be fixed and
 

00:09:31.970 --> 00:09:34.120
got right that should also be fixed and
the only fixed ones that your albums got

00:09:34.120 --> 00:09:34.130
the only fixed ones that your albums got
 

00:09:34.130 --> 00:09:36.699
the only fixed ones that your albums got
wrongly end up with a more bias estimate

00:09:36.699 --> 00:09:36.709
wrongly end up with a more bias estimate
 

00:09:36.709 --> 00:09:39.670
wrongly end up with a more bias estimate
of the error of your algorithm it kind

00:09:39.670 --> 00:09:39.680
of the error of your algorithm it kind
 

00:09:39.680 --> 00:09:41.259
of the error of your algorithm it kind
of gives you albumin a little bit of an

00:09:41.259 --> 00:09:41.269
of gives you albumin a little bit of an
 

00:09:41.269 --> 00:09:43.030
of gives you albumin a little bit of an
unfair advantage if you just try to

00:09:43.030 --> 00:09:43.040
unfair advantage if you just try to
 

00:09:43.040 --> 00:09:45.850
unfair advantage if you just try to
double-check what it got wrong but you

00:09:45.850 --> 00:09:45.860
double-check what it got wrong but you
 

00:09:45.860 --> 00:09:47.620
double-check what it got wrong but you
don't also double-check what it got

00:09:47.620 --> 00:09:47.630
don't also double-check what it got
 

00:09:47.630 --> 00:09:49.780
don't also double-check what it got
right because it might have gotten

00:09:49.780 --> 00:09:49.790
right because it might have gotten
 

00:09:49.790 --> 00:09:51.910
right because it might have gotten
something right that it was you know

00:09:51.910 --> 00:09:51.920
something right that it was you know
 

00:09:51.920 --> 00:09:54.370
something right that it was you know
just lucky on and fixing the label would

00:09:54.370 --> 00:09:54.380
just lucky on and fixing the label would
 

00:09:54.380 --> 00:09:56.889
just lucky on and fixing the label would
cause it to go from being right to be

00:09:56.889 --> 00:09:56.899
cause it to go from being right to be
 

00:09:56.899 --> 00:10:00.340
cause it to go from being right to be
wrong on that example the second bullet

00:10:00.340 --> 00:10:00.350
wrong on that example the second bullet
 

00:10:00.350 --> 00:10:02.350
wrong on that example the second bullet
isn't always easy to do so it's not

00:10:02.350 --> 00:10:02.360
isn't always easy to do so it's not
 

00:10:02.360 --> 00:10:04.689
isn't always easy to do so it's not
always done the reason it's not always

00:10:04.689 --> 00:10:04.699
always done the reason it's not always
 

00:10:04.699 --> 00:10:07.150
always done the reason it's not always
done is because if you classify as very

00:10:07.150 --> 00:10:07.160
done is because if you classify as very
 

00:10:07.160 --> 00:10:09.790
done is because if you classify as very
accurate then it's getting a lot fewer

00:10:09.790 --> 00:10:09.800
accurate then it's getting a lot fewer
 

00:10:09.800 --> 00:10:12.280
accurate then it's getting a lot fewer
things wrong then right so if your

00:10:12.280 --> 00:10:12.290
things wrong then right so if your
 

00:10:12.290 --> 00:10:15.400
things wrong then right so if your
classifier has your 98% accuracy then

00:10:15.400 --> 00:10:15.410
classifier has your 98% accuracy then
 

00:10:15.410 --> 00:10:17.620
classifier has your 98% accuracy then
it's getting two percent of things wrong

00:10:17.620 --> 00:10:17.630
it's getting two percent of things wrong
 

00:10:17.630 --> 00:10:19.930
it's getting two percent of things wrong
and 98 percent of things right so it's

00:10:19.930 --> 00:10:19.940
and 98 percent of things right so it's
 

00:10:19.940 --> 00:10:22.480
and 98 percent of things right so it's
much easier to examine and very

00:10:22.480 --> 00:10:22.490
much easier to examine and very
 

00:10:22.490 --> 00:10:25.120
much easier to examine and very
validating labels on 250 good data and

00:10:25.120 --> 00:10:25.130
validating labels on 250 good data and
 

00:10:25.130 --> 00:10:27.850
validating labels on 250 good data and
it takes much longer to validate the

00:10:27.850 --> 00:10:27.860
it takes much longer to validate the
 

00:10:27.860 --> 00:10:31.059
it takes much longer to validate the
labels on 98 percent data so this isn't

00:10:31.059 --> 00:10:31.069
labels on 98 percent data so this isn't
 

00:10:31.069 --> 00:10:32.650
labels on 98 percent data so this isn't
always done but it's just something to

00:10:32.650 --> 00:10:32.660
always done but it's just something to
 

00:10:32.660 --> 00:10:37.569
always done but it's just something to
consider finally if you go into your DEP

00:10:37.569 --> 00:10:37.579
consider finally if you go into your DEP
 

00:10:37.579 --> 00:10:40.360
consider finally if you go into your DEP
and test data to correct on the label

00:10:40.360 --> 00:10:40.370
and test data to correct on the label
 

00:10:40.370 --> 00:10:41.560
and test data to correct on the label
there

00:10:41.560 --> 00:10:41.570
there
 

00:10:41.570 --> 00:10:43.540
there
you may or may not decide to go and

00:10:43.540 --> 00:10:43.550
you may or may not decide to go and
 

00:10:43.550 --> 00:10:45.400
you may or may not decide to go and
apply the same process for the training

00:10:45.400 --> 00:10:45.410
apply the same process for the training
 

00:10:45.410 --> 00:10:47.740
apply the same process for the training
set remember we said that the size this

00:10:47.740 --> 00:10:47.750
set remember we said that the size this
 

00:10:47.750 --> 00:10:49.570
set remember we said that the size this
video there's actually less important to

00:10:49.570 --> 00:10:49.580
video there's actually less important to
 

00:10:49.580 --> 00:10:51.220
video there's actually less important to
correct on tables in your training set

00:10:51.220 --> 00:10:51.230
correct on tables in your training set
 

00:10:51.230 --> 00:10:53.500
correct on tables in your training set
and it's quite possible you decide to

00:10:53.500 --> 00:10:53.510
and it's quite possible you decide to
 

00:10:53.510 --> 00:10:55.300
and it's quite possible you decide to
just correct the labels in your Devon

00:10:55.300 --> 00:10:55.310
just correct the labels in your Devon
 

00:10:55.310 --> 00:10:58.000
just correct the labels in your Devon
test set which are also often smaller

00:10:58.000 --> 00:10:58.010
test set which are also often smaller
 

00:10:58.010 --> 00:11:00.190
test set which are also often smaller
than the training set and you might not

00:11:00.190 --> 00:11:00.200
than the training set and you might not
 

00:11:00.200 --> 00:11:02.230
than the training set and you might not
invest all that extra effort needed to

00:11:02.230 --> 00:11:02.240
invest all that extra effort needed to
 

00:11:02.240 --> 00:11:04.270
invest all that extra effort needed to
correct the labels in a much larger

00:11:04.270 --> 00:11:04.280
correct the labels in a much larger
 

00:11:04.280 --> 00:11:07.390
correct the labels in a much larger
training set this is actually okay and

00:11:07.390 --> 00:11:07.400
training set this is actually okay and
 

00:11:07.400 --> 00:11:10.420
training set this is actually okay and
we'll talk later this week about some

00:11:10.420 --> 00:11:10.430
we'll talk later this week about some
 

00:11:10.430 --> 00:11:12.970
we'll talk later this week about some
processes for handling when your

00:11:12.970 --> 00:11:12.980
processes for handling when your
 

00:11:12.980 --> 00:11:14.650
processes for handling when your
training data is different and

00:11:14.650 --> 00:11:14.660
training data is different and
 

00:11:14.660 --> 00:11:16.360
training data is different and
distribution than your depth and test

00:11:16.360 --> 00:11:16.370
distribution than your depth and test
 

00:11:16.370 --> 00:11:18.940
distribution than your depth and test
data learning algorithms are quite

00:11:18.940 --> 00:11:18.950
data learning algorithms are quite
 

00:11:18.950 --> 00:11:21.310
data learning algorithms are quite
robust student it's super important that

00:11:21.310 --> 00:11:21.320
robust student it's super important that
 

00:11:21.320 --> 00:11:23.500
robust student it's super important that
your Deb in test sets come from the same

00:11:23.500 --> 00:11:23.510
your Deb in test sets come from the same
 

00:11:23.510 --> 00:11:26.650
your Deb in test sets come from the same
distribution but if your training set

00:11:26.650 --> 00:11:26.660
distribution but if your training set
 

00:11:26.660 --> 00:11:27.490
distribution but if your training set
comes to a slightly different

00:11:27.490 --> 00:11:27.500
comes to a slightly different
 

00:11:27.500 --> 00:11:29.830
comes to a slightly different
distribution often that's a pretty

00:11:29.830 --> 00:11:29.840
distribution often that's a pretty
 

00:11:29.840 --> 00:11:31.540
distribution often that's a pretty
reasonable thing to do and we'll talk

00:11:31.540 --> 00:11:31.550
reasonable thing to do and we'll talk
 

00:11:31.550 --> 00:11:33.280
reasonable thing to do and we'll talk
more about how to handle this later this

00:11:33.280 --> 00:11:33.290
more about how to handle this later this
 

00:11:33.290 --> 00:11:36.250
more about how to handle this later this
week so I'd like to wrap up with just a

00:11:36.250 --> 00:11:36.260
week so I'd like to wrap up with just a
 

00:11:36.260 --> 00:11:38.710
week so I'd like to wrap up with just a
couple pieces of advice first these

00:11:38.710 --> 00:11:38.720
couple pieces of advice first these
 

00:11:38.720 --> 00:11:40.360
couple pieces of advice first these
learning researchers sometimes like to

00:11:40.360 --> 00:11:40.370
learning researchers sometimes like to
 

00:11:40.370 --> 00:11:42.520
learning researchers sometimes like to
say things like oh I just said the data

00:11:42.520 --> 00:11:42.530
say things like oh I just said the data
 

00:11:42.530 --> 00:11:44.050
say things like oh I just said the data
the algorithm and I trained in and it

00:11:44.050 --> 00:11:44.060
the algorithm and I trained in and it
 

00:11:44.060 --> 00:11:45.850
the algorithm and I trained in and it
worked and you know there is a lot of

00:11:45.850 --> 00:11:45.860
worked and you know there is a lot of
 

00:11:45.860 --> 00:11:47.560
worked and you know there is a lot of
truth to that in the deep learning error

00:11:47.560 --> 00:11:47.570
truth to that in the deep learning error
 

00:11:47.570 --> 00:11:49.900
truth to that in the deep learning error
there is more feeding data to an

00:11:49.900 --> 00:11:49.910
there is more feeding data to an
 

00:11:49.910 --> 00:11:51.250
there is more feeding data to an
algorithm than just training it and

00:11:51.250 --> 00:11:51.260
algorithm than just training it and
 

00:11:51.260 --> 00:11:53.620
algorithm than just training it and
doing less hand engineering using less

00:11:53.620 --> 00:11:53.630
doing less hand engineering using less
 

00:11:53.630 --> 00:11:56.050
doing less hand engineering using less
human insight but I think that in

00:11:56.050 --> 00:11:56.060
human insight but I think that in
 

00:11:56.060 --> 00:11:58.270
human insight but I think that in
building practical systems often there's

00:11:58.270 --> 00:11:58.280
building practical systems often there's
 

00:11:58.280 --> 00:12:01.300
building practical systems often there's
also more manual analysis and more human

00:12:01.300 --> 00:12:01.310
also more manual analysis and more human
 

00:12:01.310 --> 00:12:03.670
also more manual analysis and more human
insight that goes into these systems and

00:12:03.670 --> 00:12:03.680
insight that goes into these systems and
 

00:12:03.680 --> 00:12:05.710
insight that goes into these systems and
sometimes deep learning researchers like

00:12:05.710 --> 00:12:05.720
sometimes deep learning researchers like
 

00:12:05.720 --> 00:12:08.980
sometimes deep learning researchers like
to acknowledge second is that somehow

00:12:08.980 --> 00:12:08.990
to acknowledge second is that somehow
 

00:12:08.990 --> 00:12:10.720
to acknowledge second is that somehow
I've seen some engineers and researchers

00:12:10.720 --> 00:12:10.730
I've seen some engineers and researchers
 

00:12:10.730 --> 00:12:13.420
I've seen some engineers and researchers
be reluctant to manually look at

00:12:13.420 --> 00:12:13.430
be reluctant to manually look at
 

00:12:13.430 --> 00:12:15.370
be reluctant to manually look at
examples maybe is not the most

00:12:15.370 --> 00:12:15.380
examples maybe is not the most
 

00:12:15.380 --> 00:12:17.290
examples maybe is not the most
interesting thing to do to sit down and

00:12:17.290 --> 00:12:17.300
interesting thing to do to sit down and
 

00:12:17.300 --> 00:12:19.120
interesting thing to do to sit down and
look at 100 or couple hundred examples

00:12:19.120 --> 00:12:19.130
look at 100 or couple hundred examples
 

00:12:19.130 --> 00:12:22.150
look at 100 or couple hundred examples
to counter the number of errors but this

00:12:22.150 --> 00:12:22.160
to counter the number of errors but this
 

00:12:22.160 --> 00:12:23.980
to counter the number of errors but this
is something that I still do myself when

00:12:23.980 --> 00:12:23.990
is something that I still do myself when
 

00:12:23.990 --> 00:12:25.420
is something that I still do myself when
I'm reading machine learning to you and

00:12:25.420 --> 00:12:25.430
I'm reading machine learning to you and
 

00:12:25.430 --> 00:12:26.740
I'm reading machine learning to you and
I want to understand what mistakes is

00:12:26.740 --> 00:12:26.750
I want to understand what mistakes is
 

00:12:26.750 --> 00:12:28.450
I want to understand what mistakes is
making I will actually go in and look at

00:12:28.450 --> 00:12:28.460
making I will actually go in and look at
 

00:12:28.460 --> 00:12:30.550
making I will actually go in and look at
the data myself and try to counter the

00:12:30.550 --> 00:12:30.560
the data myself and try to counter the
 

00:12:30.560 --> 00:12:32.500
the data myself and try to counter the
fraction of errors and I think that

00:12:32.500 --> 00:12:32.510
fraction of errors and I think that
 

00:12:32.510 --> 00:12:34.720
fraction of errors and I think that
because these you know minutes or maybe

00:12:34.720 --> 00:12:34.730
because these you know minutes or maybe
 

00:12:34.730 --> 00:12:36.790
because these you know minutes or maybe
a small number of hours of counting data

00:12:36.790 --> 00:12:36.800
a small number of hours of counting data
 

00:12:36.800 --> 00:12:39.160
a small number of hours of counting data
can really help you prioritize where to

00:12:39.160 --> 00:12:39.170
can really help you prioritize where to
 

00:12:39.170 --> 00:12:41.440
can really help you prioritize where to
go next I find this a very good use of

00:12:41.440 --> 00:12:41.450
go next I find this a very good use of
 

00:12:41.450 --> 00:12:43.240
go next I find this a very good use of
your time that urge you to consider

00:12:43.240 --> 00:12:43.250
your time that urge you to consider
 

00:12:43.250 --> 00:12:45.550
your time that urge you to consider
doing it if you go to machine learning

00:12:45.550 --> 00:12:45.560
doing it if you go to machine learning
 

00:12:45.560 --> 00:12:47.620
doing it if you go to machine learning
system and you're trying to decide what

00:12:47.620 --> 00:12:47.630
system and you're trying to decide what
 

00:12:47.630 --> 00:12:50.440
system and you're trying to decide what
ideas or what directions to prioritize

00:12:50.440 --> 00:12:50.450
ideas or what directions to prioritize
 

00:12:50.450 --> 00:12:51.370
ideas or what directions to prioritize
things

00:12:51.370 --> 00:12:51.380
things
 

00:12:51.380 --> 00:12:54.580
things
so um that's it for the error analysis

00:12:54.580 --> 00:12:54.590
so um that's it for the error analysis
 

00:12:54.590 --> 00:12:56.800
so um that's it for the error analysis
process in the next video I want to

00:12:56.800 --> 00:12:56.810
process in the next video I want to
 

00:12:56.810 --> 00:12:59.080
process in the next video I want to
share view some thoughts on how error

00:12:59.080 --> 00:12:59.090
share view some thoughts on how error
 

00:12:59.090 --> 00:13:01.570
share view some thoughts on how error
analysis fits into how you might go

00:13:01.570 --> 00:13:01.580
analysis fits into how you might go
 

00:13:01.580 --> 00:13:03.730
analysis fits into how you might go
about starting out on a new machine

00:13:03.730 --> 00:13:03.740
about starting out on a new machine
 

00:13:03.740 --> 00:13:06.550
about starting out on a new machine
learning project

