WEBVTT
Kind: captions
Language: en

00:00:00.255 --> 00:00:03.640
CHRISTIAN KURZKE: Welcome,
everyone, to our session.

00:00:03.640 --> 00:00:06.040
So if some people are coming
in, I know I'm

00:00:06.040 --> 00:00:07.270
competing with lunch.

00:00:07.270 --> 00:00:11.310
So I really appreciate you guys
made it away from lunch

00:00:11.310 --> 00:00:13.070
early and join us here.

00:00:13.070 --> 00:00:15.630
We are going to talk today
about how to get

00:00:15.630 --> 00:00:17.530
content to Google TV.

00:00:17.530 --> 00:00:20.060
And if you guys have been here
in the earlier Google TV

00:00:20.060 --> 00:00:22.870
session, you know that there
is nothing that people love

00:00:22.870 --> 00:00:24.940
more than getting content
on their television.

00:00:24.940 --> 00:00:27.150
So I'm really excited
you guys are here.

00:00:27.150 --> 00:00:30.530
And let's just say you have
a big audience for your

00:00:30.530 --> 00:00:31.450
applications.

00:00:31.450 --> 00:00:33.830
So that's really good.

00:00:33.830 --> 00:00:35.590
Let me introduce myself.

00:00:35.590 --> 00:00:36.600
I'm Christian Kurzke.

00:00:36.600 --> 00:00:40.440
I'm a developer advocate with
the Google TV team.

00:00:40.440 --> 00:00:43.711
And with me today
we have Andrew.

00:00:43.711 --> 00:00:46.170
ANDREW JEON: Hi, my name
is Andrew Jeon.

00:00:46.170 --> 00:00:50.120
I'm a platform engineering
manager at Google TV team

00:00:50.120 --> 00:00:54.012
covering AB and general
platform features.

00:00:54.012 --> 00:00:55.780
CHRISTIAN KURZKE: And Mark.

00:00:55.780 --> 00:00:56.680
MARK LINDNER: I'm
Mark Lindner.

00:00:56.680 --> 00:00:59.970
I'm a tech lead on Google TV's
core applications and

00:00:59.970 --> 00:01:00.772
frameworks.

00:01:00.772 --> 00:01:01.480
CHRISTIAN KURZKE: Great.

00:01:01.480 --> 00:01:04.040
So those are the guys who
actually make the magic happen

00:01:04.040 --> 00:01:07.200
on the platform,
so really cool.

00:01:07.200 --> 00:01:12.140
So hopefully by now, you've all
seen the new devices, the

00:01:12.140 --> 00:01:14.000
new Google TV devices.

00:01:14.000 --> 00:01:17.890
So if you haven't, go check them
out in our sandbox right

00:01:17.890 --> 00:01:20.070
out in the second floor here.

00:01:20.070 --> 00:01:21.530
I just want to highlight
a few things.

00:01:21.530 --> 00:01:25.670
So this is the new-generation
devices from Sony, from Visio,

00:01:25.670 --> 00:01:27.300
and from LG.

00:01:27.300 --> 00:01:31.250
What they all have in common,
they are ARM-based devices.

00:01:31.250 --> 00:01:33.570
And I'm really excited.

00:01:33.570 --> 00:01:36.880
I know a lot of people outside
of the US have been asking us

00:01:36.880 --> 00:01:38.740
the last year when can they
finally get their

00:01:38.740 --> 00:01:40.590
hands on a Google TV.

00:01:40.590 --> 00:01:42.930
And those, or at least some
of them, will be available

00:01:42.930 --> 00:01:43.870
internationally.

00:01:43.870 --> 00:01:47.350
So Sony has announced they're
going international.

00:01:47.350 --> 00:01:51.350
So keep in mind, when we talk
about Google TV devices, we'll

00:01:51.350 --> 00:01:53.110
focus on all of those devices.

00:01:53.110 --> 00:01:57.010
And basically, the features that
we talk about today, they

00:01:57.010 --> 00:02:00.410
are mostly available on
international or on the

00:02:00.410 --> 00:02:02.520
ARM-based devices, and
also international.

00:02:05.350 --> 00:02:09.600
So what I want you to keep in
mind is how people interact

00:02:09.600 --> 00:02:10.320
with television.

00:02:10.320 --> 00:02:13.450
And we talk a lot about content
in this session.

00:02:13.450 --> 00:02:16.940
And it's really streaming
entertainment, streaming

00:02:16.940 --> 00:02:19.030
movies, videos.

00:02:19.030 --> 00:02:22.490
It's really the big thing
in the living room.

00:02:22.490 --> 00:02:25.080
People like to be entertained
while they're on the bus,

00:02:25.080 --> 00:02:27.830
maybe on their cell phone, but
they definitely love their

00:02:27.830 --> 00:02:30.590
content on television at home.

00:02:30.590 --> 00:02:35.610
There was also another session
earlier today by Osama, and he

00:02:35.610 --> 00:02:37.320
was talking about
how to create a

00:02:37.320 --> 00:02:38.920
beautiful user interface.

00:02:38.920 --> 00:02:40.580
Of course, you need that, too.

00:02:40.580 --> 00:02:43.850
And then we'll have Paul talk
about second screen.

00:02:43.850 --> 00:02:46.520
But the centerpiece in the
living room is really content.

00:02:46.520 --> 00:02:49.890
It's all about content,
content, content.

00:02:49.890 --> 00:02:53.170
So what I'm going to cover or
what we are all going to cover

00:02:53.170 --> 00:02:56.850
in this session is how do you
create beautiful content

00:02:56.850 --> 00:02:58.910
applications for Google TV?

00:02:58.910 --> 00:03:01.310
Some of the key features
for this is you

00:03:01.310 --> 00:03:04.010
want streaming content.

00:03:04.010 --> 00:03:07.370
Usually people, they want
their content on their

00:03:07.370 --> 00:03:07.960
fingertips.

00:03:07.960 --> 00:03:08.730
They want it now.

00:03:08.730 --> 00:03:12.040
They want access to a huge
library of content.

00:03:12.040 --> 00:03:16.230
How can you ensure that they get
the best quality possible?

00:03:16.230 --> 00:03:19.660
How can you do it securely so
that you as a content owner

00:03:19.660 --> 00:03:23.610
feel secure that content doesn't
fall into bad hands?

00:03:23.610 --> 00:03:25.970
And how can you create a
beautiful, integrated

00:03:25.970 --> 00:03:28.910
experience for your viewers?

00:03:28.910 --> 00:03:33.300
So let's get started and take
a look at streaming.

00:03:33.300 --> 00:03:36.600
So what is streaming
really all about?

00:03:36.600 --> 00:03:38.890
And I'm sure you guys
are all developers.

00:03:38.890 --> 00:03:39.790
You've written code.

00:03:39.790 --> 00:03:41.490
You know what streaming is.

00:03:41.490 --> 00:03:45.820
A lot of people, basically when
you do music streaming,

00:03:45.820 --> 00:03:48.410
you just take an MP3
URL, you have--

00:03:48.410 --> 00:03:49.520
[COUGH]

00:03:49.520 --> 00:03:50.770
CHRISTIAN KURZKE: Oops.

00:03:54.650 --> 00:03:56.020
That's all right.

00:03:56.020 --> 00:03:57.762
We'll keep you muted a little.

00:03:57.762 --> 00:04:02.300
So the HTTP streaming of
music, it's not really

00:04:02.300 --> 00:04:04.810
streaming in the
sense as video.

00:04:04.810 --> 00:04:07.180
And for music, it's actually
simple because you can just

00:04:07.180 --> 00:04:09.560
download and playback
at the same time.

00:04:09.560 --> 00:04:12.210
You basically have enough
bandwidth on all devices

00:04:12.210 --> 00:04:17.899
nowadays to just stream perfect
high-quality music.

00:04:17.899 --> 00:04:19.920
For video, it's still
the bandwidth.

00:04:19.920 --> 00:04:23.740
We're still in an age where we
don't have gigabits to every

00:04:23.740 --> 00:04:27.770
house, although I've heard
people are working on that.

00:04:27.770 --> 00:04:32.120
But what we really look for in
streaming video is how can we

00:04:32.120 --> 00:04:35.720
optimize the bandwidth that
your viewers or your users

00:04:35.720 --> 00:04:39.250
have to get the best
possible content?

00:04:39.250 --> 00:04:43.200
And so this is just a snapshot
from one of my lab tools.

00:04:43.200 --> 00:04:46.280
But it shows basically when
you play back video, you

00:04:46.280 --> 00:04:50.130
always get bursts of high
bandwidth, and you basically

00:04:50.130 --> 00:04:51.500
load, you buffer.

00:04:51.500 --> 00:04:54.180
And in this particular scenario,
we don't really

00:04:54.180 --> 00:04:56.010
utilize the bandwidth fully.

00:04:56.010 --> 00:04:59.460
Because what happens is there
is a lot of times when we

00:04:59.460 --> 00:05:02.220
don't download any data that
we actually could, so we're

00:05:02.220 --> 00:05:04.880
not really getting
the best possible

00:05:04.880 --> 00:05:07.970
experience to the viewer.

00:05:07.970 --> 00:05:12.700
And so if you have too low of
a bandwidth, you're leaving

00:05:12.700 --> 00:05:14.260
quality on the table.

00:05:14.260 --> 00:05:17.180
On the other hand, if you have a
higher bandwidth or a higher

00:05:17.180 --> 00:05:20.490
bit rate encoding than your
viewers have access to on

00:05:20.490 --> 00:05:23.690
their home network connection,
then you're actually getting

00:05:23.690 --> 00:05:25.630
this whole reloading,
re-buffering.

00:05:25.630 --> 00:05:28.280
And let me tell you, people
hate nothing more in their

00:05:28.280 --> 00:05:31.540
living room than looking at a
spinning reloading, reloading

00:05:31.540 --> 00:05:33.180
in the middle of a movie.

00:05:33.180 --> 00:05:39.130
So we want to make sure you
can do better than that.

00:05:39.130 --> 00:05:42.060
The other thing that I want to
put out there is a lot of

00:05:42.060 --> 00:05:44.100
people have heard about
variable bit rate.

00:05:44.100 --> 00:05:45.840
And they're like, oh, yeah,
that's the solution.

00:05:45.840 --> 00:05:47.990
We need variable bit rate.

00:05:47.990 --> 00:05:50.910
Variable bit rate is OK.

00:05:50.910 --> 00:05:56.130
It gives you the best possible
perceived encoding for your

00:05:56.130 --> 00:05:59.970
video stream, but it's actually
still one stream.

00:05:59.970 --> 00:06:02.970
After you're done encoding
variable bit rate stream, you

00:06:02.970 --> 00:06:06.150
end up with one stream with
an average bit rate of--

00:06:06.150 --> 00:06:06.880
pick one--

00:06:06.880 --> 00:06:09.940
3 megabits, 5 megabits,
7 megabits.

00:06:09.940 --> 00:06:14.320
But this is not adaptive at run
time to the network needs

00:06:14.320 --> 00:06:18.190
that your viewers or
your users have.

00:06:18.190 --> 00:06:23.170
So in an ideal world, if we
had all the computing

00:06:23.170 --> 00:06:26.750
resources in the world, we could
encode a stream on the

00:06:26.750 --> 00:06:28.970
fly for each network
connection.

00:06:28.970 --> 00:06:31.880
The challenge then is the
network speed also changes.

00:06:31.880 --> 00:06:36.050
If you watch a two-hour movie
and maybe your kids in the

00:06:36.050 --> 00:06:38.740
back play a game or maybe your
neighbor turns on the

00:06:38.740 --> 00:06:42.250
microwave and jams your Wi-Fi
signal, so your bandwidth

00:06:42.250 --> 00:06:45.060
might fluctuate, even throughout
the movie.

00:06:45.060 --> 00:06:48.980
So what you need to do is you
need to be able to actually

00:06:48.980 --> 00:06:52.950
dynamically adapt to the
bandwidth that is available to

00:06:52.950 --> 00:06:55.770
you while you play back.

00:06:55.770 --> 00:06:58.440
So how can we do that?

00:06:58.440 --> 00:07:02.510
The key word for this is
"adaptive bit rate streaming."

00:07:02.510 --> 00:07:05.830
And it's not just variable, but
it's actually adaptive.

00:07:05.830 --> 00:07:10.320
That means we are actually
monitoring the playback

00:07:10.320 --> 00:07:13.440
bandwidth as we play back
the movie, and we adjust

00:07:13.440 --> 00:07:15.260
accordingly.

00:07:15.260 --> 00:07:16.910
So how do we do this
technically?

00:07:16.910 --> 00:07:20.520
We don't encode the video for
each one of the viewers, for

00:07:20.520 --> 00:07:24.120
each one of you, because that
would be a lot of encoding.

00:07:24.120 --> 00:07:27.520
So usually we have a set
of pre-recorded,

00:07:27.520 --> 00:07:29.440
pre-encoded bit rates.

00:07:29.440 --> 00:07:32.910
So we have a low bit rate, a
medium bit rate, somewhere

00:07:32.910 --> 00:07:36.730
between 5 or 10 different
quality streams.

00:07:36.730 --> 00:07:39.540
And then we have an XML
descriptor, which

00:07:39.540 --> 00:07:40.730
describes all this.

00:07:40.730 --> 00:07:43.840
And then in the playback, you
basically point to the XML

00:07:43.840 --> 00:07:44.970
descriptor.

00:07:44.970 --> 00:07:48.860
The playback stack knows that
if the bit rate that is

00:07:48.860 --> 00:07:52.320
currently playing, there is
potential that we could go

00:07:52.320 --> 00:07:54.890
higher, then it switches to
the higher quality stream.

00:07:54.890 --> 00:07:57.830
If it notices the buffer is
getting shorter and shorter,

00:07:57.830 --> 00:08:01.040
it temporarily can switch to
a lower quality stream.

00:08:01.040 --> 00:08:04.860
On the end, your users and your
viewers on the screen see

00:08:04.860 --> 00:08:08.540
the best possible content that
they can with their given

00:08:08.540 --> 00:08:10.420
network connection.

00:08:10.420 --> 00:08:11.290
There's nothing we can do.

00:08:11.290 --> 00:08:13.490
If they have a 2-megabit network
connection in their

00:08:13.490 --> 00:08:16.988
home, they will see
2-megabit quality.

00:08:16.988 --> 00:08:21.980
But I'll talk to you later how
you can actually at least

00:08:21.980 --> 00:08:24.250
detect this on your end.

00:08:24.250 --> 00:08:26.670
So there is various standards
for this.

00:08:26.670 --> 00:08:28.230
So I didn't invent this.

00:08:28.230 --> 00:08:30.670
We didn't invent this.

00:08:30.670 --> 00:08:32.350
People have been doing this.

00:08:32.350 --> 00:08:35.409
There is HTTP Live
Streaming, HLS.

00:08:35.409 --> 00:08:36.640
There is MPEG-DASH.

00:08:36.640 --> 00:08:38.580
There is smooth streaming.

00:08:38.580 --> 00:08:40.570
And believe it or not,
there's a lot more.

00:08:40.570 --> 00:08:43.510
Because this is cutting edge
stuff, and it's really pushing

00:08:43.510 --> 00:08:44.570
the boundaries.

00:08:44.570 --> 00:08:48.410
And companies who do this for a
living, they all believe or

00:08:48.410 --> 00:08:50.930
know that they have the best
possible solution for this.

00:08:50.930 --> 00:08:53.490
So they all tweak the standard
just a little bit and push it

00:08:53.490 --> 00:08:55.140
a little bit one
way or another.

00:08:55.140 --> 00:08:58.230
So we'll talk about that, too.

00:08:58.230 --> 00:09:04.520
So in Google TV, what you can do
is our playback stack, our

00:09:04.520 --> 00:09:08.470
media player, it actually
supports playback of adaptive

00:09:08.470 --> 00:09:13.210
bit rate streams currently in
HTTP Live Streaming format.

00:09:13.210 --> 00:09:17.300
So if you, for example, in your
code, you just use Media

00:09:17.300 --> 00:09:21.590
Player and you set the data
source to be an m3u8 file,

00:09:21.590 --> 00:09:25.830
which is the XML descriptor that
I explained, then we will

00:09:25.830 --> 00:09:28.350
play back an adaptive
bit rate stream.

00:09:28.350 --> 00:09:30.050
We also support LiveLine.

00:09:30.050 --> 00:09:32.930
So that's basically
out in Google TV.

00:09:32.930 --> 00:09:36.610
If you have one of our boxes
today, you can do this.

00:09:36.610 --> 00:09:39.710
And now I actually want to hand
over to Andrew, and he

00:09:39.710 --> 00:09:41.940
can tell us a little bit more
about what the engineers have

00:09:41.940 --> 00:09:43.455
been up to recently.

00:09:43.455 --> 00:09:45.160
ANDREW JEON: Thanks,
Christian.

00:09:45.160 --> 00:09:48.950
So as Christian mentioned,
Android, as teamwork, has been

00:09:48.950 --> 00:09:52.530
supporting HLS and wide-band
media format.

00:09:52.530 --> 00:09:57.560
But as Christian mentioned,
various techniques have been

00:09:57.560 --> 00:09:59.680
introduced by multiple
companies.

00:09:59.680 --> 00:10:03.060
From the beginning, HLS by
Apple, Apple did a beautiful

00:10:03.060 --> 00:10:05.910
job of coming up
with this idea.

00:10:05.910 --> 00:10:09.430
And then later on, Microsoft
realized that

00:10:09.430 --> 00:10:12.330
that has lots of issues.

00:10:12.330 --> 00:10:15.080
So they extended the protocol
and then came up with

00:10:15.080 --> 00:10:17.270
something called Smooth
Streaming protocol.

00:10:17.270 --> 00:10:20.350
And we realized that there are a
lot of content providers who

00:10:20.350 --> 00:10:22.310
are using Microsoft format.

00:10:22.310 --> 00:10:25.970
And we recognized that, and we
thought it is very important

00:10:25.970 --> 00:10:29.080
to support it from our platform
as a default without

00:10:29.080 --> 00:10:30.880
having to do any
special thing.

00:10:30.880 --> 00:10:34.390
So now we are announcing a
Google TV platform which

00:10:34.390 --> 00:10:36.850
supports Smooth Streaming
protocol from the underlying

00:10:36.850 --> 00:10:39.580
platform layer without having
to do anything from the

00:10:39.580 --> 00:10:43.330
developer's end from that
Java application side.

00:10:43.330 --> 00:10:47.800
So actually, from the
developer's perspective, in

00:10:47.800 --> 00:10:51.260
order to play smooth-streaming,

00:10:51.260 --> 00:10:55.650
encoded-streaming content,
simply create MediaPlayer, as

00:10:55.650 --> 00:10:58.060
you can see.

00:10:58.060 --> 00:11:01.740
Simply a MediaPlayer and then
just hand off a data source

00:11:01.740 --> 00:11:04.840
URL, which points
to the isn URL.

00:11:04.840 --> 00:11:07.950
Then the underlying MediaPlayer
will handle

00:11:07.950 --> 00:11:09.940
playback gracefully.

00:11:09.940 --> 00:11:14.790
And then later on, some content
providers got together

00:11:14.790 --> 00:11:18.505
and realized that, oh, smooth
streaming is good, but it's a

00:11:18.505 --> 00:11:21.290
little bit geared toward
Microsoft, as we can see.

00:11:21.290 --> 00:11:25.520
So they come up with a standard
called MPEG-DASH, and

00:11:25.520 --> 00:11:27.640
a lot of Hollywood studios
are supporting it.

00:11:27.640 --> 00:11:30.350
So we are also actively working
on supporting that

00:11:30.350 --> 00:11:33.480
from the platform layer.

00:11:33.480 --> 00:11:37.730
But right now, we have
HLS and Wi-Fi media

00:11:37.730 --> 00:11:40.980
format and smooth streaming.

00:11:40.980 --> 00:11:43.230
Also, there is something
called progressive file

00:11:43.230 --> 00:11:45.990
download, basically downloading
a file.

00:11:45.990 --> 00:11:49.870
And as it gets buffered, you can
actually read it, and then

00:11:49.870 --> 00:11:52.500
play back, which is not
adaptive streaming.

00:11:52.500 --> 00:11:56.830
However, even if we keep adding
these popular streaming

00:11:56.830 --> 00:11:58.860
protocols, we can't
actually support

00:11:58.860 --> 00:11:59.870
everything in the world.

00:11:59.870 --> 00:12:03.050
Because as Christian mentioned,
there are a lot of

00:12:03.050 --> 00:12:06.970
content providers who have
legacy content in their back

00:12:06.970 --> 00:12:10.620
end, so that it takes time
to re-encode to a certain

00:12:10.620 --> 00:12:13.570
standard, or they are already
locked into something which we

00:12:13.570 --> 00:12:14.520
don't support.

00:12:14.520 --> 00:12:17.160
So there are a lot of custom
streaming servers.

00:12:17.160 --> 00:12:19.980
So how we can solve
this problem?

00:12:19.980 --> 00:12:21.520
So we thought about it.

00:12:21.520 --> 00:12:26.610
And then the reason for the
people who use a custom series

00:12:26.610 --> 00:12:29.400
streaming series protocol
is the following.

00:12:29.400 --> 00:12:33.700
First of all, they may have a
special need, or they wanted

00:12:33.700 --> 00:12:38.880
to add special features to
differentiate themselves from

00:12:38.880 --> 00:12:40.110
competitors.

00:12:40.110 --> 00:12:43.550
Or so they are so innovative,
so even though draft

00:12:43.550 --> 00:12:48.040
specification is not really
done, but futuristic features

00:12:48.040 --> 00:12:49.140
they adopt.

00:12:49.140 --> 00:12:53.610
Or some of them are locked
into very old technology.

00:12:53.610 --> 00:12:55.790
So in this case,
how can we do?

00:12:55.790 --> 00:13:00.460
So we came up with an idea of,
let's say, if we can create an

00:13:00.460 --> 00:13:04.020
API which can enable developers
to write their own

00:13:04.020 --> 00:13:06.780
streaming protocol and content
processing, that would be very

00:13:06.780 --> 00:13:10.210
nice so that we don't have to
embed thousands of streaming

00:13:10.210 --> 00:13:13.480
protocols in our platform.

00:13:13.480 --> 00:13:17.430
So from the API's perspective,
as we can see, MediaPlayer

00:13:17.430 --> 00:13:24.370
interface in Android expects a
data source which is URI or

00:13:24.370 --> 00:13:29.130
String or FileDescriptors, which
means that underlying

00:13:29.130 --> 00:13:32.570
player implementation should
know what this means.

00:13:32.570 --> 00:13:38.570
So in order to overcome this
limitation, we introduced

00:13:38.570 --> 00:13:41.410
something called MediaSource
API.

00:13:41.410 --> 00:13:47.440
So what this API does is from
the Java layer, as an Android

00:13:47.440 --> 00:13:50.580
application developer, if you
have a custom streaming

00:13:50.580 --> 00:13:55.170
protocol, you can just write
Java code to handle streaming,

00:13:55.170 --> 00:13:56.820
basically getting the
data chunk from

00:13:56.820 --> 00:13:58.200
your streaming server.

00:13:58.200 --> 00:14:02.950
And then if you encoded this
content in a certain container

00:14:02.950 --> 00:14:05.870
which is not standard or
something we don't support,

00:14:05.870 --> 00:14:09.250
then you can actually extract
the data from your container

00:14:09.250 --> 00:14:14.470
itself from the Java and then
end reserved from streaming.

00:14:14.470 --> 00:14:19.120
And then extraction of the
audio-visual stream will be

00:14:19.120 --> 00:14:21.900
audio element stream and
video element stream.

00:14:21.900 --> 00:14:24.920
And then you can just push
down these two streaming

00:14:24.920 --> 00:14:27.680
sources to the underlying
media player.

00:14:27.680 --> 00:14:31.400
And then what's going to happen
is, although we can

00:14:31.400 --> 00:14:35.940
delegate streaming, handling and
container parser, once an

00:14:35.940 --> 00:14:38.170
element stream is being pushed
down to an underlying

00:14:38.170 --> 00:14:42.495
MediaPlayer framework, it can
still use hardware-accelerated

00:14:42.495 --> 00:14:46.820
codec and rendering and
audio-video synchronization,

00:14:46.820 --> 00:14:50.200
And even the PTS, we
do mapping and

00:14:50.200 --> 00:14:51.340
all kinds of stuff.

00:14:51.340 --> 00:14:57.540
So we basically separated the
portion that developers can

00:14:57.540 --> 00:15:01.490
adapt to their own proprietary
streaming and still use

00:15:01.490 --> 00:15:03.850
hardware features.

00:15:03.850 --> 00:15:10.540
So how it works is basically
we have a class in our API

00:15:10.540 --> 00:15:16.250
package called GtvMediaPlayer,
which is a sub-class of a

00:15:16.250 --> 00:15:20.320
Android standard video player
class interface.

00:15:20.320 --> 00:15:24.220
And we added an API called
setMediaSource, and then it

00:15:24.220 --> 00:15:28.630
expects a class, which is
extended from either

00:15:28.630 --> 00:15:32.560
PullMediaSource or
PushMediaSource.

00:15:32.560 --> 00:15:36.230
So the reason why we have two
different media sources

00:15:36.230 --> 00:15:38.050
depends on the use case.

00:15:38.050 --> 00:15:43.170
Let's say if you are trying to
stream live content, usually

00:15:43.170 --> 00:15:45.000
live content is time
sensitive.

00:15:45.000 --> 00:15:49.830
So we have to display the
content as it arrives.

00:15:49.830 --> 00:15:53.520
It shouldn't actually delay
or buffer too much.

00:15:53.520 --> 00:15:56.240
In that case, PushMediaSource
works better.

00:15:56.240 --> 00:16:00.280
But in most cases of on-demand
streaming, you can keep the

00:16:00.280 --> 00:16:02.060
buffer to keep the
quality high.

00:16:02.060 --> 00:16:03.870
So in that case you can
use PullMediaSource.

00:16:07.160 --> 00:16:12.300
So both PullMediaSource and
PushMediaSource inherits from

00:16:12.300 --> 00:16:16.990
a video source interface and
then implements basic

00:16:16.990 --> 00:16:18.140
functionalities.

00:16:18.140 --> 00:16:21.540
And MediaSource is a support
class of those.

00:16:21.540 --> 00:16:26.790
And then this is a skeleton
of the interface.

00:16:26.790 --> 00:16:31.600
So as you can see, there are
multiple methods that will be

00:16:31.600 --> 00:16:35.850
recorded by the underlying
media player to handle an

00:16:35.850 --> 00:16:38.880
actual streaming pipeline.

00:16:38.880 --> 00:16:42.200
So if you take a look at the
sample, for example, if you

00:16:42.200 --> 00:16:45.370
want to implement you own
MediaSource using

00:16:45.370 --> 00:16:49.470
PullMediaSource interface,
PullMediaSource interface

00:16:49.470 --> 00:16:52.740
actually implements all
of this defined in the

00:16:52.740 --> 00:16:56.230
MediaSource interface for you
for convenience, so you don't

00:16:56.230 --> 00:16:57.780
have to do anything special.

00:16:57.780 --> 00:17:00.600
And there are only a few APIs
you need to implement.

00:17:00.600 --> 00:17:04.440
So, for example, here on
de-queue access unit, access

00:17:04.440 --> 00:17:08.550
unit is a chunk of data you want
to pass down to the lower

00:17:08.550 --> 00:17:11.150
layer media framework.

00:17:11.150 --> 00:17:16.130
And this event is called when
the underlying video framework

00:17:16.130 --> 00:17:18.730
display are decoded and
displayed all the content from

00:17:18.730 --> 00:17:19.490
the buffer.

00:17:19.490 --> 00:17:22.000
So you can keep pulling
the data and

00:17:22.000 --> 00:17:23.540
keep it in your queue.

00:17:23.540 --> 00:17:28.130
And then your queued data will
be de-queued by this event.

00:17:28.130 --> 00:17:31.270
So that's very simple.

00:17:31.270 --> 00:17:34.856
So now let's look at the
actual software.

00:17:34.856 --> 00:17:38.860
CHRISTIAN KURZKE: So here's
one example application.

00:17:38.860 --> 00:17:42.140
We were working with a company
you may have heard of--

00:17:42.140 --> 00:17:43.550
Sirius XM.

00:17:43.550 --> 00:17:45.690
They do satellite radio.

00:17:45.690 --> 00:17:49.800
And they also do stream their
content over the internet

00:17:49.800 --> 00:17:54.860
using a custom protocol because
they have very unique

00:17:54.860 --> 00:17:57.310
needs for encoding
their media.

00:17:57.310 --> 00:18:00.790
And initially, they came to us,
and they're like, well, we

00:18:00.790 --> 00:18:03.550
would love to work with you,
but how do we support our

00:18:03.550 --> 00:18:06.050
custom stream technology?

00:18:06.050 --> 00:18:10.530
And so we worked with them and
explained the MediaSource API.

00:18:10.530 --> 00:18:13.230
And they were actually demoing
yesterday on our devices.

00:18:13.230 --> 00:18:16.140
And I think the quote says
it pretty fittingly.

00:18:16.140 --> 00:18:18.770
They were really able to very
quickly develop this

00:18:18.770 --> 00:18:22.040
application using the
new MediaSource API.

00:18:22.040 --> 00:18:25.270
And the best part was
they did not have to

00:18:25.270 --> 00:18:27.130
develop any native code.

00:18:27.130 --> 00:18:29.520
They could do everything
in the Java layer,

00:18:29.520 --> 00:18:30.870
in the Android layer.

00:18:30.870 --> 00:18:35.050
So this was really very easy for
them to put their software

00:18:35.050 --> 00:18:36.300
onto Google TV.

00:18:38.670 --> 00:18:42.860
So besides all the cool stuff
that Andrew has talked about,

00:18:42.860 --> 00:18:45.390
we also have a few new
features in general.

00:18:45.390 --> 00:18:49.510
So the GtvMediaPlayer class,
it also supports multiple

00:18:49.510 --> 00:18:54.600
audio tracks, so if you have
multiple languages for your

00:18:54.600 --> 00:18:55.940
video format.

00:18:55.940 --> 00:18:57.650
And, of course, it
supports closed

00:18:57.650 --> 00:18:59.690
captioning and subtitle.

00:18:59.690 --> 00:19:05.420
So we actually have time text
markup language support.

00:19:05.420 --> 00:19:10.550
And we have also a widget that
you can customize for closed

00:19:10.550 --> 00:19:11.880
captioning.

00:19:11.880 --> 00:19:14.140
So here's an example
what it looks like.

00:19:14.140 --> 00:19:15.490
And this is very basic.

00:19:15.490 --> 00:19:19.640
This is just basically rendering
TTML on top of a

00:19:19.640 --> 00:19:22.620
video stream.

00:19:22.620 --> 00:19:26.100
So now you've seen it's really
easy to actually

00:19:26.100 --> 00:19:29.220
stream to Google TV.

00:19:29.220 --> 00:19:32.590
If you have your content encoded
in any of the common

00:19:32.590 --> 00:19:39.290
formats like HLS or Widevine or
now also PlayReady, you can

00:19:39.290 --> 00:19:40.100
easily do this.

00:19:40.100 --> 00:19:43.830
If you have special needs, we
have APIs for you to implement

00:19:43.830 --> 00:19:45.510
support for that as well.

00:19:45.510 --> 00:19:49.370
So now the question is, how can
you make sure the viewers

00:19:49.370 --> 00:19:51.890
really get the best
possible quality?

00:19:51.890 --> 00:19:55.990
And how can actively monitor
what the viewers actually see?

00:19:55.990 --> 00:19:58.880
And with that I'm going to hand
it back to Andrew, and we

00:19:58.880 --> 00:20:02.000
can look at some of the APIs
that we came up with.

00:20:02.000 --> 00:20:07.080
ANDREW JEON: So let's say you
can use all these APIs to

00:20:07.080 --> 00:20:09.090
support your streaming
protocol and

00:20:09.090 --> 00:20:10.620
your container format.

00:20:10.620 --> 00:20:15.460
And then you use multi-thread
audio APIs to support multiple

00:20:15.460 --> 00:20:17.630
audio tracks and
the subtitles.

00:20:17.630 --> 00:20:20.030
And then now, you open
up a service.

00:20:20.030 --> 00:20:22.100
So a lot of users are watching
your content.

00:20:22.100 --> 00:20:25.220
And the next thing you are
interested in is what was the

00:20:25.220 --> 00:20:27.730
quality the user was
experiencing?

00:20:27.730 --> 00:20:33.030
The fact is that adaptive
streaming is relying on

00:20:33.030 --> 00:20:34.470
fluctuating bandwidth.

00:20:34.470 --> 00:20:39.030
So at some point in the video
playback, the playback quality

00:20:39.030 --> 00:20:40.220
may be worse.

00:20:40.220 --> 00:20:42.440
And at some point, it
could be better.

00:20:42.440 --> 00:20:45.410
So how you can actually monitor
what was the actual

00:20:45.410 --> 00:20:45.950
experience?

00:20:45.950 --> 00:20:48.020
Let's say you have--

00:20:48.020 --> 00:20:52.280
let's say, five tracks, so 200
kilobit, and then 500 kilobit,

00:20:52.280 --> 00:20:55.210
and 1 Meg, 3 Meg, 7
Meg, for example.

00:20:55.210 --> 00:21:00.890
So if a user paid for, like say,
$5 to watch this movie,

00:21:00.890 --> 00:21:04.840
then one user was watching all
the way from the beginning to

00:21:04.840 --> 00:21:07.280
the end using 500 kilobits.

00:21:07.280 --> 00:21:09.980
And then the other user, who
has a relatively better

00:21:09.980 --> 00:21:12.700
bandwidth, has been
using 1 megabit.

00:21:12.700 --> 00:21:17.380
And then at some point in
another part of town, another

00:21:17.380 --> 00:21:20.060
user was able to watch
with 7 megabits.

00:21:20.060 --> 00:21:22.680
Is it fair to charge
the same amount?

00:21:22.680 --> 00:21:24.500
So you may want to do it
slightly differently.

00:21:24.500 --> 00:21:29.450
Or let's say a user had an issue
with the ISP, so they

00:21:29.450 --> 00:21:31.720
couldn't watch the movie
in high quality.

00:21:31.720 --> 00:21:34.130
So they are claiming, oh, please
give me another day.

00:21:34.130 --> 00:21:36.050
I need to watch it again
with better quality, or

00:21:36.050 --> 00:21:37.100
something like that.

00:21:37.100 --> 00:21:39.660
But if you don't have a
mechanism to measure what was

00:21:39.660 --> 00:21:42.140
actually experienced, there
will be a big issue.

00:21:42.140 --> 00:21:45.420
So we paid attention
to this issue.

00:21:45.420 --> 00:21:47.360
And then the biggest--

00:21:47.360 --> 00:21:49.770
there are two things we
need to care about.

00:21:49.770 --> 00:21:53.170
One is actual network bandwidth
during the playback,

00:21:53.170 --> 00:21:55.630
how the network was
fluctuating.

00:21:55.630 --> 00:21:58.940
At the same time, even if the
network is sufficient, that

00:21:58.940 --> 00:22:02.430
doesn't mean that the user was
able to watch every video as

00:22:02.430 --> 00:22:06.160
it's encoded and which is
supposed to be displayed.

00:22:06.160 --> 00:22:10.150
Let's say video has been encoded
in three frames per

00:22:10.150 --> 00:22:13.510
second, but for some reason, the
user was running something

00:22:13.510 --> 00:22:17.300
in the background so the
hardware all slowed down, so

00:22:17.300 --> 00:22:20.010
like half of the frame was
dropped in the middle.

00:22:20.010 --> 00:22:22.680
So even if you have a full-blown
bandwidth for the

00:22:22.680 --> 00:22:26.010
content, but if the device was
not capable, then actual

00:22:26.010 --> 00:22:28.840
experience will be affected.

00:22:28.840 --> 00:22:34.280
So once we have a set of APIs
to measure these two things,

00:22:34.280 --> 00:22:39.840
then developers can actually
ensure customer satisfaction.

00:22:39.840 --> 00:22:43.810
And by monitoring all the
experience, you can decide

00:22:43.810 --> 00:22:47.640
whether to refund or extend
the playback time or do

00:22:47.640 --> 00:22:51.730
whatever to satisfy
your customer.

00:22:51.730 --> 00:22:55.320
And also, if the application
itself has access to this

00:22:55.320 --> 00:22:59.240
information in real time, you
can make a good judgment.

00:22:59.240 --> 00:23:03.900
Let's say bandwidth goes down
too much and has been dropping

00:23:03.900 --> 00:23:07.410
too often, then you can actually
recommend the user to

00:23:07.410 --> 00:23:08.645
view it later.

00:23:08.645 --> 00:23:14.260
Or the bandwidth hasn't been
able to go up to full 1080p

00:23:14.260 --> 00:23:18.000
quality for a long period of
time, then you can actually

00:23:18.000 --> 00:23:20.800
suggest to the user, oh, you
have an issue with the 1080

00:23:20.800 --> 00:23:23.090
playback so the user
will know rather

00:23:23.090 --> 00:23:25.170
than they just complain.

00:23:25.170 --> 00:23:30.300
So these are the set of APIs we
came up with so the set of

00:23:30.300 --> 00:23:32.930
APIs can measure these things.

00:23:32.930 --> 00:23:37.450
First of all, actual frame per
second data can be measured.

00:23:37.450 --> 00:23:40.670
Let's say from your Java
application, you can kick off

00:23:40.670 --> 00:23:45.740
a monitoring heartbeat to the
underlying media player.

00:23:45.740 --> 00:23:49.075
So let's say if you want to
measure frame per second, then

00:23:49.075 --> 00:23:52.335
the underlying media player,
along with a low-level video

00:23:52.335 --> 00:23:57.030
SDK to measure extra frames per
second in the renderer so

00:23:57.030 --> 00:24:01.380
that it can return the
information of how much frames

00:24:01.380 --> 00:24:04.580
per second has been displayed
to the user.

00:24:04.580 --> 00:24:05.760
And network bandwidth.

00:24:05.760 --> 00:24:09.710
As the bandwidth goes down
and up and down, we can

00:24:09.710 --> 00:24:15.020
periodically, whether every
second or something or even if

00:24:15.020 --> 00:24:18.580
you want to monitor much
less often, then you

00:24:18.580 --> 00:24:19.650
can do that, too.

00:24:19.650 --> 00:24:22.900
And when the network bandwidth
changes, we can report extra

00:24:22.900 --> 00:24:26.170
bandwidth measured right before
that point up to the

00:24:26.170 --> 00:24:27.830
application.

00:24:27.830 --> 00:24:32.970
And the adaptive streaming uses
buffering technology.

00:24:32.970 --> 00:24:36.360
And buffer actually
changes in size.

00:24:36.360 --> 00:24:41.310
Let's say at some point a 500
kilobit stream was being

00:24:41.310 --> 00:24:44.330
played, then the buffer doesn't
have to be too long

00:24:44.330 --> 00:24:48.360
because each chunk is smaller,
so the buffer can be this.

00:24:48.360 --> 00:24:52.080
And if quality goes all the
way up to 1080p, then the

00:24:52.080 --> 00:24:55.230
buffer size may get larger
to keep, let's

00:24:55.230 --> 00:24:56.600
say, up to 10 seconds.

00:24:56.600 --> 00:25:00.720
But even the 10-second
high-quality video requires

00:25:00.720 --> 00:25:01.750
bigger memory.

00:25:01.750 --> 00:25:06.860
And the buffer size and actual
fielding ratio is very

00:25:06.860 --> 00:25:07.610
important information.

00:25:07.610 --> 00:25:11.860
Let's say I allocate 30
megabytes and then 10

00:25:11.860 --> 00:25:15.660
megabytes has refilled, so
that's a good indicator for

00:25:15.660 --> 00:25:19.500
current quality for
upcoming seconds.

00:25:19.500 --> 00:25:23.760
But if we only provide proper
size and proper filling by

00:25:23.760 --> 00:25:27.290
bytes, there is a lot of work
for developers to do.

00:25:27.290 --> 00:25:30.450
Because depending on the
encoding quality, you need to

00:25:30.450 --> 00:25:33.590
calculate how many number
of seconds of

00:25:33.590 --> 00:25:35.520
video is being buffered.

00:25:35.520 --> 00:25:39.650
So we added another API, which
can actually return buffered

00:25:39.650 --> 00:25:43.790
media playback duration, which
is, regardless of the size of

00:25:43.790 --> 00:25:47.320
the buffer, regardless of the
size of encode, if you just

00:25:47.320 --> 00:25:49.870
want to know how many seconds
of video is remaining in the

00:25:49.870 --> 00:25:52.540
buffer, then you can actually
know that--

00:25:52.540 --> 00:25:56.420
Two 2 remaining, 10 seconds
remaining, 0 seconds

00:25:56.420 --> 00:25:58.880
remaining, regardless
of the size.

00:25:58.880 --> 00:26:01.280
So we thought that would
be very useful.

00:26:01.280 --> 00:26:02.770
And then audio information.

00:26:02.770 --> 00:26:06.040
So right now we don't really
have a lot of use cases for

00:26:06.040 --> 00:26:09.320
audio information because
usually audio is encoded in a

00:26:09.320 --> 00:26:10.400
single bit rate.

00:26:10.400 --> 00:26:15.980
But in the future, if a
developer chooses to variate

00:26:15.980 --> 00:26:22.430
the audio encoding, let's say,
from 10 K, to 44 K, it depends

00:26:22.430 --> 00:26:24.525
on the network bandwidth if you
want to change the audio

00:26:24.525 --> 00:26:29.140
quality also to squeeze out
every bit of the network

00:26:29.140 --> 00:26:31.230
that'll be possible that
you can measure.

00:26:31.230 --> 00:26:34.840
And in the future, if a
developer wants to change on

00:26:34.840 --> 00:26:38.190
their server side, if the
bandwidth is good enough, then

00:26:38.190 --> 00:26:39.835
send out 7.1 channel.

00:26:39.835 --> 00:26:43.770
If the bandwidth goes down to
a little worse than 5.1

00:26:43.770 --> 00:26:45.590
channel, the bandwidth
is limited

00:26:45.590 --> 00:26:46.860
then to only two channels.

00:26:46.860 --> 00:26:50.830
So we don't really have a use
case like that today, but we

00:26:50.830 --> 00:26:52.620
thought that would be very
useful information.

00:26:52.620 --> 00:26:56.990
So there's an API
to return that.

00:26:56.990 --> 00:27:01.150
Default implementation and
default set of error codes in

00:27:01.150 --> 00:27:02.750
Android is quite limited.

00:27:02.750 --> 00:27:06.960
So we add a bunch of extra error
codes to monitor various

00:27:06.960 --> 00:27:09.540
error situations.

00:27:09.540 --> 00:27:12.700
And the good thing about this
is once you start monitoring

00:27:12.700 --> 00:27:16.230
all these variables, you can use
the Analytics framework to

00:27:16.230 --> 00:27:21.430
send this data back to the
Google server, and you can

00:27:21.430 --> 00:27:24.140
monitor that.

00:27:24.140 --> 00:27:30.390
So from the encoding point of
view, there are two cases to

00:27:30.390 --> 00:27:31.610
implement this API.

00:27:31.610 --> 00:27:35.470
One is using existing Android
events, for example,

00:27:35.470 --> 00:27:39.610
OnInfoListener event or
adding our own events.

00:27:39.610 --> 00:27:42.330
So, for example, in the case
of OnInfoListener, this

00:27:42.330 --> 00:27:45.240
example shows you how to monitor
network bandwidth

00:27:45.240 --> 00:27:48.780
changes and frame per second
and dropped frames.

00:27:48.780 --> 00:27:53.690
So basically, the same event
handler you usually use based

00:27:53.690 --> 00:27:58.600
on the Android video playback
standard, so OnInfoListener

00:27:58.600 --> 00:28:01.490
can receive the event.

00:28:01.490 --> 00:28:05.190
And then there's an extra
what type to be defined.

00:28:05.190 --> 00:28:08.350
For example, video info network
bandwidth or video

00:28:08.350 --> 00:28:11.250
info FPS or dropped frames.

00:28:11.250 --> 00:28:17.200
And you can actually create a
switch syntax to check that.

00:28:17.200 --> 00:28:22.610
And then, in this case, what is
the type of the data in the

00:28:22.610 --> 00:28:24.160
actualized extra value?

00:28:24.160 --> 00:28:27.210
So, for example, in network
bandwidth, the extra will be

00:28:27.210 --> 00:28:29.530
kilobitPS in integer.

00:28:29.530 --> 00:28:31.750
And then the frame per
second is in integer.

00:28:31.750 --> 00:28:35.060
So you can actually either log
it or send it to your server,

00:28:35.060 --> 00:28:36.660
or send it to Analytics.

00:28:36.660 --> 00:28:39.930
You can do whatever you want.

00:28:39.930 --> 00:28:43.770
So all of this sounds good, but
if it's really difficult

00:28:43.770 --> 00:28:46.760
to use, then that's not going
to be a good thing for

00:28:46.760 --> 00:28:47.400
developers.

00:28:47.400 --> 00:28:52.370
So when we release this API as
a package, we will also open

00:28:52.370 --> 00:28:57.330
source some of the sample code
that demonstrates these APIs.

00:28:57.330 --> 00:29:01.590
For example, we do support
smooth streaming in the

00:29:01.590 --> 00:29:05.210
underlying media framework, but
in order to demonstrate

00:29:05.210 --> 00:29:09.910
the power of MediaSource API,
we actually implemented

00:29:09.910 --> 00:29:14.360
full-blown smooth streaming
protocol in Java and then used

00:29:14.360 --> 00:29:17.160
the MediaSource API to play.

00:29:17.160 --> 00:29:19.670
So you will have a full-blown
smooth streaming protocol

00:29:19.670 --> 00:29:22.710
implementation in Java, then you
can defer it or change it

00:29:22.710 --> 00:29:24.500
or whatever you want.

00:29:24.500 --> 00:29:28.810
And along with the MediaSource
API, we support PlayReady DRM.

00:29:28.810 --> 00:29:31.980
So if you have a PlayReady DRM
server, you can send the

00:29:31.980 --> 00:29:35.245
license to request, receive
it, and there are certain

00:29:35.245 --> 00:29:40.200
conventions to parse that out
and then send out the encoded

00:29:40.200 --> 00:29:43.160
key portion back to the
underlying framework to load

00:29:43.160 --> 00:29:45.100
the key, the session key.

00:29:45.100 --> 00:29:49.250
So that when you send out
audio/video elements in

00:29:49.250 --> 00:29:51.850
stream, then underlying media
framework, DRM framework will

00:29:51.850 --> 00:29:54.310
know how to decrypt
and display.

00:29:54.310 --> 00:29:57.050
And multi-track audio,
TTLM-based closed captioning

00:29:57.050 --> 00:30:00.320
rendering, and extra rendering
code itself

00:30:00.320 --> 00:30:01.610
will be open sourced.

00:30:01.610 --> 00:30:07.730
So the sample Christian showed
you with the little red and

00:30:07.730 --> 00:30:11.340
italic text, that code
is a sample.

00:30:11.340 --> 00:30:14.270
It doesn't support full-blown
TTMS spec.

00:30:14.270 --> 00:30:18.600
But if you are using a very rare
feature of a TTML, then

00:30:18.600 --> 00:30:20.350
you can use it in your
server side.

00:30:20.350 --> 00:30:24.033
At the same time, you can extend
the rendering widget to

00:30:24.033 --> 00:30:26.450
handle that.

00:30:26.450 --> 00:30:29.410
And full-blown QoS API
demonstration will be part of

00:30:29.410 --> 00:30:30.150
the sample.

00:30:30.150 --> 00:30:32.770
So that you can just take a look
and then use it in your

00:30:32.770 --> 00:30:34.940
application.

00:30:34.940 --> 00:30:37.540
OK, now I will hand it
off to Christian.

00:30:37.540 --> 00:30:39.090
CHRISTIAN KURZKE:
Thanks, Andrew.

00:30:39.090 --> 00:30:40.810
So I think this is
really awesome.

00:30:40.810 --> 00:30:43.680
So basically, this is a summary
of a lot of the

00:30:43.680 --> 00:30:45.490
features that Andrew's
team has been

00:30:45.490 --> 00:30:47.480
working on in the platform.

00:30:47.480 --> 00:30:51.460
And I think it's exciting for
developers who create Google

00:30:51.460 --> 00:30:56.730
TV applications that talk to
servers to stream content to

00:30:56.730 --> 00:30:59.860
their app and to show really
high-quality videos in their

00:30:59.860 --> 00:31:00.910
application.

00:31:00.910 --> 00:31:04.190
And it gives you all the
necessary APIs to monitor,

00:31:04.190 --> 00:31:08.790
make sure the video is displayed
properly, and so on.

00:31:08.790 --> 00:31:10.690
So actually, he already
advanced--

00:31:10.690 --> 00:31:11.950
so wait, there's more.

00:31:11.950 --> 00:31:15.680
So this is actually something
I want to tell you.

00:31:15.680 --> 00:31:18.290
It's actually a session going on
right in parallel, which is

00:31:18.290 --> 00:31:20.430
unfortunate for people
who are here live.

00:31:20.430 --> 00:31:23.660
Fortunately, all the sessions
are recorded, so please check

00:31:23.660 --> 00:31:26.530
it out when you have a
chance afterwards.

00:31:26.530 --> 00:31:32.060
So YouTube has announced that
there are now content APIs.

00:31:32.060 --> 00:31:37.090
And if you don't have servers
to host all of your content,

00:31:37.090 --> 00:31:39.220
you can use the YouTube servers
and the YouTube

00:31:39.220 --> 00:31:40.000
infrastructure.

00:31:40.000 --> 00:31:43.740
And we know quite a bit about
how to stream high-quality

00:31:43.740 --> 00:31:48.250
content, so this is really
actually pretty exciting.

00:31:48.250 --> 00:31:51.310
So you don't need all of the
infrastructure back-end stuff.

00:31:51.310 --> 00:31:54.150
You could just use ours, and you
can focus on creating the

00:31:54.150 --> 00:31:56.950
app for playing back
this content.

00:31:56.950 --> 00:31:58.910
So there is an entire session.

00:31:58.910 --> 00:32:00.800
It's called the YouTube
Player API and the

00:32:00.800 --> 00:32:01.910
YouTube Content API.

00:32:01.910 --> 00:32:04.230
It's basically going on
right now as we speak.

00:32:08.170 --> 00:32:11.720
Now we've talked about how
to get content there.

00:32:11.720 --> 00:32:16.890
And I'm just going to talk a
little bit quickly about how

00:32:16.890 --> 00:32:19.890
to make sure your content
actually stays secure and gets

00:32:19.890 --> 00:32:21.140
delivered securely.

00:32:23.530 --> 00:32:26.680
And in the interest of time,
you all know what a DRM is

00:32:26.680 --> 00:32:28.390
supposed to do.

00:32:28.390 --> 00:32:31.170
I just want to highlight, only
because you're streaming your

00:32:31.170 --> 00:32:35.000
content over HTTPS does
not make it a DRM.

00:32:35.000 --> 00:32:36.080
DRM is a lot more.

00:32:36.080 --> 00:32:37.950
It's license management.

00:32:37.950 --> 00:32:42.170
Here is sort of a typical use
case where, for example, a

00:32:42.170 --> 00:32:45.960
Google TV application, it would
talk to a commerce site

00:32:45.960 --> 00:32:48.210
where you browse through
a library of movies.

00:32:48.210 --> 00:32:49.310
You purchase a movie.

00:32:49.310 --> 00:32:51.300
You have all those
transactions.

00:32:51.300 --> 00:32:53.420
And then you use Media
Player to actually

00:32:53.420 --> 00:32:55.400
request the video stream.

00:32:55.400 --> 00:32:58.180
The video stream comes back with
a license request, and

00:32:58.180 --> 00:33:00.660
then you deal with a licensed
server, and

00:33:00.660 --> 00:33:01.520
so on and so forth.

00:33:01.520 --> 00:33:04.960
And again, just like streaming,
there's a whole set

00:33:04.960 --> 00:33:07.460
of industry standard
protocols.

00:33:07.460 --> 00:33:12.840
And Android, actually, in
Honeycomb, Version 3,

00:33:12.840 --> 00:33:17.400
introduced the DRM framework,
which is really powerful.

00:33:17.400 --> 00:33:19.130
It is extensible.

00:33:19.130 --> 00:33:23.000
It's the standard Android DRM
framework, which, of course,

00:33:23.000 --> 00:33:25.060
works on Google TV.

00:33:25.060 --> 00:33:30.690
So today we do support Widevine,
which is a very

00:33:30.690 --> 00:33:33.410
commonly used DRM system.

00:33:33.410 --> 00:33:38.270
And actually, we have been
working on some plug-ins.

00:33:38.270 --> 00:33:42.920
And Andrew can talk a little bit
more about the new stuff

00:33:42.920 --> 00:33:45.740
that his team has been
working for DRM.

00:33:45.740 --> 00:33:48.050
ANDREW JEON: So we
actually already

00:33:48.050 --> 00:33:49.030
mentioned the PlayReady.

00:33:49.030 --> 00:33:51.560
So it's kind of funny that we
are announcing it again here.

00:33:51.560 --> 00:33:57.710
But it isn't Widevine, so we
added PlayReady DRM as a

00:33:57.710 --> 00:33:59.750
default to all the
second generation

00:33:59.750 --> 00:34:02.080
ARM-based Google TV platform.

00:34:02.080 --> 00:34:06.890
And the way it's supported is
it's still using Android DRM

00:34:06.890 --> 00:34:08.230
framework as is.

00:34:08.230 --> 00:34:12.320
But if you look at the Android
DRM API, it's so powerful.

00:34:12.320 --> 00:34:16.230
So you can almost feel like
you can do anything.

00:34:16.230 --> 00:34:18.920
But the problem is it's
too powerful.

00:34:18.920 --> 00:34:24.790
So it's not really well defined
for each specific DRM.

00:34:24.790 --> 00:34:29.000
So in case of Widevine, the way
Widevine is accessed is

00:34:29.000 --> 00:34:32.929
using the same API code, we used
to need to know the IDN

00:34:32.929 --> 00:34:38.190
key pair to operate with the
underlying Widevine DRM.

00:34:38.190 --> 00:34:41.885
So we took the idea of how
Widevine was supported and

00:34:41.885 --> 00:34:44.040
then applied it to PlayReady.

00:34:44.040 --> 00:34:44.510
So

00:34:44.510 --> 00:34:47.070
Once we added the PlayReady
DRM in the underlying

00:34:47.070 --> 00:34:50.370
platform, then there are certain
interactions to work

00:34:50.370 --> 00:34:51.469
with the PlayReady.

00:34:51.469 --> 00:34:55.030
So we came up with the
convention of ID and key pair

00:34:55.030 --> 00:34:58.240
to send out all the parameters
to the PlayReady DRM and the

00:34:58.240 --> 00:35:00.140
underlying platform
to operate it.

00:35:00.140 --> 00:35:04.840
So right now it is already built
into a Google TV second

00:35:04.840 --> 00:35:05.640
generation.

00:35:05.640 --> 00:35:08.450
And then the picture it supports
is basic license

00:35:08.450 --> 00:35:10.570
acquisition and license
management.

00:35:10.570 --> 00:35:13.540
And it can be extended to
support customize licensed

00:35:13.540 --> 00:35:15.310
software from your
application.

00:35:15.310 --> 00:35:19.050
So let's say if you have your
own licensed server, then you

00:35:19.050 --> 00:35:21.230
can talk to your licensed
server, basically calling the

00:35:21.230 --> 00:35:25.050
API to request a license
request text.

00:35:25.050 --> 00:35:28.860
And then send that off to your
licensed software, receive the

00:35:28.860 --> 00:35:32.500
license, and then publish the
license into the underlying

00:35:32.500 --> 00:35:37.030
framework, and then send out
video data so that video data

00:35:37.030 --> 00:35:40.510
can be decrypted and
then played back.

00:35:40.510 --> 00:35:42.410
And we also--

00:35:42.410 --> 00:35:46.480
it is already there, but we
wanted to mention that even if

00:35:46.480 --> 00:35:50.640
there's a DRM, if the DRM is
implemented in the CPU,

00:35:50.640 --> 00:35:55.370
basically if all the DRM code
is running in the CPU, then

00:35:55.370 --> 00:35:56.860
it's not really secure.

00:35:56.860 --> 00:36:03.200
Because if a malicious user or
hacker can access the platform

00:36:03.200 --> 00:36:06.630
and then gain access to the
route, then everything in the

00:36:06.630 --> 00:36:09.440
main CPU can potentially
be accessed.

00:36:09.440 --> 00:36:14.280
So we introduced something
called TVP, Trusted Video

00:36:14.280 --> 00:36:18.890
Pass, which means that once the
data is decrypted, that

00:36:18.890 --> 00:36:23.010
decrypted data cannot be
accessed by the main CPU.

00:36:23.010 --> 00:36:26.250
The whatever software, piece
of software running in the

00:36:26.250 --> 00:36:31.020
main CPU, will not have access
to the decrypted data.

00:36:31.020 --> 00:36:33.550
There are various techniques--
depends on each SOC.

00:36:33.550 --> 00:36:36.350
The chief vendor has
multiple choices.

00:36:36.350 --> 00:36:39.500
They make their own choice and
then apply their own design.

00:36:39.500 --> 00:36:43.250
But the data is used in the
different section of the

00:36:43.250 --> 00:36:45.380
memory so that it
is protected.

00:36:45.380 --> 00:36:48.160
And then once they are actually
decrypted in the

00:36:48.160 --> 00:36:52.520
section, the way the video
pipeline works from decryption

00:36:52.520 --> 00:36:55.490
to decoding to rendering is
done through the handle.

00:36:55.490 --> 00:36:59.340
Let's say you've got a buffer
with encrypted data, and then

00:36:59.340 --> 00:37:03.820
send that buffer to the
DRM security module.

00:37:03.820 --> 00:37:06.190
Then the security module will
decrypt and keep it in the

00:37:06.190 --> 00:37:07.250
secure zone.

00:37:07.250 --> 00:37:10.620
And then return to the handle,
which points to that buffer,

00:37:10.620 --> 00:37:12.790
and then hand it off
to the decoder.

00:37:12.790 --> 00:37:14.880
Then the decoder implementation
should have

00:37:14.880 --> 00:37:18.850
access to the secure area
to get to the data

00:37:18.850 --> 00:37:20.140
and then decode it.

00:37:20.140 --> 00:37:25.080
And then uncompressed data will
be also so stored in the

00:37:25.080 --> 00:37:27.880
secure region, and then return
another handle to point to

00:37:27.880 --> 00:37:31.330
that, and then send that handle
to the rendering piece.

00:37:31.330 --> 00:37:36.100
So that the renderer, usually it
could be FRC in case of TP

00:37:36.100 --> 00:37:39.860
or STMI vendor in the set-top
box case, and then send it off

00:37:39.860 --> 00:37:41.080
to the display.

00:37:41.080 --> 00:37:46.920
So that we can ensure
video protection.

00:37:46.920 --> 00:37:49.390
And this feature is integrated
with smooth

00:37:49.390 --> 00:37:51.170
streaming and Wi-Fi.

00:37:51.170 --> 00:37:55.590
So if you are using smooth
streaming or Wi-Fi protocol or

00:37:55.590 --> 00:37:58.610
any other custom streaming
protocol with a video-sourced

00:37:58.610 --> 00:38:04.290
API and parity, we
will protect the

00:38:04.290 --> 00:38:05.540
trusted video path.

00:38:07.540 --> 00:38:12.050
So just to summarize, we have an
Android DRM framework which

00:38:12.050 --> 00:38:15.160
enables you to access the DRM
feature from the Java

00:38:15.160 --> 00:38:16.410
application.

00:38:16.410 --> 00:38:19.780
And once data is decrypted and
re-protected through trusted

00:38:19.780 --> 00:38:24.580
video paths all the way to the
display unit and then if the

00:38:24.580 --> 00:38:29.060
device a standby device, either
a TV that supports the

00:38:29.060 --> 00:38:33.460
HDMI input or body box that
streams in but sends out data

00:38:33.460 --> 00:38:34.900
to HDMI out.

00:38:34.900 --> 00:38:39.345
We always protect the data
inside of the box using the

00:38:39.345 --> 00:38:40.720
trusted video path.

00:38:40.720 --> 00:38:44.740
And whenever data goes in from
our external box or goes out

00:38:44.740 --> 00:38:50.050
to the external box, we are
using HTTP content protection

00:38:50.050 --> 00:38:51.850
to secure the content.

00:38:51.850 --> 00:38:55.080
Now I will hand off to
Christian again.

00:38:55.080 --> 00:38:56.460
CHRISTIAN KURZKE:
Thanks, Andrew.

00:38:56.460 --> 00:38:56.630
Yeah.

00:38:56.630 --> 00:38:58.880
I think this is really
exciting.

00:38:58.880 --> 00:39:02.240
So we have now a full
set of Java APIs.

00:39:02.240 --> 00:39:03.870
And I really want
to stress this.

00:39:03.870 --> 00:39:05.630
There is no native
code required.

00:39:05.630 --> 00:39:08.400
You can just stick in the
comforts of the Android

00:39:08.400 --> 00:39:11.830
virtual machine and you can
deliver super high-quality

00:39:11.830 --> 00:39:14.230
content, adaptive streaming.

00:39:14.230 --> 00:39:16.830
You can even support your custom
streaming protocols.

00:39:16.830 --> 00:39:19.130
We have support for smooth
streaming and

00:39:19.130 --> 00:39:21.480
Widevine and HLS.

00:39:21.480 --> 00:39:26.620
And we have a full DRM system,
which will keep your content

00:39:26.620 --> 00:39:29.070
secure all the way end to end.

00:39:29.070 --> 00:39:31.980
So now, how can we make
this convenient and

00:39:31.980 --> 00:39:33.690
integrated to use?

00:39:33.690 --> 00:39:37.250
So our vision-- and our team is
working really hard to make

00:39:37.250 --> 00:39:40.870
Google TV sort of the user
interface to your

00:39:40.870 --> 00:39:43.140
entertainment, to your
living room.

00:39:43.140 --> 00:39:46.540
It's really the way how you get
to content in your living

00:39:46.540 --> 00:39:51.050
room from both broadcast
television or satellite or

00:39:51.050 --> 00:39:54.970
other set-top boxes that are
connected over HDMI or

00:39:54.970 --> 00:39:58.900
streaming directly digitally
over the internet and bringing

00:39:58.900 --> 00:40:01.520
it to the television.

00:40:01.520 --> 00:40:04.760
So let's first look at-- and
I'll browse through this.

00:40:04.760 --> 00:40:06.790
There was an earlier
talk where we did a

00:40:06.790 --> 00:40:07.980
lot about user research.

00:40:07.980 --> 00:40:11.740
So we really looked how people
find content, what they want

00:40:11.740 --> 00:40:13.480
to watch on their television.

00:40:13.480 --> 00:40:16.090
And usually, people, if they
know what they want, then they

00:40:16.090 --> 00:40:17.300
search for it.

00:40:17.300 --> 00:40:19.660
If they don't know what they
want, they just know roughly

00:40:19.660 --> 00:40:21.240
what they're in the mood
for, they can browse.

00:40:21.240 --> 00:40:23.710
And we have a TV
and movies app.

00:40:23.710 --> 00:40:27.090
And then how do we
get the content?

00:40:27.090 --> 00:40:28.250
So there is a different ways.

00:40:28.250 --> 00:40:29.870
So one is the back end.

00:40:29.870 --> 00:40:31.770
You may have heard that
we sort of search

00:40:31.770 --> 00:40:32.770
stuff on the internet.

00:40:32.770 --> 00:40:35.550
So we index videos,
site maps, and

00:40:35.550 --> 00:40:37.200
everything on the internet.

00:40:37.200 --> 00:40:41.730
But also on the client side, we
actually talk with devices.

00:40:41.730 --> 00:40:43.850
And we have basically
the client side on

00:40:43.850 --> 00:40:45.550
the Google TV box.

00:40:45.550 --> 00:40:49.670
We talk with both physical
and also virtual devices.

00:40:49.670 --> 00:40:54.160
So quick graphic, what
it looks like.

00:40:54.160 --> 00:40:57.800
So basically, what we do is we
can retrieve a channel list or

00:40:57.800 --> 00:41:01.280
a list of DVR recordings
directly from your set-top

00:41:01.280 --> 00:41:03.640
box, if it supports it.

00:41:03.640 --> 00:41:05.450
And we have a lot of devices
that are currently

00:41:05.450 --> 00:41:07.260
integrated this way.

00:41:07.260 --> 00:41:12.260
And that's how we generate
basically the TV and movies

00:41:12.260 --> 00:41:15.020
application which aggregates
all the content that's

00:41:15.020 --> 00:41:18.710
available from your-- in this
case-- satellite provider.

00:41:18.710 --> 00:41:22.370
Maybe it includes also DVR
recordings that you have made.

00:41:22.370 --> 00:41:24.400
And it also can--

00:41:24.400 --> 00:41:26.440
I'll show later how we can
get content from the

00:41:26.440 --> 00:41:27.340
internet into this.

00:41:27.340 --> 00:41:30.180
And when you change channels,
then you just send the command

00:41:30.180 --> 00:41:33.430
back to the satellite box.

00:41:33.430 --> 00:41:36.430
So when the user searches,
this is what our search

00:41:36.430 --> 00:41:38.790
experience looks like.

00:41:38.790 --> 00:41:41.060
This is what our browsing
experience looks like.

00:41:41.060 --> 00:41:43.800
And when you pick a movie and
you want to play back a movie,

00:41:43.800 --> 00:41:45.860
you basically get a
list of sources.

00:41:45.860 --> 00:41:49.300
So, for example, this movie that
I picked, it may already

00:41:49.300 --> 00:41:51.370
be on my local DVR.

00:41:51.370 --> 00:41:55.460
It may be available from dish,
or I can get it from Amazon.

00:41:55.460 --> 00:41:58.220
And the question that I always
get is, well, how can I get my

00:41:58.220 --> 00:41:59.090
stuff in here?

00:41:59.090 --> 00:42:02.470
I am the new and exciting
video provider, how

00:42:02.470 --> 00:42:03.900
can I get in there?

00:42:03.900 --> 00:42:08.050
And we'll talk a little
bit about that.

00:42:08.050 --> 00:42:11.220
So just to clarify some
of the terms.

00:42:11.220 --> 00:42:13.660
We have one-way pairing, which
is the more traditional

00:42:13.660 --> 00:42:17.150
infrared blasting way of
talking with devices.

00:42:17.150 --> 00:42:20.120
And then when we talk about
pairing, we talk more about

00:42:20.120 --> 00:42:23.120
the two-way case, where we not
just change channels on a

00:42:23.120 --> 00:42:26.180
device, but we also read
information back.

00:42:26.180 --> 00:42:30.370
And I'm actually going to hand
over to Mark in a second, and

00:42:30.370 --> 00:42:34.050
he can explain how we do this,
how we integrate one device.

00:42:34.050 --> 00:42:37.510
So the use case that we're
trying to solve now is, OK,

00:42:37.510 --> 00:42:38.870
you have Google TV at home.

00:42:38.870 --> 00:42:42.230
You have a new device that you
bought, or as a manufacturer,

00:42:42.230 --> 00:42:43.170
you're building a new device.

00:42:43.170 --> 00:42:46.720
How can you integrate this
with your device?

00:42:46.720 --> 00:42:47.970
So, Mark.

00:42:53.322 --> 00:42:55.350
MARK LINDNER: So we're going to
talk about how do you build

00:42:55.350 --> 00:42:57.550
your own media device.

00:42:57.550 --> 00:43:00.890
And what a media device is is
basically it's similar to a

00:43:00.890 --> 00:43:03.070
device driver.

00:43:03.070 --> 00:43:06.540
It's a software component that
actually communicates with

00:43:06.540 --> 00:43:08.440
some external device.

00:43:08.440 --> 00:43:11.590
It's packaged as an apk, and
you can install it by

00:43:11.590 --> 00:43:14.760
downloading it from the
Google Play store.

00:43:14.760 --> 00:43:17.230
And a media device really
consists of three basic

00:43:17.230 --> 00:43:18.500
components.

00:43:18.500 --> 00:43:21.210
There's what we call the Media
Device Controller Service,

00:43:21.210 --> 00:43:23.410
which is a standard
Android service.

00:43:23.410 --> 00:43:28.010
And the service hosts one or
more actual media device

00:43:28.010 --> 00:43:29.860
controllers.

00:43:29.860 --> 00:43:33.260
There's a setup activity, which
is used to initially

00:43:33.260 --> 00:43:36.690
pair your device
with Google TV.

00:43:36.690 --> 00:43:39.440
And finally, there's a settings
activity in case your

00:43:39.440 --> 00:43:42.550
device has any user configurable
options that can

00:43:42.550 --> 00:43:43.800
be changed at any time.

00:43:46.250 --> 00:43:48.130
So this is kind of an
overview of our

00:43:48.130 --> 00:43:50.100
media devices framework.

00:43:50.100 --> 00:43:53.180
We have the TV Player
Application, which

00:43:53.180 --> 00:43:55.720
communicates with the Media
Devices Service.

00:43:55.720 --> 00:43:58.490
And the Media Devices Service is
a standard component of the

00:43:58.490 --> 00:44:00.890
Google TV platform.

00:44:00.890 --> 00:44:04.240
The main job of the Media
Devices Service is to

00:44:04.240 --> 00:44:11.240
coordinate access to media
devices, and for each session

00:44:11.240 --> 00:44:15.010
with a media device, it
maintains the instance of the

00:44:15.010 --> 00:44:16.495
Google TV Media Player.

00:44:19.190 --> 00:44:21.580
So all this stuff that's in gray
is stuff that's already

00:44:21.580 --> 00:44:22.210
implemented.

00:44:22.210 --> 00:44:26.770
And the white portion is what
you would implement to create

00:44:26.770 --> 00:44:28.870
a new media device.

00:44:28.870 --> 00:44:30.930
So essentially, we have a
Media Device Controller

00:44:30.930 --> 00:44:34.390
Service, which hosts the device
controller instance.

00:44:34.390 --> 00:44:36.390
And that, in turn, talks
to the actual device.

00:44:38.960 --> 00:44:41.060
So the Device Controller
Service, as we said, is a

00:44:41.060 --> 00:44:42.886
standard Android service.

00:44:42.886 --> 00:44:47.340
It interfaces to one or
more media devices.

00:44:47.340 --> 00:44:49.610
The things it does is notify
the system when the device

00:44:49.610 --> 00:44:51.635
comes online and goes offline.

00:44:51.635 --> 00:44:55.270
It notifies the framework when
the channel is changed on the

00:44:55.270 --> 00:44:57.330
device and so on.

00:44:57.330 --> 00:44:59.790
It can also report information
from the device, like its

00:44:59.790 --> 00:45:03.840
channel lineup, its list of
DVR recordings if it has

00:45:03.840 --> 00:45:06.910
them, and so on.

00:45:06.910 --> 00:45:10.010
So when we implement a new
Media Device Controller

00:45:10.010 --> 00:45:12.720
Service, our framework
provides a

00:45:12.720 --> 00:45:13.760
base class for this.

00:45:13.760 --> 00:45:16.980
So you don't have to build
it from first principles.

00:45:16.980 --> 00:45:20.460
We sub-class abstract device
controller service, and we

00:45:20.460 --> 00:45:22.240
fill in some details.

00:45:22.240 --> 00:45:25.340
The main things we
do here is we

00:45:25.340 --> 00:45:27.290
construct our device object.

00:45:27.290 --> 00:45:30.510
The device object, it just
basically describes the

00:45:30.510 --> 00:45:33.970
attributes of the device's
capabilities and so on.

00:45:33.970 --> 00:45:35.840
And we construct or
device controller

00:45:35.840 --> 00:45:38.310
instance for that device.

00:45:38.310 --> 00:45:42.340
So here's a simple example of
some hypothetical device with

00:45:42.340 --> 00:45:45.910
some various options enabled.

00:45:45.910 --> 00:45:48.530
And the final thing we can do
here is we can register a

00:45:48.530 --> 00:45:52.890
timer to call us back at fixed
intervals so we can check for

00:45:52.890 --> 00:45:55.780
channel updates in case our
device is the type that has a

00:45:55.780 --> 00:45:59.600
channel in it that can
change over time.

00:45:59.600 --> 00:46:01.430
So now the final thing we
implement is the device

00:46:01.430 --> 00:46:03.200
controller.

00:46:03.200 --> 00:46:05.790
This is the actual component
that talks directly to your

00:46:05.790 --> 00:46:08.060
device through whatever

00:46:08.060 --> 00:46:10.970
protocol that device publishes.

00:46:10.970 --> 00:46:13.350
So one thing we do is we handle
user key press events,

00:46:13.350 --> 00:46:15.850
like if you press channel up,
channel down, fast forward on

00:46:15.850 --> 00:46:18.850
your remote, that gets passed
to the device controller for

00:46:18.850 --> 00:46:20.870
processing.

00:46:20.870 --> 00:46:23.650
And we also handle
tune requests.

00:46:23.650 --> 00:46:27.130
So if we get one of our TV URIs
to tune to a channel or a

00:46:27.130 --> 00:46:31.940
DVR recording or whatnot, that
gets processed as well.

00:46:31.940 --> 00:46:34.180
CHRISTIAN KURZKE: Actually,
I just want to quickly

00:46:34.180 --> 00:46:35.150
highlight one thing.

00:46:35.150 --> 00:46:37.210
So just to make sure
you don't miss the

00:46:37.210 --> 00:46:38.860
last part of the slide.

00:46:38.860 --> 00:46:42.440
So basically, when you have this
device controller, you

00:46:42.440 --> 00:46:46.510
can do tune requests to local
URLs, TV URLs, or you can go

00:46:46.510 --> 00:46:52.510
to like HTTP URLs or other URLs
using streaming services.

00:46:52.510 --> 00:46:54.970
So that's where basically it
ties back to the first part of

00:46:54.970 --> 00:46:58.760
the talk where Andrew explained
how you can just use

00:46:58.760 --> 00:47:02.120
the GtvMediaPlayer to play
back streaming media.

00:47:02.120 --> 00:47:07.030
So the DVR can come either from
your HDMI in from your

00:47:07.030 --> 00:47:11.190
local DVR, or it can come
through a streaming protocol

00:47:11.190 --> 00:47:13.850
from basically anywhere
from the cloud.

00:47:13.850 --> 00:47:18.410
So this is basically a very
elegant way to tie the

00:47:18.410 --> 00:47:22.210
streaming together and make it
transparent, look just like a

00:47:22.210 --> 00:47:25.222
local device connected
in your living room.

00:47:25.222 --> 00:47:27.940
MARK LINDNER: So as we mentioned
before, the Media

00:47:27.940 --> 00:47:31.980
Device Session holds the actual
media player instance.

00:47:31.980 --> 00:47:35.600
So as Christian described, for a
physical device, that's just

00:47:35.600 --> 00:47:38.320
connected to an HDMI port.

00:47:38.320 --> 00:47:41.760
The device controller would
tell the session, yes, I

00:47:41.760 --> 00:47:44.300
wanted to tune to HDMI port
number two, or whatever that

00:47:44.300 --> 00:47:45.580
happens to be.

00:47:45.580 --> 00:47:48.850
But if this is a virtual
controller that's representing

00:47:48.850 --> 00:47:50.650
a virtual device that's
streaming media over the

00:47:50.650 --> 00:47:55.880
internet, it would provide the
appropriate URL or data source

00:47:55.880 --> 00:47:59.490
to the media player
as necessary.

00:47:59.490 --> 00:48:04.280
So when we implement a device
controller, again, we provide

00:48:04.280 --> 00:48:10.140
a subclass or a base class in
our framework, use subclass

00:48:10.140 --> 00:48:12.630
device controller.

00:48:12.630 --> 00:48:15.510
And the main two things you
would do here is implement

00:48:15.510 --> 00:48:19.770
this method perform action,
which is handling things like

00:48:19.770 --> 00:48:22.900
channel up, channel down, or
user actions from the remote,

00:48:22.900 --> 00:48:25.550
and tune to channel where given
a channel number, we

00:48:25.550 --> 00:48:28.230
need to tune to that channel.

00:48:28.230 --> 00:48:31.110
So in this case, we would
translate the channel number

00:48:31.110 --> 00:48:34.690
to an appropriate video URI for
the media player to play,

00:48:34.690 --> 00:48:38.240
and then we would call a base
class method to notify the

00:48:38.240 --> 00:48:42.710
framework that we want the media
player instance in that

00:48:42.710 --> 00:48:47.780
media device session to start
playing that stream.

00:48:47.780 --> 00:48:49.890
So in addition to those things,
the typical things you

00:48:49.890 --> 00:48:53.440
would implement are a setup
or a pairing activity.

00:48:53.440 --> 00:48:58.560
This is just an example of the
pairing activity from the dish

00:48:58.560 --> 00:49:02.140
DVR integration that we have
on our existing devices.

00:49:02.140 --> 00:49:06.490
So in this example activity, we
send a command to the DVR

00:49:06.490 --> 00:49:08.530
saying we want to pair.

00:49:08.530 --> 00:49:11.220
The DVR displays the
confirmation code on the video

00:49:11.220 --> 00:49:14.690
stream, and then the user has
to enter that code to

00:49:14.690 --> 00:49:17.060
accomplish the pairing.

00:49:17.060 --> 00:49:19.990
And then finally, if you have
any user configurable settings

00:49:19.990 --> 00:49:24.610
for your device, you can
implement a settings activity.

00:49:24.610 --> 00:49:27.330
This is just a standard Android
preferences activity

00:49:27.330 --> 00:49:30.050
that gets installed into
Google TVs settings

00:49:30.050 --> 00:49:31.440
application.

00:49:31.440 --> 00:49:35.120
And this is, again, an example
of DISH network's--

00:49:35.120 --> 00:49:39.930
the DISH DVR's settings where
we can configure things like

00:49:39.930 --> 00:49:41.590
the behavior of the fast
forward, rewind

00:49:41.590 --> 00:49:42.840
keys, and so on.

00:49:42.840 --> 00:49:45.700
And we can also display some
status information about our

00:49:45.700 --> 00:49:49.880
device like the IP address
and so on.

00:49:49.880 --> 00:49:51.365
And back to Christian.

00:49:51.365 --> 00:49:52.696
CHRISTIAN KURZKE: Thank you.

00:49:52.696 --> 00:49:53.450
Thank you, Mark.

00:49:53.450 --> 00:49:59.570
So basically, just to summarize
this API, first of

00:49:59.570 --> 00:50:03.500
all, if you have a device that
is connected to the Google

00:50:03.500 --> 00:50:06.500
TV-- and connected can
be used very loosely.

00:50:06.500 --> 00:50:10.310
It can be either an infrared
protocol that you can speak to

00:50:10.310 --> 00:50:11.460
your device.

00:50:11.460 --> 00:50:13.210
Maybe it's a legacy device.

00:50:13.210 --> 00:50:15.570
Or maybe you have a more
advanced two-way

00:50:15.570 --> 00:50:17.440
communication-capable device.

00:50:17.440 --> 00:50:19.920
Usually they come with like
an ethernet port.

00:50:19.920 --> 00:50:24.610
If you know how to control your
DVR device or your media

00:50:24.610 --> 00:50:28.950
device, you can write
a Java layer code.

00:50:28.950 --> 00:50:34.720
We call it basically a media
device APK, which is all

00:50:34.720 --> 00:50:36.930
basically sort of like
a driver that

00:50:36.930 --> 00:50:38.620
talks to your device.

00:50:38.620 --> 00:50:42.460
And you can stay all in Java,
no native code required.

00:50:42.460 --> 00:50:43.620
So you can do all this.

00:50:43.620 --> 00:50:48.030
And then you can do this, and
you can create virtual devices

00:50:48.030 --> 00:50:51.020
that get the content over
streaming protocols using all

00:50:51.020 --> 00:50:54.640
of our adaptive bit rate
streaming, using all the DRM

00:50:54.640 --> 00:50:59.010
that we have, and bring it,
integrated to the user.

00:50:59.010 --> 00:51:03.000
And then the setup and settings
activities, they will

00:51:03.000 --> 00:51:04.300
do device-specific things.

00:51:04.300 --> 00:51:07.900
So if you need to negotiate an
IP address or if you need to

00:51:07.900 --> 00:51:11.260
negotiate a pairing pin,
you can do that.

00:51:11.260 --> 00:51:13.800
Or if you have things like for
a remote service, you might

00:51:13.800 --> 00:51:14.720
have to log in.

00:51:14.720 --> 00:51:17.070
If you need to set maybe a user
account and password and

00:51:17.070 --> 00:51:20.180
so on, you can do
that as well.

00:51:20.180 --> 00:51:25.060
So basically, what that means
is we really have one

00:51:25.060 --> 00:51:28.800
interface to all of your content
on potentially all of

00:51:28.800 --> 00:51:33.020
the devices in your living room
and all of the devices or

00:51:33.020 --> 00:51:36.640
all of the content that's
out there in the cloud.

00:51:36.640 --> 00:51:40.180
So what that means is if
you as a developer--

00:51:40.180 --> 00:51:43.180
and I think one of the biggest
opportunities is really

00:51:43.180 --> 00:51:46.980
creating applications that bring
content to television So

00:51:46.980 --> 00:51:51.370
you have access to all the
content out there on streaming

00:51:51.370 --> 00:51:55.780
protocol, so you can use HTTP
live streaming, you can use

00:51:55.780 --> 00:51:57.740
now also smooth streaming.

00:51:57.740 --> 00:52:00.190
And if that's not enough, you
can implement your own

00:52:00.190 --> 00:52:03.740
streaming protocol that matches
your potentially

00:52:03.740 --> 00:52:07.500
legacy streaming servers
or your CDNs.

00:52:07.500 --> 00:52:10.250
We are compatible with
the industry-leading

00:52:10.250 --> 00:52:11.740
standard DRM solutions.

00:52:11.740 --> 00:52:16.360
We have support for Widevine
and, as Andrew pointed out,

00:52:16.360 --> 00:52:19.850
now also for smooth streaming
and PlayReady.

00:52:19.850 --> 00:52:22.550
We know there's a lot of
existing content out there.

00:52:22.550 --> 00:52:25.270
And it's a huge investment for
a company to build up a

00:52:25.270 --> 00:52:29.210
library of hundreds of
thousands of titles.

00:52:29.210 --> 00:52:33.180
So we want to make possible that
you can adapt or create a

00:52:33.180 --> 00:52:38.880
custom application to talk to
your existing back ends.

00:52:38.880 --> 00:52:44.060
And all of this, even in the
Java layer, we have a DRM

00:52:44.060 --> 00:52:48.780
trusted video path, so you can
be assured that your video is

00:52:48.780 --> 00:52:51.660
really handled in the hardware
secure path.

00:52:51.660 --> 00:52:54.170
So that's pretty powerful.

00:52:54.170 --> 00:52:57.780
And then to make it easy for the
user, you can integrate,

00:52:57.780 --> 00:53:01.780
just as a virtual or a real
media device, so users have

00:53:01.780 --> 00:53:04.660
the exact same experience
flipping channels through

00:53:04.660 --> 00:53:08.560
their satellite box as they
would have flipping channels

00:53:08.560 --> 00:53:12.550
through maybe your virtual
application.

00:53:12.550 --> 00:53:16.040
So if you're really interested
in learning more about this,

00:53:16.040 --> 00:53:20.310
we have, of course, our
Google TV Plus page.

00:53:20.310 --> 00:53:22.030
I encourage you to
stay in touch.

00:53:22.030 --> 00:53:25.370
We keep it updated with
new information.

00:53:25.370 --> 00:53:28.370
And of course, as developers,
come to our

00:53:28.370 --> 00:53:31.980
developers.google.com/tv page.

00:53:31.980 --> 00:53:34.290
And I just want to
thank you all.

00:53:34.290 --> 00:53:37.210
And we take questions, so
there's two microphones.

00:53:37.210 --> 00:53:39.350
If you have questions,
you're more than

00:53:39.350 --> 00:53:40.450
welcome to ask us now.

00:53:40.450 --> 00:53:43.580
Otherwise, we'll be hanging
around the sandbox throughout

00:53:43.580 --> 00:53:47.490
the day, so you can come by
and you can play firsthand

00:53:47.490 --> 00:53:49.790
with some of the devices and
can ask us questions.

00:53:59.942 --> 00:54:01.020
AUDIENCE: Hello.

00:54:01.020 --> 00:54:04.550
So are there plans to bring
these features to the main

00:54:04.550 --> 00:54:06.576
Android code base?

00:54:06.576 --> 00:54:07.100
CHRISTIAN KURZKE: Sorry?

00:54:07.100 --> 00:54:09.600
AUDIENCE: Are there plans to
bring smooth streaming and the

00:54:09.600 --> 00:54:14.700
other PlayReady features to the
main Android code base?

00:54:14.700 --> 00:54:16.690
CHRISTIAN KURZKE: Do we bring
smooth streaming to the main

00:54:16.690 --> 00:54:17.720
Android code base?

00:54:17.720 --> 00:54:20.765
Andrew, do you have an
answer for that?

00:54:20.765 --> 00:54:24.010
ANDREW JEON: It actually depends
on Android team's road

00:54:24.010 --> 00:54:27.620
map and their future
road map decision.

00:54:27.620 --> 00:54:32.540
But we just came up with this,
so we haven't had a chance to

00:54:32.540 --> 00:54:34.950
actually discuss when it's going
to be suitable for them

00:54:34.950 --> 00:54:38.160
to adopt yet.

00:54:38.160 --> 00:54:40.986
So right now, it's only
for Google TV.

00:54:40.986 --> 00:54:41.820
CHRISTIAN KURZKE: Yes.

00:54:41.820 --> 00:54:43.100
AUDIENCE: I have a
similar question,

00:54:43.100 --> 00:54:45.660
but from the browser.

00:54:45.660 --> 00:54:47.320
So from the Chromium browser.

00:54:47.320 --> 00:54:50.920
CHRISTIAN KURZKE: So will
the streaming APIs--

00:54:50.920 --> 00:54:55.180
or will it be possible in the
Chromium browser to use the

00:54:55.180 --> 00:54:56.685
DRM frameworks?

00:54:56.685 --> 00:55:00.720
ANDREW JEON: There is a draft
protocol, encryption module

00:55:00.720 --> 00:55:04.200
protocol which is in draft and
being actively worked on.

00:55:04.200 --> 00:55:07.480
But it will be different from
the DRM API in Android.

00:55:07.480 --> 00:55:13.240
But there are a lot of working
groups in our company and also

00:55:13.240 --> 00:55:16.310
other companies that have
combined, so working together,

00:55:16.310 --> 00:55:19.340
but not available to the
general public yet.

00:55:19.340 --> 00:55:20.700
It's actually still
in the works.

00:55:20.700 --> 00:55:23.412
AUDIENCE: So it's the
W3C-- what is it?

00:55:23.412 --> 00:55:24.500
The CMB--

00:55:24.500 --> 00:55:26.661
ANDREW JEON: Yes.

00:55:26.661 --> 00:55:29.630
CHRISTIAN KURZKE: So is that the
Chrome browser for Google

00:55:29.630 --> 00:55:31.040
TV, or the Chrome browser--

00:55:31.040 --> 00:55:32.450
ANDREW JEON: General, general.

00:55:32.450 --> 00:55:33.700
Including all of them, yeah.

00:55:35.935 --> 00:55:36.840
CHRISTIAN KURZKE: Yes.

00:55:36.840 --> 00:55:39.790
AUDIENCE: Will information from
the remote devices like

00:55:39.790 --> 00:55:43.970
the DVRs, will it also pass
control copy information as

00:55:43.970 --> 00:55:48.755
well once the stream
is decrypted?

00:55:48.755 --> 00:55:51.720
CHRISTIAN KURZKE: You mean the
copy information from--

00:55:51.720 --> 00:55:52.690
AUDIENCE: CCI.

00:55:52.690 --> 00:55:54.260
CHRISTIAN KURZKE: CCI.

00:55:54.260 --> 00:55:58.400
The content will come in through
the HDMI channel.

00:55:58.400 --> 00:56:01.540
I assume you mean with the
HDCP security bit?

00:56:01.540 --> 00:56:02.090
AUDIENCE: Correct.

00:56:02.090 --> 00:56:04.170
CHRISTIAN KURZKE: So that is
basically just an HDMI

00:56:04.170 --> 00:56:04.890
pass-through.

00:56:04.890 --> 00:56:08.150
So we would just control the
playback, for example, start

00:56:08.150 --> 00:56:09.440
the playback.

00:56:09.440 --> 00:56:13.590
But then once the content plays
back over HDMI in, we

00:56:13.590 --> 00:56:19.130
would just basically pass
through the device.

00:56:19.130 --> 00:56:20.620
You guys can correct me.

00:56:20.620 --> 00:56:22.030
ANDREW JEON: So we
don't touch CCI.

00:56:22.030 --> 00:56:24.230
If the CCI is 1, we keep it 1.

00:56:24.230 --> 00:56:26.360
If it's 0, we keep it 0.

00:56:26.360 --> 00:56:27.610
And we don't do anything else.

00:56:29.700 --> 00:56:31.062
CHRISTIAN KURZKE: Yes?

00:56:31.062 --> 00:56:38.336
AUDIENCE: Are there any plans
to improve the control over

00:56:38.336 --> 00:56:40.180
video content being displayed?

00:56:40.180 --> 00:56:45.150
For example, the overlay or
position TV windows, or that

00:56:45.150 --> 00:56:46.596
sort of thing?

00:56:46.596 --> 00:56:50.430
CHRISTIAN KURZKE: So overlays
and positioning the TV window

00:56:50.430 --> 00:56:51.680
inside of an application.

00:56:54.310 --> 00:56:55.305
It is a frequent request.

00:56:55.305 --> 00:56:58.170
ANDREW JEON: It is actually
technically possible if you

00:56:58.170 --> 00:57:02.150
use something called Media
Device View as an object.

00:57:02.150 --> 00:57:05.430
But we don't really have
a concrete widget or a

00:57:05.430 --> 00:57:07.890
component-type of infrastructure
readily

00:57:07.890 --> 00:57:10.460
available for you to
use at this point.

00:57:10.460 --> 00:57:12.470
But that's something we are
thinking about, but we don't

00:57:12.470 --> 00:57:15.040
really have a concrete
timing yet.

00:57:15.040 --> 00:57:17.260
CHRISTIAN KURZKE: We know it's
a frequent request for

00:57:17.260 --> 00:57:20.810
developers to take the live TV
or basically take the HDMI in

00:57:20.810 --> 00:57:22.920
and embed it in their
application.

00:57:22.920 --> 00:57:25.840
It's one of those things we
want to get it right, and

00:57:25.840 --> 00:57:28.750
we're still working on the
proper APIs that we feel

00:57:28.750 --> 00:57:31.630
confident we can support
going forward.

00:57:31.630 --> 00:57:35.330
With overlays, we've seen Google
TV applications that

00:57:35.330 --> 00:57:39.510
actually overlay over the
current screen using things

00:57:39.510 --> 00:57:42.930
like toasts are toast widgets
with customer views and so on.

00:57:42.930 --> 00:57:49.370
So there is Android capability
to do that.

00:57:49.370 --> 00:57:50.020
Next question?

00:57:50.020 --> 00:57:52.840
AUDIENCE: Any time window when
you will be releasing the

00:57:52.840 --> 00:57:54.906
sample code?

00:57:54.906 --> 00:57:57.935
ANDREW JEON: It will be the
later part of this year when

00:57:57.935 --> 00:57:59.635
the device--

00:57:59.635 --> 00:58:03.300
I mean, when our software update
for second-generation

00:58:03.300 --> 00:58:05.930
device will be rolled
out to the market.

00:58:05.930 --> 00:58:09.160
We are working into multiple
OEMs, so even if we are done,

00:58:09.160 --> 00:58:11.930
it's not really readily
available to all the devices.

00:58:11.930 --> 00:58:13.260
It takes some time.

00:58:13.260 --> 00:58:15.360
A little bit later part
of this year.

00:58:15.360 --> 00:58:16.650
But it will be in this year.

00:58:16.650 --> 00:58:18.910
AUDIENCE: Thank you.

00:58:18.910 --> 00:58:21.050
CHRISTIAN KURZKE: So basically,
all the APIs that

00:58:21.050 --> 00:58:24.200
we talk about in this session,
they will come with the next

00:58:24.200 --> 00:58:26.390
software update to
the ARM devices.

00:58:26.390 --> 00:58:30.700
So today in the sandbox, it's
not quite there yet, but we're

00:58:30.700 --> 00:58:33.520
working on basically getting the
next-generation software

00:58:33.520 --> 00:58:34.210
update out.

00:58:34.210 --> 00:58:38.220
And as soon as this launches, we
will have all the APIs, the

00:58:38.220 --> 00:58:40.390
documentation, and all the stuff
on our developer page.

00:58:40.390 --> 00:58:41.640
So stay tuned for that.

00:58:44.206 --> 00:58:46.395
AUDIENCE: You know, we've still
got to deal with this

00:58:46.395 --> 00:58:47.810
four-by-three--

00:58:47.810 --> 00:58:51.380
4:3-- and 16:9, some
of the live content

00:58:51.380 --> 00:58:54.400
which comes in 4:3.

00:58:54.400 --> 00:58:58.680
Some of the devices, I think
I've seen one, kind of given a

00:58:58.680 --> 00:59:02.600
button, and then you just make
it, stretch it to 16-by-9.

00:59:02.600 --> 00:59:06.460
Is there any way we can deal
with that situation in

00:59:06.460 --> 00:59:08.100
software or app?

00:59:08.100 --> 00:59:10.690
CHRISTIAN KURZKE: So changing
the aspect ratio

00:59:10.690 --> 00:59:12.405
of the video input?

00:59:12.405 --> 00:59:13.350
AUDIENCE: Correct.

00:59:13.350 --> 00:59:14.890
4:3 to whatever--

00:59:14.890 --> 00:59:16.040
16:9.

00:59:16.040 --> 00:59:20.060
So press a button like normally
we in normal TVs on

00:59:20.060 --> 00:59:20.945
the remote.

00:59:20.945 --> 00:59:27.380
ANDREW JEON: So our platform has
an API for OEMs to be able

00:59:27.380 --> 00:59:29.610
to implement the features to
change the aspect ratio.

00:59:29.610 --> 00:59:33.760
So some OEMs do have a feature
to change, some OEMs don't.

00:59:33.760 --> 00:59:37.630
But if that's critical, we can
actually strongly recommend

00:59:37.630 --> 00:59:41.310
all of our device makers to
follow this API standard to

00:59:41.310 --> 00:59:43.660
enable aspect ratio change.

00:59:43.660 --> 00:59:47.800
AUDIENCE: The problem with that
is that they don't really

00:59:47.800 --> 00:59:49.200
implement that.

00:59:49.200 --> 00:59:51.730
My question was that is there
any way we can handle that

00:59:51.730 --> 00:59:56.220
software, put that in our APK,
and then just tell the users,

00:59:56.220 --> 00:59:59.420
in our own way, OK, press this
button and that would just

00:59:59.420 --> 01:00:00.820
stretch the image?

01:00:00.820 --> 01:00:02.320
ANDREW JEON: We will
take that as a

01:00:02.320 --> 01:00:03.575
request, a future request.

01:00:03.575 --> 01:00:05.060
AUDIENCE: Sorry, I
didn't get that.

01:00:05.060 --> 01:00:06.540
ANDREW JEON: We can take--

01:00:06.540 --> 01:00:08.370
CHRISTIAN KURZKE: We'll
look into this.

01:00:08.370 --> 01:00:10.430
We'll note it.

01:00:10.430 --> 01:00:11.810
I think the answer
is today there

01:00:11.810 --> 01:00:14.610
is no such API available.

01:00:14.610 --> 01:00:17.220
But I think it's something
to look into.

01:00:17.220 --> 01:00:19.000
AUDIENCE: Yeah, I see
great demand.

01:00:19.000 --> 01:00:24.441
And I mean, people see all the
black sides on both sides.

01:00:24.441 --> 01:00:27.926
CHRISTIAN KURZKE: So I think if
you have feature requests

01:00:27.926 --> 01:00:32.740
or any ideas, also reach out to
us on our developer page.

01:00:32.740 --> 01:00:36.350
We have what we call an Issue
Tracker, where you can submit

01:00:36.350 --> 01:00:39.520
ideas and things you want
to have implemented.

01:00:39.520 --> 01:00:43.390
Or you can actually reach out to
us on our Google+ page, and

01:00:43.390 --> 01:00:44.920
we can start a discussion
on it.

01:00:44.920 --> 01:00:45.640
AUDIENCE: All right,
thank you.

01:00:45.640 --> 01:00:48.340
CHRISTIAN KURZKE: Thank you.

01:00:48.340 --> 01:00:49.170
All right.

01:00:49.170 --> 01:00:52.080
I think we're just on time.

01:00:52.080 --> 01:00:55.220
Thank you everyone very much,
and have enjoy the rest of

01:00:55.220 --> 01:00:57.530
your Google I/O.

